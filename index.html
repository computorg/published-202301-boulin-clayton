<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">

<head>

<meta charset="utf-8" />
<meta name="generator" content="quarto-1.4.537" />

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />

<meta name="author" content="Alexis Boulin" />
<meta name="dcterms.date" content="2023-01-12" />
<meta name="keywords" content="Copulae, Random number generation" />
<meta name="description" content="The package \textsf{clayton} is designed to be intuitive, user-friendly, and efficient. It offers a wide range of copula models, including Archimedean, Elliptical, and Extreme. The package is implemented in pure \textsf{Python}, making it easy to install and use." />

<title>A Python Package for Sampling from Copulae: clayton</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<!-- htmldependencies:E3FAD763 -->
<style>

      .quarto-title-block .quarto-title-banner h1,
      .quarto-title-block .quarto-title-banner h2,
      .quarto-title-block .quarto-title-banner h3,
      .quarto-title-block .quarto-title-banner h4,
      .quarto-title-block .quarto-title-banner h5,
      .quarto-title-block .quarto-title-banner h6
      {
        color: #FFFFFF;
      }

      .quarto-title-block .quarto-title-banner {
        color: #FFFFFF;
background: #034E79;
      }
</style>

  <script defer="" src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css" />

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <div id="quarto-toc-target"></div>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
  
  <div class="quarto-title-banner">
    <div class="quarto-title column-body">
      <h1 class="title"><a href="https://computo.sfds.asso.fr">
        <img src="https://computo.sfds.asso.fr/assets/img/logo_notext_white.png" height="60px">
      </a> &nbsp; A Python Package for Sampling from Copulae: clayton</h1>
            <p class="subtitle lead">A Python Package for Sampling from Copulae: clayton</p>
            <p><a href="http://creativecommons.org/licenses/by/4.0/"><img src='https://i.creativecommons.org/l/by/4.0/80x15.png' alt='Creative Commons BY License'></a>
ISSN 2824-7795</p>
            <div>
        <div class="description">
          <p>The package <span class="math inline">\textsf{clayton}</span> is designed to be intuitive, user-friendly, and efficient. It offers a wide range of copula models, including Archimedean, Elliptical, and Extreme. The package is implemented in pure <span class="math inline">\textsf{Python}</span>, making it easy to install and use.</p>
        </div>
      </div>
                </div>
  </div>
    
    <div class="quarto-title-meta-author">
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-heading">Affiliations</div>
          
          <div class="quarto-title-meta-contents">
        <a href="https://aleboul.github.io/">Alexis Boulin</a> 
      </div>
          
          <div class="quarto-title-meta-contents">
              <p class="affiliation">
                  <a href="https://univ-cotedazur.fr/">
                  Université Côte d’Azur, CNRS, LJAD, France
                  </a>
                </p>
              <p class="affiliation">
                  <a href="https://www.inria.fr/fr/lemon">
                  Inria, Lemon
                  </a>
                </p>
            </div>
        </div>
                    
  <div class="quarto-title-meta">
                                
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">January 12, 2023</p>
      </div>
    </div>
                                    
      <div>
      <div class="quarto-title-meta-heading">Modified</div>
      <div class="quarto-title-meta-contents">
        <p class="date-modified">January 9, 2024</p>
      </div>
    </div>
      
                  
      <div>
      <div class="quarto-title-meta-heading">Keywords</div>
      <div class="quarto-title-meta-contents">
        <p class="date">Copulae, Random number generation</p>
      </div>
    </div>
    
    <div>
      <div class="quarto-title-meta-heading">Status</div>
      <div class="quarto-title-meta-contents">
              <a href="https://github.com/computorg/published-202301-boulin-clayton"><img src='https://github.com/computorg/published-202301-boulin-clayton/actions/workflows/build.yml/badge.svg' alt='build status'></a>
                    <p class="date"></p>
        <a href="https://github.com/computorg/published-202301-boulin-clayton/issues?q=is%3Aopen+is%3Aissue+label%3Areview"><img src='https://img.shields.io/badge/reviews-reports-blue' alt='reviews'></a>
            </div>
    </div>

  </div>
                                                
  <div>
    <div class="abstract">
    <div class="abstract-title">Abstract</div>
      <p>The package <span class="math inline">\textsf{clayton}</span> is designed to be intuitive, user-friendly, and efficient. It offers a wide range of copula models, including Archimedean, Elliptical, and Extreme. The package is implemented in pure <span class="math inline">\textsf{Python}</span>, making it easy to install and use. In addition, we provide detailed documentation and examples to help users get started quickly. We also conduct a performance comparison with existing <span class="math inline">\textsf{R}</span> packages, demonstrating the efficiency of our implementation. The <span class="math inline">\textsf{clayton}</span> package is a valuable tool for researchers and practitioners working with copulae in <span class="math inline">\textsf{Python}</span>.</p>
    </div>
  </div>

  </header>

<nav id="TOC" role="doc-toc">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction"><span class="header-section-number">1</span> Introduction</a></li>
  <li><a href="#sec-classes" id="toc-sec-classes"><span class="header-section-number">2</span> Classes</a>
  <ul>
  <li><a href="#sec-arch" id="toc-sec-arch"><span class="header-section-number">2.1</span> The Archimedean class</a></li>
  <li><a href="#sec-extreme" id="toc-sec-extreme"><span class="header-section-number">2.2</span> The Extreme class</a></li>
  </ul></li>
  <li><a href="#sec-rng" id="toc-sec-rng"><span class="header-section-number">3</span> Random number generator</a>
  <ul>
  <li><a href="#sec-biv_case" id="toc-sec-biv_case"><span class="header-section-number">3.1</span> The bivariate case</a></li>
  <li><a href="#sec-mv_case" id="toc-sec-mv_case"><span class="header-section-number">3.2</span> The multivariate case</a></li>
  </ul></li>
  <li><a href="#sec-pairwise" id="toc-sec-pairwise"><span class="header-section-number">4</span> Case study : Modeling pairwise dependence between spatial maximas with missing data</a>
  <ul>
  <li><a href="#sec-background" id="toc-sec-background"><span class="header-section-number">4.1</span> Background</a></li>
  <li><a href="#sec-num" id="toc-sec-num"><span class="header-section-number">4.2</span> Numerical results</a></li>
  </ul></li>
  <li><a href="#sec-discussion" id="toc-sec-discussion"><span class="header-section-number">5</span> Discussion</a>
  <ul>
  <li><a href="#comparison-of-textsfclayton-with-textsfr-packages" id="toc-comparison-of-textsfclayton-with-textsfr-packages"><span class="header-section-number">5.1</span> Comparison of <span class="math inline">\textsf{clayton}</span> with <span class="math inline">\textsf{R}</span> packages</a></li>
  <li><a href="#conclusion" id="toc-conclusion"><span class="header-section-number">5.2</span> Conclusion</a></li>
  </ul></li>
  <li><a href="#references" id="toc-references">References</a></li>
  <li><a href="#appendices" id="toc-appendices"><span class="header-section-number">6</span> Appendix</a>
  <ul>
  <li><a href="#sec-bv_arch" id="toc-sec-bv_arch"><span class="header-section-number">6.1</span> Bivariate Archimedean models</a></li>
  <li><a href="#sec-bv_ext" id="toc-sec-bv_ext"><span class="header-section-number">6.2</span> Implemented bivariate extreme models</a></li>
  <li><a href="#sec-mv_arch" id="toc-sec-mv_arch"><span class="header-section-number">6.3</span> Multivariate Archimedean copulae</a></li>
  <li><a href="#sec-mv_ext" id="toc-sec-mv_ext"><span class="header-section-number">6.4</span> Multivariate extreme models</a></li>
  <li><a href="#sec-mv_ellip" id="toc-sec-mv_ellip"><span class="header-section-number">6.5</span> Multivariate elliptical dependencies</a></li>
  </ul></li>
  </ul>
</nav>
<section id="introduction" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Introduction</h1>
<p>Modeling dependence relations between random variables is a topic of interest in probability theory and statistics. The most popular approach is based on the second moment of the underlying random variables, namely, the covariance. It is well known that only linear dependence can be captured by the covariance and it is only characteristic for a few models, e.g., the multivariate normal distribution or binary random variables. As a beneficial alternative to dependence, the concept of copulae, going back to <span class="citation" data-cites="Skla59">Sklar (<a href="#ref-Skla59" role="doc-biblioref">1959</a>)</span>, has drawn a lot of attention. The copula <span class="math inline">C: [0,1]^d \rightarrow [0,1]</span> of a random vector <span class="math inline">\mathbf{X} = (X_0, \dots, X_{d-1})</span> with <span class="math inline">d \geq 2</span> allows us to separate the effect of dependence from the effect of the marginal distribution, such that:</p>
<p><span class="math display">
    \mathbb{P}\left\{ X_0 \leq x_0, \dots, X_{d-1} \leq x_{d-1} \right\} = C\left(\mathbb{P} \{X_0 \leq x_0\}, \dots, \mathbb{P}\{X_{d-1} \leq x_{d-1} \}\right),
</span></p>
<p>where <span class="math inline">(x_0, \dots, x_{d-1}) \in \mathbb{R}^d</span>. The main consequence of this identity is that the copula completely characterizes the stochastic dependence between the margins of <span class="math inline">\mathbf{X}</span>.</p>
<p>In other words, copulae allow us to model marginal distributions and dependence structure separately. Furthermore, motivated by Sklar’s theorem, the problem of investigating stochastic dependence is reduced to the study of multivariate distribution functions under the unit hypercube <span class="math inline">[0,1]^d</span> with uniform margins. The theory of copulae has been of prime interest for many applied fields of science, such as quantitative finance (<span class="citation" data-cites="patton2012review">Patton (<a href="#ref-patton2012review" role="doc-biblioref">2012</a>)</span>) or environmental sciences (<span class="citation" data-cites="MISHRA2011157">Mishra and Singh (<a href="#ref-MISHRA2011157" role="doc-biblioref">2011</a>)</span>). This increasing number of applications has led to a demand for statistical methods. For example, semiparametric estimation (<span class="citation" data-cites="10.2307/2337532">Genest, Ghoudi, and Rivest (<a href="#ref-10.2307/2337532" role="doc-biblioref">1995</a>)</span>), nonparametric estimation (<span class="citation" data-cites="10.2307/3318798">Fermanian, Radulović, and Wegkamp (<a href="#ref-10.2307/3318798" role="doc-biblioref">2004</a>)</span>) of copulae or nonparametric estimation of conditional copulae (<span class="citation" data-cites="10.2307/24586878">Gijbels, Omelka, and Veraverbeke (<a href="#ref-10.2307/24586878" role="doc-biblioref">2015</a>)</span>, <span class="citation" data-cites="PORTIER2018160">Portier and Segers (<a href="#ref-PORTIER2018160" role="doc-biblioref">2018</a>)</span>) have been investigated. These results are established for a fixed arbitrary dimension <span class="math inline">d \geq 2</span>, but several investigations (e.g. <span class="citation" data-cites="10.2307/25463423">Einmahl and Lin (<a href="#ref-10.2307/25463423" role="doc-biblioref">2006</a>)</span>, <span class="citation" data-cites="10.1214/21-AOS2050">Einmahl and Segers (<a href="#ref-10.1214/21-AOS2050" role="doc-biblioref">2021</a>)</span>) are done for functional data for the tail copula, which captures dependence in the upper tail.</p>
<p>Software implementation of copulae has been extensively studied in <span class="math inline">\textsf{R}</span>, for example in the packages <span class="citation" data-cites="evdR">A. G. Stephenson (<a href="#ref-evdR" role="doc-biblioref">2002</a>)</span>, <span class="citation" data-cites="copulaR">Jun Yan (<a href="#ref-copulaR" role="doc-biblioref">2007</a>)</span>, <span class="citation" data-cites="VineCopulaR">Schepsmeier et al. (<a href="#ref-VineCopulaR" role="doc-biblioref">2019</a>)</span>. However, methods for working with copulae in <span class="math inline">\textsf{Python}</span> are still limited. As far as we know, copula-dedicated packages in <span class="math inline">\textsf{Python}</span> are mainly designed for modeling, such as <span class="citation" data-cites="copulasPy">Alvarez et al. (<a href="#ref-copulasPy" role="doc-biblioref">2021</a>)</span> and <span class="citation" data-cites="copulaePy">Bock and Chapman (<a href="#ref-copulaePy" role="doc-biblioref">2021</a>)</span>. These packages use maximum likelihood methods to estimate the copula parameters from observed data and generate synthetic data using the estimated copula model. Other packages provide sampling methods for copulae, but they are typically restricted to the bivariate case and the conditional simulation method (see, for example, <span class="citation" data-cites="baudin2017openturns">Baudin et al. (<a href="#ref-baudin2017openturns" role="doc-biblioref">2017</a>)</span>). Additionally, if the multivariate case is considered only Archimedean and elliptical copulae are under interest and those packages (see <span class="citation" data-cites="nicolas2022pycop">Nicolas (<a href="#ref-nicolas2022pycop" role="doc-biblioref">2022</a>)</span>) do not include the extreme value class in arbitrary dimensions <span class="math inline">d \geq 2</span>. In this paper, we propose to implement a wide range of copulae, including the extreme value class, in arbitrary fixed dimension <span class="math inline">d \geq 2</span>.</p>
<p>Through this paper we adopt the following notational conventions: all the indices will start at <span class="math inline">0</span> as in <span class="math inline">\textsf{Python}</span>. Consider <span class="math inline">(\Omega, \mathcal{A}, \mathbb{P})</span> a probability space and let <span class="math inline">\textbf{X} = (X_0, \dots, X_{d-1})</span> be a <span class="math inline">d</span>-dimensional random vector with values in <span class="math inline">(\mathbb{R}^d, \mathcal{B}(\mathbb{R}^d))</span>, with <span class="math inline">d \geq 2</span> and <span class="math inline">\mathcal{B}(\mathbb{R}^d)</span> the Borel <span class="math inline">\sigma</span>-algebra of <span class="math inline">\mathbb{R}^d</span>. This random vector has a joint distribution <span class="math inline">F</span> with copula <span class="math inline">C</span> and its margins are denoted by <span class="math inline">F_j(x) = \mathbb{P}\{X_j \leq x\}</span> for all <span class="math inline">x \in \mathbb{R}</span> and <span class="math inline">j \in \{0, \dots, d-1\}</span>. Denote by <span class="math inline">\textbf{U} = (U_0, \dots, U_{d-1})</span> a <span class="math inline">d</span> random vector with copula <span class="math inline">C</span> and uniform margins. All bold letters <span class="math inline">\textbf{x}</span> will denote a vector of <span class="math inline">\mathbb{R}^d</span>.</p>
<p>The <span class="math inline">\textsf{clayton}</span> package, whose Python code can be found in <a href="https://github.com/Aleboul/clayton">https://github.com/Aleboul/clayton</a>, uses object-oriented features of the Python language. The package contains classes for Archimedean, elliptical, and extreme value copulae. In <a href="#sec-classes" class="quarto-xref">Section 2</a>, we briefly describe the classes defined in the package. <a href="#sec-rng" class="quarto-xref">Section 3</a> presents methods for generating random vectors. In <a href="#sec-pairwise" class="quarto-xref">Section 4</a>, we apply the <span class="math inline">\textsf{clayton}</span> package to model pairwise dependence between maxima. <a href="#sec-discussion" class="quarto-xref">Section 5</a> discusses potential improvements to the package and provides concluding remarks. Sections from <a href="#sec-bv_arch" class="quarto-xref">Section 6.1</a> to <a href="#sec-mv_ellip" class="quarto-xref">Section 6.5</a> define and illustrate all the parametric copula models implemented in the package.</p>
</section>
<section id="sec-classes" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Classes</h1>
<div id="fig-diagram" class="quarto-figure quarto-figure-center quarto-float">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-diagram-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/diagram.png" class="img-fluid" />
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-diagram-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure 1: The figure shows a object diagram that structures the code. The <span class="math inline">\textbf{Multivariate}</span> class serves as the root and is used to instantiate all its child classes <span class="math inline">\textbf{Archimedean}</span>, <span class="math inline">\textbf{Extreme}</span>, <span class="math inline">\textbf{Gaussian}</span>, and <span class="math inline">\textbf{Student}</span> in red. The blue-colored classes correspond to various parametric copula models, and the green-colored classes represent examples of methods. Symbols <span class="math inline">\varphi, \varphi^\leftarrow, \dot{\varphi}</span> correspond to the generator function, its inverse, and its derivative, respectively, while <span class="math inline">A, \dot{A}</span> refer to the Pickands dependence function and its derivative.
</figcaption>
</figure>
</div>
<p>The architecture of the code is shown in <a href="#fig-diagram" class="quarto-xref">Figure 1</a>. At the third level of the architecture, we find important parametric models of Archimedean and extreme value copulae (depicted as blue in the figure). These parametric models contain methods such as the generator function <span class="math inline">\varphi</span> (see <a href="#sec-arch" class="quarto-xref">Section 2.1</a>) for Archimedean copulae and the Pickands dependence function <span class="math inline">A</span> (see <a href="#sec-extreme" class="quarto-xref">Section 2.2</a>) for extreme value copulae (depicted as green in the figure). We provide a brief overview of Archimedean copulae and some of their properties in high-dimensional spaces in <a href="#sec-arch" class="quarto-xref">Section 2.1</a>. A characterization of extreme value copulae is given in <a href="#sec-extreme" class="quarto-xref">Section 2.2</a>. The from <a href="#sec-bv_arch" class="quarto-xref">Section 6.1</a> to <a href="#sec-mv_ellip" class="quarto-xref">Section 6.5</a> define and illustrate all the copula models implemented in the package.</p>
<section id="sec-arch" class="level2" data-number="2.1">
<h2 data-number="2.1"><span class="header-section-number">2.1</span> The Archimedean class</h2>
<p>Let <span class="math inline">\varphi</span> be a generator that is a strictly decreasing, convex function from <span class="math inline">[0,1]</span> to <span class="math inline">[0, \infty]</span> such that <span class="math inline">\varphi(1) = 0</span> and <span class="math inline">\varphi(0) = \infty</span>. We denote the generalized inverse of <span class="math inline">\varphi</span> by <span class="math inline">\varphi^\leftarrow</span>. Consider the following equation:</p>
<p><span id="eq-arch_cop"><span class="math display">
    C(\textbf{u}) = \varphi^\leftarrow (\varphi(u_0)+ \dots + \varphi(u_{d-1})).
\tag{1}</span></span></p>
<p>If this relation holds and <span class="math inline">C</span> is a copula function, then <span class="math inline">C</span> is called an Archimedean copula. A necessary condition for <a href="#eq-arch_cop" class="quarto-xref">Equation 1</a> to be a copula is that the generator <span class="math inline">\varphi</span> is a <span class="math inline">d</span>-monotonic function, i.e., it is differentiable up to the order <span class="math inline">d</span> and its derivatives satisfy</p>
<p><span id="eq-dmono"><span class="math display">
  (-1)^k \left(\varphi\right)^{(k)}(x) \geq 0, \quad k \in \{1, \dots, d\}
\tag{2}</span></span></p>
<p>for <span class="math inline">x \in (0, \infty)</span> (see Corollary 2.1 of <span class="citation" data-cites="10.1214/07-AOS556">McNeil and Nešlehová (<a href="#ref-10.1214/07-AOS556" role="doc-biblioref">2009</a>)</span>). Note that <span class="math inline">d</span>-monotonic Archimedean inverse generators do not necessarily generate Archimedean copulae in dimensions higher than <span class="math inline">d</span> (see <span class="citation" data-cites="10.1214/07-AOS556">McNeil and Nešlehová (<a href="#ref-10.1214/07-AOS556" role="doc-biblioref">2009</a>)</span>). As a result, some Archimedean subclasses are only implemented for the bivariate case as they do not generate an Archimedean copula in higher dimensions. In the bivariate case, <a href="#eq-dmono" class="quarto-xref">Equation 2</a> can be interpreted as <span class="math inline">\varphi</span> being a convex function.</p>
<p>The <span class="math inline">\textsf{clayton}</span> package implements common one-parameter families of Archimedean copulae, such as the Clayton (<span class="citation" data-cites="10.2307/2335289">Clayton (<a href="#ref-10.2307/2335289" role="doc-biblioref">1978</a>)</span>), Gumbel (<span class="citation" data-cites="1960">Gumbel (<a href="#ref-1960" role="doc-biblioref">1960</a>)</span>), Joe (<span class="citation" data-cites="joe1997multivariate">Joe (<a href="#ref-joe1997multivariate" role="doc-biblioref">1997</a>)</span>), Frank (<span class="citation" data-cites="Frank1979">Frank (<a href="#ref-Frank1979" role="doc-biblioref">1979</a>)</span>), and AMH (<span class="citation" data-cites="ALI1978405">Ali, Mikhail, and Haq (<a href="#ref-ALI1978405" role="doc-biblioref">1978</a>)</span>) copulae for the multivariate case. It is worth noting that all Archimedean copulae are symmetric, and in dimensions 3 or higher, only positive associations are allowed. For the specific bivariate case, the package also implements other families, such as those numbered from 4.2.9 to 4.2.15 and 4.2.22 in Section 4.2 of <span class="citation" data-cites="nelsen2007introduction">Nelsen (<a href="#ref-nelsen2007introduction" role="doc-biblioref">2007</a>)</span>. Definitions and illustrations of these parametric copula models can be found in <a href="#sec-bv_arch" class="quarto-xref">Section 6.1</a> and <a href="#sec-mv_arch" class="quarto-xref">Section 6.3</a>.</p>
</section>
<section id="sec-extreme" class="level2" data-number="2.2">
<h2 data-number="2.2"><span class="header-section-number">2.2</span> The Extreme class</h2>
<p>Investigating the notion of copulae within the framework of multivariate extreme value theory leads to the extreme value copulae (see <span class="citation" data-cites="gudendorf2009extremevalue">Gudendorf and Segers (<a href="#ref-gudendorf2009extremevalue" role="doc-biblioref">2010</a>)</span> for an overview) defined as <span id="eq-evc"><span class="math display">
C(\textbf{u}) = \exp \left( - \ell(-\ln(u_0), \dots, -\ln(u_{d-1})) \right), \quad \textbf{u} \in (0,1]^d,
\tag{3}</span></span> where <span class="math inline">\ell: [0,\infty)^d \rightarrow [0,\infty)</span> the stable tail dependence function which is convex, homogeneous of order one, namely <span class="math inline">\ell(c\textbf{x}) = c \ell(\textbf{x})</span> for <span class="math inline">c &gt; 0</span> and satisfies <span class="math inline">\max(x_0,\dots,x_{d-1})  \leq \ell(x_0,\dots,x_{d-1}) \leq x_0+\dots+x_{d-1}, \forall \textbf{x} \in [0,\infty)^d</span>. Let <span class="math inline">\Delta^{d-1} = \{\textbf{w} \in [0,1]^d: w_0 + \dots + w_{d-1} = 1\}</span> be the unit simplex. The Pickands dependence function <span class="math inline">A: \Delta^{d-1} \rightarrow [1/d,1]</span> characterizes <span class="math inline">\ell</span> by its homogeneity, which is the restriction of <span class="math inline">\ell</span> to the unit simplex <span class="math inline">\Delta^{d-1}</span>: <span id="eq-tail_dependence_pickands"><span class="math display">
  \ell(x_0, \dots,x_{d-1}) = (x_0 + \dots + x_{d-1}) A(w_0, \dots, w_{d-1}), \quad w_j = \frac{x_j}{x_0 + \dots + x_{d-1}},
\tag{4}</span></span> for <span class="math inline">j \in \{1,\dots,d-1\}</span> and <span class="math inline">w_0 = 1 - w_1 - \dots - w_{d-1}</span> with <span class="math inline">\textbf{x} \in [0, \infty)^d \setminus \{\textbf{0}\}</span>. The Pickands dependence function characterizes the extremal dependence structure of an extreme value random vector and verifies <span class="math inline">\max\{w_0,\dots,w_{d-1}\} \leq A(w_0,\dots,w_{d-1}) \leq 1</span> where the lower bound corresponds to comonotonicity and the upper bound corresponds to independence. Estimating this function is an active area of research, with many compelling studies having been conducted on the topic (see, for example, <span class="citation" data-cites="bucher2011new">Bücher, Dette, and Volgushev (<a href="#ref-bucher2011new" role="doc-biblioref">2011</a>)</span>, <span class="citation" data-cites="GUDENDORF20123073">Gudendorf and Segers (<a href="#ref-GUDENDORF20123073" role="doc-biblioref">2012</a>)</span>).</p>
<p>From a practical point of view, the family of extreme value copulae is very rich and arises naturally as the limiting distribution of properly normalised componentwise maxima. Furthermore, it contains a rich variety of parametric models and allows asymmetric dependence, that is, for the bivariate case: <span class="math display">
  \exists (u_0,u_1) \in [0,1]^2, \quad C(u_0,u_1) \neq C(u_1,u_0).
</span></p>
<p>In the multivariate framework, the logistic copula (or Gumbel, see <span class="citation" data-cites="1960">Gumbel (<a href="#ref-1960" role="doc-biblioref">1960</a>)</span>), the asymmetric logistic copula (<span class="citation" data-cites="tawn1990">Tawn (<a href="#ref-tawn1990" role="doc-biblioref">1990</a>)</span>), the Hüsler and Reiss distribution (<span class="citation" data-cites="HUSLER1989283">Hüsler and Reiss (<a href="#ref-HUSLER1989283" role="doc-biblioref">1989</a>)</span>), the t-EV copula (<span class="citation" data-cites="Demarta_Mcneil">Demarta and McNeil (<a href="#ref-Demarta_Mcneil" role="doc-biblioref">2005</a>)</span>), Bilogistic model (<span class="citation" data-cites="Smith1990">Smith (<a href="#ref-Smith1990" role="doc-biblioref">1990</a>)</span>) are implemented. It’s worth noting that the logistic copula is the sole model that is both Archimedean and extreme value. The library includes bivariate extreme value copulae such as asymmetric negative logistic (<span class="citation" data-cites="Joe1990FamiliesOM">Joe (<a href="#ref-Joe1990FamiliesOM" role="doc-biblioref">1990</a>)</span>), asymmetric mixed (<span class="citation" data-cites="10.1093/biomet/75.3.397">Tawn (<a href="#ref-10.1093/biomet/75.3.397" role="doc-biblioref">1988</a>)</span>). The reader is again invited to read from <a href="#sec-bv_ext" class="quarto-xref">Section 6.2</a> to <a href="#sec-mv_ext" class="quarto-xref">Section 6.4</a> for precise definitions of these models.</p>
</section>
</section>
<section id="sec-rng" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Random number generator</h1>
<p>We propose a <span class="math inline">\textsf{Python}</span>-based implementation for generating random numbers from a wide variety of copulae. The <span class="math inline">\textsf{clayton}</span> package requires a few external libraries that are commonly used in scientific computing in <span class="math inline">\textsf{Python}</span>.</p>
<ul>
<li><code>numpy</code> version 1.6.1 or newer. This is the fundamental package for scientific computing, it contains linear algebra functions and matrix / vector objects (<span class="citation" data-cites="harris2020array">Harris et al. (<a href="#ref-harris2020array" role="doc-biblioref">2020</a>)</span>).</li>
<li><code>scipy</code> version 1.7.1 or newer. A library of open-source software for mathematics, science and engineering (<span class="citation" data-cites="virtanen2020scipy">Virtanen et al. (<a href="#ref-virtanen2020scipy" role="doc-biblioref">2020</a>)</span>).</li>
</ul>
<p>The <span class="math inline">\textsf{clayton}</span> package provides two methods for generating random vectors: <span class="math inline">\texttt{sample\_unimargin}</span> and <span class="math inline">\texttt{sample}</span>. The first method generates a sample where the margins are uniformly distributed on the unit interval <span class="math inline">[0,1]</span>, while the second method generates a sample from the chosen margins.</p>
<p>In <a href="#sec-biv_case" class="quarto-xref">Section 3.1</a>, we present an algorithm that uses the conditioning method to sample from a copula. This method is very general and can be used for any copula that is sufficiently smooth (see <a href="#eq-cond_sim" class="quarto-xref">Equation 5</a> and <a href="#eq-cond_dist_mv" class="quarto-xref">Equation 8</a> below). However, the practical infeasibility of the algorithm in dimensions higher than <span class="math inline">2</span> and the computational intensity of numerical inversion call for more efficient ways to sample in higher dimensions. The purpose of <a href="#sec-mv_case" class="quarto-xref">Section 3.2</a> is to present such methods and to provide details on the methods used in the <span class="math inline">\textsf{clayton}</span> package. In each section, we provide examples of code to illustrate how to instantiate a copula and how to sample with <span class="math inline">\textsf{clayton}</span>.</p>
<p>In the following sections, we will use <span class="math inline">\textsf{Python}</span> code that assumes that the following packages have been loaded:</p>
<div id="3a1bed2c" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode" id="cb1"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> clayton</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> clayton.rng <span class="im">import</span> base, evd, archimedean, monte_carlo</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm, expon</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>plt.style.use(<span class="st">&#39;qb-light.mplstyle&#39;</span>) <span class="co"># for fancy figures</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">10</span>)</span></code></pre></div>
</details>
</div>
<section id="sec-biv_case" class="level2" data-number="3.1">
<h2 data-number="3.1"><span class="header-section-number">3.1</span> The bivariate case</h2>
<p>In this subsection, we address the problem of generating a bivariate sample from a specified joint distribution with <span class="math inline">d=2</span>. Suppose that we want to sample a bivariate random vector <span class="math inline">\textbf{X}</span> with copula <span class="math inline">C</span>. In the case where the components are independent, the sampling procedure is straightforward: we can independently sample <span class="math inline">X_0</span> and <span class="math inline">X_1</span>. However, in the general case where the copula is not the independent copula, this approach is not applicable.</p>
<p>One solution to this problem is to use the conditioning method to sample from the copula. This method relies on the fact that given <span class="math inline">(U_0, U_1)</span> with copula <span class="math inline">C</span>, the conditonal law of <span class="math inline">U_1</span> given <span class="math inline">U_0</span> is written as:</p>
<p><span id="eq-cond_sim"><span class="math display">
  c_{u_0}(u_1) \triangleq \mathbb{P}\left\{ U_1 \leq u_1 | U_0 = u_0 \right\} = \frac{\partial C(u_0,u_1)}{\partial u_0}.
\tag{5}</span></span></p>
<p>This allows us to first sample <span class="math inline">U_0</span> from a uniform distribution on the unit interval, and then to use the copula to generate <span class="math inline">U_1</span> given <span class="math inline">U_0</span>. Finally, we can transform the resulting sample <span class="math inline">(U_0, U_1)</span> into the original space by applying the inverse marginal distributions <span class="math inline">F_0^{-1}</span> and <span class="math inline">F_1^{-1}</span> to <span class="math inline">U_0</span> and <span class="math inline">U_1</span> respectively. Thus, an algorithm for sampling bivariate copulae is given in <a href="#fig-alg_1" class="quarto-xref">Figure 2</a>. Algorithm in <a href="#fig-alg_1" class="quarto-xref">Figure 2</a> presents a procedure for generating a bivariate sample from a copula. The algorithm takes as input the length of the sample <span class="math inline">n</span>, as well as the parameters of the copula (<span class="math inline">\theta, \psi_1, \psi_2</span>). The output is a bivariate sample from the desired copula model, denoted <span class="math inline">\{(u_0^{(1)},u_1^{(1)}), \dots, (u_0^{(n)},u_1^{(n)})\}</span>. This algorithm is applicable as long as the copula has a first partial derivative with respect to its first component.</p>
<div id="fig-alg_1" class="quarto-figure quarto-figure-center quarto-float">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-alg_1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/alg_1.png" class="img-fluid" />
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-alg_1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure 2: Conditional sampling from copula
</figcaption>
</figure>
</div>
<p>For step 6 of the algorithm, we need to find <span class="math inline">u_1 \in [0,1]</span> such that <span class="math inline">c_{u_0}(u_1) - t_1 = 0</span> holds. This <span class="math inline">u_1</span> always exists because for every <span class="math inline">u \in ]0,1[</span>, we have <span class="math inline">0 \leq c_{u_0}(u) \leq 1</span>, and the function <span class="math inline">u \mapsto c_{u_0}(u)</span> is increasing (see Theorem 2.2.7 of <span class="citation" data-cites="nelsen2007introduction">Nelsen (<a href="#ref-nelsen2007introduction" role="doc-biblioref">2007</a>)</span> for a proof). This step can be solved using the function from the package. A sufficient condition for a copula to have a first partial derivative with respect to its first component in the Archimedean and extreme value cases is that the generator <span class="math inline">\varphi</span> and the Pickands dependence function <span class="math inline">A</span> are continuously differentiable on <span class="math inline">]0,1[</span>, respectively. In this case, the first partial derivatives of the copula are given by:</p>
<p><span id="eq-partial_deriv_arch"><span class="math display">
    \frac{\partial C}{\partial u_0}(u_0,u_1) = \frac{\varphi&#39;(u_0)}{\varphi&#39;(C(u_0,u_1))}, \quad (u_0,u_1) \in ]0,1[^2,
\tag{6}</span></span></p>
<p><span id="eq-partial_deriv_pick"><span class="math display">
    \frac{\partial C}{\partial u_0}(u_0,u_1) = \frac{\varphi&#39;(u_0)}{\varphi&#39;(C(u_0,u_1))}, \quad (u_0,u_1) \in ]0,1[^2,
\tag{7}</span></span></p>
<p>where <span class="math inline">t = \ln(u_1) / \ln(u_0u_1) \in (0,1)</span> and <span class="math inline">\mu(t) = A(t) - tA&#39;(t)</span>.</p>
<p>We now have all the necessary theoretical tools to give details on how the <span class="math inline">\textsf{clayton}</span> package is designed. The file <span class="math inline">\texttt{base.py}</span> contains the <span class="math inline">\textbf{Multivariate}</span> class and the <span class="math inline">\texttt{sample}</span> method to generate random numbers from <span class="math inline">\textbf{X}</span> with copula <span class="math inline">C</span>. To do so, we use the inversion method that is to sample from <span class="math inline">\textbf{U}</span> using algorithm in <a href="#fig-alg_1" class="quarto-xref">Figure 2</a> and we compose the corresponding uniform margins by <span class="math inline">F_j^\leftarrow</span>. indicates that the sole knowledge of <span class="math inline">A</span> and <span class="math inline">\varphi</span> and their respective derivatives are needed in order to perform the sixth step of algorithm in <a href="#fig-alg_1" class="quarto-xref">Figure 2</a>. For that purpose, <span class="math inline">\texttt{cond\_sim}</span> method located inside <span class="math inline">\textbf{Archimedean}</span> and <span class="math inline">\textbf{Extreme}</span> classes performs algorithm in <a href="#fig-alg_1" class="quarto-xref">Figure 2</a>. Then each child of the bivariate <span class="math inline">\textbf{Archimedean}</span> (resp. <span class="math inline">\textbf{Extreme}</span>) class is thus defined by its generator <span class="math inline">\varphi</span> (resp. <span class="math inline">A</span>), it’s derivative <span class="math inline">\varphi&#39;</span> (resp. <span class="math inline">A&#39;</span>) and it’s inverse <span class="math inline">\varphi^\leftarrow</span> as emphasized in green in <a href="#fig-diagram" class="quarto-xref">Figure 1</a>. Namely, we perform algorithm in <a href="#fig-alg_1" class="quarto-xref">Figure 2</a> for the <span class="math inline">\textbf{Archimedean}</span> subclasses <span class="math inline">\texttt{Frank}</span>, <span class="math inline">\texttt{AMH}</span>, <span class="math inline">\texttt{Clayton}</span> (when <span class="math inline">\theta &lt; 0</span> for the previous three), <span class="math inline">\texttt{Nelsen\_9}</span>, <span class="math inline">\texttt{Nelsen\_10}</span>, <span class="math inline">\texttt{Nelsen\_11}</span>, <span class="math inline">\texttt{Nelsen\_12}</span>, <span class="math inline">\texttt{Nelsen\_13}</span>, <span class="math inline">\texttt{Nelsen\_14}</span>, <span class="math inline">\texttt{Nelsen\_15}</span> and <span class="math inline">\texttt{Nelsen\_22}</span>. For the <span class="math inline">\textbf{Extreme}</span> class, such algorithm is performed for the <span class="math inline">\texttt{AsyNegLog}</span> and <span class="math inline">\texttt{AsyMix}</span>. For other models, faster algorithms are known and thus implemented, we refer to <a href="#sec-mv_case" class="quarto-xref">Section 3.2</a> for details.</p>
<p>The following code illustrates the random vector generation for a bivariate Archimedean copula. By defining the parameter of the copula and the sample’s length, the constructor for this copula is available and can be called using the <span class="math inline">\texttt{Clayton}</span> method, such as:</p>
<div id="8f46c0c2" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode" id="cb2"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>  n_samples, theta <span class="op">=</span> <span class="dv">1024</span>, <span class="op">-</span><span class="fl">0.5</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  copula <span class="op">=</span> archimedean.Clayton(theta<span class="op">=</span>theta, n_samples<span class="op">=</span>n_samples)</span></code></pre></div>
</details>
</div>
<p>To obtain a sample with uniform margins and a Clayton copula, we can use the <span class="math inline">\texttt{sample\_unimargin}</span> method, as follows:</p>
<div id="820ac53f" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode" id="cb3"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>  sample <span class="op">=</span> copula.sample_unimargin()</span></code></pre></div>
</details>
</div>
<p>Here, the <span class="math inline">\texttt{sample}</span> object is a <span class="math inline">\textsf{numpy}</span> array with <span class="math inline">2</span> columns and <span class="math inline">1024</span> rows, where each row contains a realization from a Clayton copula (see below)</p>
<div id="0fbc623c" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode" id="cb4"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>  fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>  ax.scatter(sample[:,<span class="dv">0</span>], sample[:,<span class="dv">1</span>],</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>             edgecolors<span class="op">=</span><span class="st">&#39;#6F6F6F&#39;</span>, color<span class="op">=</span><span class="st">&#39;#C5C5C5&#39;</span>, s<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>  ax.set_xlabel(<span class="vs">r&#39;$u_0$&#39;</span>)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>  ax.set_ylabel(<span class="vs">r&#39;$u_1$&#39;</span>)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>  plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img src="published-202301-boulin-clayton_files/figure-html/cell-5-output-1.svg" class="img-fluid" /></p>
</figure>
</div>
</div>
</div>
</section>
<section id="sec-mv_case" class="level2" data-number="3.2">
<h2 data-number="3.2"><span class="header-section-number">3.2</span> The multivariate case</h2>
<p>We will now address the generation of multivariate Archimedean and Extreme value copulae proposed in the Clayton package. In the multivariate case, the link between partial derivatives and the conditional law remains. Indeed, let <span class="math inline">(U_0, \dots, U_{d-1})</span> be a <span class="math inline">d</span>-dimensional random vector with uniform margins and copula <span class="math inline">C</span>. The conditional distribution of <span class="math inline">U_k</span> given the values of <span class="math inline">U_0, \dots, U_{k-1}</span> is</p>
<p><span id="eq-cond_dist_mv"><span class="math display">
  \mathbb{P}\left\{ U_k \leq u_k | U_0 = u_0, \dots, U_{k-1} = u_{k-1} \right\} = \frac{\partial^{k-1} C(u_0, \dots, u_k,1,\dots,1)/\partial u_0 \dots \partial u_{k-1}}{\partial^{k-1} C(u_0, \dots, u_{k-1},1,\dots,1) / \partial u_0 \dots \partial u_{k-1}}.
\tag{8}</span></span></p>
<p>for <span class="math inline">k \in {1,\dots, d-1}</span>. The conditional simulation algorithm may be written as follows.</p>
<ol type="1">
<li>Generate <span class="math inline">d</span> independent uniform random on <span class="math inline">[0,1]</span> variates <span class="math inline">v_0, \dots, v_{d-1}</span>.</li>
<li>Set <span class="math inline">u_0 = v_0</span>.</li>
<li>For <span class="math inline">k = 1, \dots, d-1</span>, evaluate the inverse of the conditional distribution given by at <span class="math inline">v_k</span>, to generate <span class="math inline">u_k</span>.</li>
</ol>
<p>Nevertheless, the evaluation of the inverse conditional distribution becomes increasingly complicated as the dimension <span class="math inline">d</span> increases. Furthermore, it can be difficult for some models to derive a closed form of <a href="#eq-cond_dist_mv" class="quarto-xref">Equation 8</a> that makes it impossible to implement it in a general algorithm with only the dimension <span class="math inline">d</span> as an input. For multivariate Archimedean copulae, <span class="citation" data-cites="10.1214/07-AOS556">McNeil and Nešlehová (<a href="#ref-10.1214/07-AOS556" role="doc-biblioref">2009</a>)</span> give a method to generate a random vector from the <span class="math inline">d</span>-dimensional copula <span class="math inline">C</span> with generator <span class="math inline">\varphi</span> (see Section 5.2 of <span class="citation" data-cites="10.1214/07-AOS556">McNeil and Nešlehová (<a href="#ref-10.1214/07-AOS556" role="doc-biblioref">2009</a>)</span>). A stochastic representation for Archimedean copulae generated by a <span class="math inline">d</span>-monotone generator is given by</p>
<p><span id="eq-radial"><span class="math display">
\textbf{U} = \left( \varphi^\leftarrow(R S_1), \dots, \varphi^\leftarrow(RS_d) \right) \sim C,
\tag{9}</span></span></p>
<p>where <span class="math inline">R \sim F_R</span>, the radial distribution which is independent of <span class="math inline">S</span> and <span class="math inline">S</span> is distributed uniformly in the unit simplex <span class="math inline">\Delta^{d-1}</span>. One challenging aspect of this algorithm is to have an accurate evaluation of the radial distribution of the Archimedean copula and thus to numerically inverse this distribution. The associated radial distribution for the <span class="math inline">\textsf{Clayton}</span> copula is given in Example 3.3 <span class="citation" data-cites="10.1214/07-AOS556">McNeil and Nešlehová (<a href="#ref-10.1214/07-AOS556" role="doc-biblioref">2009</a>)</span> while those of the <span class="math inline">\textsf{Joe}</span>, <span class="math inline">\textsf{AMH}</span>, <span class="math inline">\textsf{Gumbel}</span> and <span class="math inline">\textsf{Frank}</span> copulae are given in <span class="citation" data-cites="hofert2012likelihood">Hofert, Mächler, and McNeil (<a href="#ref-hofert2012likelihood" role="doc-biblioref">2012</a>)</span>. In general, one can use numerical inversion algorithms for computing the inverse of the radial distribution, however it will lead to spurious numerical errors. Other algorithms exist when the generator is known to be the Laplace-Stieltjes transform, denoted as <span class="math inline">\mathcal{LS}</span>, of some positive random variables (see <span class="citation" data-cites="10.2307/2289314">Marshall and Olkin (<a href="#ref-10.2307/2289314" role="doc-biblioref">1988</a>)</span>, <span class="citation" data-cites="frees1998understanding">Frees and Valdez (<a href="#ref-frees1998understanding" role="doc-biblioref">1998</a>)</span>). This positive random variable is often referenced as the frailty distribution. In this framework, Archimedean copulae allow for the stochastic representation</p>
<p><span class="math display">
  \textbf{U} = \left( \varphi^\leftarrow (E_1/V), \dots, \varphi^\leftarrow(E_d /V)\right) \sim C,
</span></p>
<p>with <span class="math inline">V \sim F = \mathcal{LS}^{-1}[\varphi^\leftarrow]</span> the frailty and <span class="math inline">E_1, \dots, E_d</span> are distributed i.i.d. according to a standard exponential and independent of <span class="math inline">V</span>. Algorithm in <a href="#fig-alg_2" class="quarto-xref">Figure 3</a> presents a procedure for generating a multivariate sample from an Archimedean copula where the frailty distribution is known. The algorithm takes as an input the length of the sample <span class="math inline">n</span>, as well as the parameter of the copula <span class="math inline">\theta</span>. The output is a <span class="math inline">d</span>-variate sample from the desired copula model, denoted <span class="math inline">\{(u_0^{(1)}, \dots, u_{d-1}^{(1)}), \dots, (u_0^{(n)},\dots,u_{d-1}^{(n)})\}</span>.</p>
<div id="fig-alg_2" class="quarto-figure quarto-figure-center quarto-float">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-alg_2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/alg_2.png" class="img-fluid" />
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-alg_2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure 3: Sampling from Archimedean copula using frailty distribution
</figcaption>
</figure>
</div>
<p>In this framework, we define <span class="math inline">\texttt{\_frailty\_sim}</span> method defined inside the <span class="math inline">\textbf{Archimedean}</span> class which performs algorithm in <a href="#fig-alg_2" class="quarto-xref">Figure 3</a>. Then, each Archimedean copula is defined by the generator <span class="math inline">\varphi</span>, it’s inverse <span class="math inline">\varphi^\leftarrow</span> and the frailty distribution denoted as <span class="math inline">\mathcal{LS}^{-1}[\varphi^\leftarrow]</span> as long as we know the frailty. This is the case for <span class="math inline">\texttt{Joe}</span>, <span class="math inline">\texttt{Clayton}</span>, <span class="math inline">\texttt{AMH}</span> or <span class="math inline">\texttt{Frank}</span>.</p>
<p>For the extreme value case, algorithms have been proposed, as in <span class="citation" data-cites="stephenson2003simulating">A. Stephenson (<a href="#ref-stephenson2003simulating" role="doc-biblioref">2003</a>)</span> (see Algorithms 2.1 and 2.2), who proposes sampling methods for the Gumbel and the asymmetric logistic model. These algorithms are implemented in the <span class="math inline">\textsf{clayton}</span> package. Note that these algorithms are model-specific, thus the <span class="math inline">\texttt{sample\_unimargin}</span> method is exceptionally located in the corresponding child of the multivariate <span class="math inline">\textbf{Extreme}</span> class. Another procedure designed by <span class="citation" data-cites="10.1093/biomet/asw008">Dombry, Engelke, and Oesting (<a href="#ref-10.1093/biomet/asw008" role="doc-biblioref">2016</a>)</span> to sample from multivariate extreme value models using extremal functions (see Algorithm 2 in <span class="citation" data-cites="10.1093/biomet/asw008">Dombry, Engelke, and Oesting (<a href="#ref-10.1093/biomet/asw008" role="doc-biblioref">2016</a>)</span>) is also of prime interest. For the implemented models using this algorithm, namely <span class="math inline">\textbf{Hüsler-Reiss}</span>, <span class="math inline">\textbf{tEV}</span>, <span class="math inline">\textbf{Bilogistic}</span> and <span class="math inline">\textbf{Dirichlet}</span> models, a method called <span class="math inline">\texttt{\_rextfunc}</span> is located inside each classes which allows to generate an observation from the according law of the extremal function.</p>
<p>Samples from the Gaussian and Student copula are directly given by Algorithm 5.9 and 5.10 respectively of <span class="citation" data-cites="quantrisk">Alexander J. McNeil (<a href="#ref-quantrisk" role="doc-biblioref">2005</a>)</span>. As each algorithm is model specific, the <span class="math inline">\texttt{sample\_unimargin}</span> method is located inside the <span class="math inline">\textbf{Gaussian}</span> and <span class="math inline">\textbf{Student}</span> classes.</p>
<p>We present how to construct a multivariate Archimedean copula and to generate random vectors from this model. Introducing the parameters of the copula, we appeal the following lines to construct our copula object:</p>
<div id="cee9eb8f" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode" id="cb5"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>d, theta, n_samples <span class="op">=</span> <span class="dv">3</span>, <span class="fl">2.0</span>, <span class="dv">1024</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>copula <span class="op">=</span> archimedean.Clayton(theta<span class="op">=</span>theta, n_samples<span class="op">=</span>n_samples, dim<span class="op">=</span>d)</span></code></pre></div>
</details>
</div>
<p>We now call the <span class="math inline">\texttt{sample\_unimargin}</span> method to obtain randomly generated vectors.</p>
<div id="03d7f2b1" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode" id="cb6"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>sample <span class="op">=</span> copula.sample_unimargin()</span></code></pre></div>
</details>
</div>
<p>We thus represent in three dimensions these realizations below.</p>
<div id="fab14c1a" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode" id="cb7"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>  fig <span class="op">=</span> plt.figure()</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>  ax <span class="op">=</span> fig.add_subplot(<span class="dv">111</span>, projection <span class="op">=</span> <span class="st">&#39;3d&#39;</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>  ax.scatter3D(sample[:,<span class="dv">0</span>], sample[:,<span class="dv">1</span>], sample[:,<span class="dv">2</span>], s<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>               edgecolors<span class="op">=</span><span class="st">&#39;#6F6F6F&#39;</span>, color<span class="op">=</span><span class="st">&#39;#C5C5C5&#39;</span>)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>  ax.set_xlabel(<span class="vs">r&#39;$u_0$&#39;</span>)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>  ax.set_ylabel(<span class="vs">r&#39;$u_1$&#39;</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>  ax.set_zlabel(<span class="vs">r&#39;$u_2$&#39;</span>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>  plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img src="published-202301-boulin-clayton_files/figure-html/cell-8-output-1.svg" class="img-fluid" /></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="sec-pairwise" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Case study : Modeling pairwise dependence between spatial maximas with missing data</h1>
<p>We now proceed to a case study where we use our package to assess, under a finite sample framework, the asymptotic properties of an estimator of the <span class="math inline">\lambda</span>-madogram when data are completely missing at random (MCAR). This case study comes from numerical results of <span class="citation" data-cites="boulin2021non">Boulin et al. (<a href="#ref-boulin2021non" role="doc-biblioref">2022</a>)</span>. The <span class="math inline">\lambda</span>-madogram belongs to a family of estimators, namely the madogram, which is of prime interest in environmental sciences, as it is designed to model pairwise dependence between maxima in space, see, e.g., <span class="citation" data-cites="bernard:hal-03207469">Bernard et al. (<a href="#ref-bernard:hal-03207469" role="doc-biblioref">2013</a>)</span>, <span class="citation" data-cites="BADOR201517">Bador et al. (<a href="#ref-BADOR201517" role="doc-biblioref">2015</a>)</span>, <span class="citation" data-cites="saunders">Saunders, Stephenson, and Karoly (<a href="#ref-saunders" role="doc-biblioref">2021</a>)</span> where the madogram was used as a dissimilarity measure to perform clustering. Where in several fields, for example econometrics (<span class="citation" data-cites="woolridge2007">Wooldridge (<a href="#ref-woolridge2007" role="doc-biblioref">2007</a>)</span>) or survey theory (<span class="citation" data-cites="chauvet2015">Boistard, Chauvet, and Haziza (<a href="#ref-chauvet2015" role="doc-biblioref">2016</a>)</span>), the MCAR hypothesis appears to be a strong hypothesis, this hypothesis is more realistic in environmental research as the missingness of one observation is usually due to instruments, communication and processing errors that may be reasonably supposed independent of the quantity of interest. In <a href="#sec-background" class="quarto-xref">Section 4.1</a>, we define objects and properties of interest while in <a href="#sec-num" class="quarto-xref">Section 4.2</a> we describe a detailed tutorial in <span class="math inline">\textsf{python}</span> and with <span class="math inline">\textsf{clayton}</span> package to compare the asymptotic variance with an empirical counterpart of the <span class="math inline">\lambda</span>-madogram with <span class="math inline">\lambda = 0.5</span>.</p>
<section id="sec-background" class="level2" data-number="4.1">
<h2 data-number="4.1"><span class="header-section-number">4.1</span> Background</h2>
<p>It was emphasized that the possible dependence between maxima can be described with the extreme value copula. This function is completely characterized by the Pickands dependence function (see <a href="#eq-tail_dependence_pickands" class="quarto-xref">Equation 4</a>) where the latter is equivalent to the <span class="math inline">\lambda</span>-madogram introduced by <span class="citation" data-cites="naveau:hal-00312758">Naveau et al. (<a href="#ref-naveau:hal-00312758" role="doc-biblioref">2009</a>)</span> and defined as</p>
<p><span id="eq-lmbd_mado"><span class="math display">
  \nu(\lambda) = \mathbb{E}\left[ \left|\{F_0(X_0)\}^{1/\lambda} - \{F_1(X_1)\}^{1/(1-\lambda)} \right|\right],
\tag{10}</span></span></p>
<p>with <span class="math inline">\lambda \in (0,1)</span>, and if <span class="math inline">\lambda = 0</span> and <span class="math inline">0&lt;u&lt;1</span>, then <span class="math inline">u^{1/\lambda} = 0</span> by convention. The <span class="math inline">\lambda</span>-madogram took its inspiration from the extensively used geostatistics tool, the variogram (see Chapter 1.3 of <span class="citation" data-cites="alma991005826659705596">Gaetan and Guyon (<a href="#ref-alma991005826659705596" role="doc-biblioref">2008</a>)</span> for a definition and some classical properties). The <span class="math inline">\lambda</span>-madogram can be interpreted as the <span class="math inline">L_1</span>-distance between the uniform margins elevated to the inverse of the corresponding weights <span class="math inline">\lambda</span> and <span class="math inline">1-\lambda</span>. This quantity describes the dependence structure between extremes by its relation with the Pickands dependence function. If we suppose that <span class="math inline">C</span> is an extreme value copula as in , we have</p>
<p><span id="eq-pickands_mado"><span class="math display">
  A(\lambda) = \frac{\nu(\lambda) + c(\lambda)}{1-\nu(\lambda) - c(\lambda)},
\tag{11}</span></span></p>
<p>with <span class="math inline">c(\lambda) = 2^{-1} (\lambda / (1-\lambda) + (1-\lambda)/\lambda)</span> (see Proposition 3 of <span class="citation" data-cites="MARCON20171">Marcon et al. (<a href="#ref-MARCON20171" role="doc-biblioref">2017</a>)</span> for details).</p>
<p>We consider independent and identically distributed i.i.d. copies <span class="math inline">\textbf{X}_1, \dots, \textbf{X}_n</span> of <span class="math inline">\textbf{X}</span>. In presence of missing data, we do not observe a complete vector <span class="math inline">\textbf{X}_i</span> for <span class="math inline">i \in \{1,\dots,n\}</span>. We introduce <span class="math inline">\textbf{I}_i \in \{0,1\}^2</span> which satisfies, <span class="math inline">\forall j \in \{0,1\}</span>, if <span class="math inline">X_{i,j}</span> is not observed then <span class="math inline">I_{i,j} = 0</span>. To formalize incomplete observations, we introduce the incomplete vector <span class="math inline">\tilde{\textbf{X}}_i</span> with values in the product space <span class="math inline">\bigotimes_{j=1}^2 (\mathbb{R} \cup \{\textsf{NA}\})</span> such as</p>
<p><span class="math display">
  \tilde{X}_{i,j} = X_{i,j} I_{i,j} + \textsf{NA} (1-I_{i,j}), \quad i \in \{1,\dots,n\}, \, j \in \{0,\dots, d-1\}.
</span></p>
<p>We thus suppose that we observe a <span class="math inline">4</span>-tuple such as</p>
<p><span id="eq-missing_2"><span class="math display">
  (\textbf{I}_i, \tilde{\textbf{X}}_i), \quad i \in \{1,\dots,n\},
\tag{12}</span></span></p>
<p>i.e. at each <span class="math inline">i \in \{1,\dots,n\}</span>, several entries may be missing. We also suppose that for all <span class="math inline">i \in \{1, \dots,n \}</span>, <span class="math inline">\textbf{I}_{i}</span> are i.i.d copies from <span class="math inline">\textbf{I} = (I_0, I_1)</span> where <span class="math inline">I_j</span> is distributed according to a Bernoulli random variable <span class="math inline">\mathcal{B}(p_j)</span> with <span class="math inline">p_j = \mathbb{P}(I_j = 1)</span> for <span class="math inline">j \in \{0,1\}</span>. We denote by <span class="math inline">p</span> the probability of observing completely a realization from <span class="math inline">\textbf{X}</span>, that is <span class="math inline">p = \mathbb{P}(I_0=1, I_1 = 1)</span>. In <span class="citation" data-cites="boulin2021non">Boulin et al. (<a href="#ref-boulin2021non" role="doc-biblioref">2022</a>)</span>, hybrid and corrected estimators, respectively denoted as <span class="math inline">\hat{\nu}_n^{\mathcal{H}}</span> and <span class="math inline">\hat{\nu}_n^{\mathcal{H*}}</span>, are proposed to estimate nonparametrically the <span class="math inline">\lambda</span>-madogram in presence of missing data completely at random. Furthermore, a closed expression of their asymptotic variances for <span class="math inline">\lambda \in ]0,1[</span> is also given. This result is summarized in the following proposition.</p>
<div id="thm-line" class="theorem">
<p><span class="theorem-title"><strong>Theorem 1 (<span class="citation" data-cites="boulin2021non">Boulin et al. (<a href="#ref-boulin2021non" role="doc-biblioref">2022</a>)</span>)</strong></span> Let <span class="math inline">(\textbf{I}_i, \tilde{\textbf{X}_i})_{i=1}^n</span> be a samble given by <a href="#eq-missing_2" class="quarto-xref">Equation 12</a>. For <span class="math inline">\lambda \in ]0,1[</span>, if <span class="math inline">C</span> is an extreme value copula with Pickands dependence function <span class="math inline">A</span>, we have as <span class="math inline">n \rightarrow \infty</span> <span class="math display">\begin{align*}
    &amp;\sqrt{n} \left(\hat{\nu}_n^{\mathcal{H}}(\lambda) - \nu( \lambda)\right) \overset{d}{\rightarrow} \mathcal{N}\left(0, \mathcal{S}^{\mathcal{H}}(p_1,p_2,p, \lambda)\right), \\
    &amp;\sqrt{n} \left(\hat{\nu}_n^{\mathcal{H}*}(\lambda) - \nu( \lambda)\right) \overset{d}{\rightarrow} \mathcal{N}\left(0, \mathcal{S}^{\mathcal{H}*}(p_1,p_2,p, \lambda)\right),
\end{align*}</span></p>
<p>where <span class="math inline">\mathcal{S}^{\mathcal{H}}(p_1,p_2,p, \lambda)</span> and <span class="math inline">\mathcal{S}^{\mathcal{H}*}(p_1,p_2,p, \lambda)</span> are the asymptoptic variances of the random variables.</p>
</div>
</section>
<section id="sec-num" class="level2" data-number="4.2">
<h2 data-number="4.2"><span class="header-section-number">4.2</span> Numerical results</h2>
<p>Benefiting from generating data with <span class="math inline">\textsf{clayton}</span> we are thus able, with Monte Carlo simulation, to assess theoretical results given by <a href="#thm-line" class="quarto-xref">Theorem 1</a> in a finite sample setting. For that purpose, we implement a <span class="math inline">\textsf{MonteCarlo}</span> class (in <span class="math inline">\texttt{monte\_carlo.py}</span> file) which contains some methods to perform some Monte Carlo iterations for a given extreme value copula. Now, we set up parameters to sample our bivariate dataset. For this subsection, we choose the asymmetric negative logistic model (see <a href="#sec-bv_ext" class="quarto-xref">Section 6.2</a> for a definition) with parameters <span class="math inline">\theta = 10, \psi_1 = 0.1, \psi_2 = 1.0</span> and we define the following function:</p>
<div id="65b65928" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode" id="cb8"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> gauss_function(x, x0, sigma):</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>      <span class="cf">return</span> (np.sqrt(<span class="fl">1.</span> <span class="op">/</span> (<span class="dv">2</span><span class="op">*</span>np.pi <span class="op">*</span> sigma<span class="op">**</span><span class="dv">2</span>)) <span class="op">*</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>              np.exp(<span class="op">-</span>(x <span class="op">-</span> x0) <span class="op">**</span> <span class="dv">2</span> <span class="op">/</span> (<span class="dv">2</span> <span class="op">*</span> sigma<span class="op">**</span><span class="dv">2</span>)))</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>  n_samples <span class="op">=</span> <span class="dv">512</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>  theta, psi1, psi2 <span class="op">=</span> <span class="dv">10</span>, <span class="fl">0.1</span>, <span class="fl">1.0</span></span></code></pre></div>
</details>
</div>
<p>We choose the standard normal and exponential as margins. To simulate this sample, the following lines should be typed:</p>
<div id="f5be635c" class="cell" data-execution_count="9">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode" id="cb9"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>  copula <span class="op">=</span> evd.AsyNegLog(theta<span class="op">=</span>theta, psi1<span class="op">=</span>psi1,</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>                         psi2<span class="op">=</span>psi2, n_samples<span class="op">=</span>n_samples)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>  sample <span class="op">=</span> copula.sample(inv_cdf<span class="op">=</span>[norm.ppf, expon.ppf])</span></code></pre></div>
</details>
</div>
<p>The <span class="math inline">1024 \times 2</span> array <span class="math inline">\texttt{sample}</span> contains <span class="math inline">1024</span> realization of the <span class="math inline">\textbf{asymmetric negative logistic}</span> model where the first column is distributed according to a standard normal random variable and the second column as a standard exponential. This distribution is depicted below. To obtain it, one needs the following lines of command:</p>
<div id="9219bf02" class="cell" data-execution_count="10">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode" id="cb10"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>  fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>  ax.scatter(sample[:,<span class="dv">0</span>], sample[:,<span class="dv">1</span>],</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>             edgecolors<span class="op">=</span><span class="st">&quot;#6F6F6F&quot;</span>, color<span class="op">=</span><span class="st">&quot;#C5C5C5&quot;</span>, s<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>  ax.set_xlabel(<span class="vs">r&#39;$x_0$&#39;</span>)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>  ax.set_ylabel(<span class="vs">r&#39;$x_1$&#39;</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>  plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img src="published-202301-boulin-clayton_files/figure-html/cell-11-output-1.svg" class="img-fluid" /></p>
</figure>
</div>
</div>
</div>
<p>Before going into further details, we will present the missing mechanism. Let <span class="math inline">V_0</span> and <span class="math inline">V_1</span> be random variables uniformly distributed under the <span class="math inline">]0,1[</span> segment with copula <span class="math inline">C_{(V_0,V_1)}</span>. We set <span class="math inline">I_0 = 1\{{V_0 \leq p_0}\}</span> and <span class="math inline">I_1 = 1\{{V_1 \leq p_1}\}</span>. It is thus immediate that <span class="math inline">I_0 \sim \mathcal{B}(p_0)</span> and <span class="math inline">I_1 \sim \mathcal{B}(p_1)</span> and <span class="math inline">p \triangleq \mathbb{P}\{I_0 = 1, I_1 =1 \} = C_{(V_0,V_1)}(p_0, p_1)</span>. For our illustration, we will take <span class="math inline">C_{(V_0,V_1)}</span> as a copula with parameter <span class="math inline">\theta = 2.0</span> (we refer to <a href="#sec-bv_arch" class="quarto-xref">Section 6.1</a> for a definition of this copula). For this copula, it is more likely to observe a realization <span class="math inline">v_0 \geq 0.8</span> from <span class="math inline">V_0</span> if <span class="math inline">v_1 \geq 0.8</span> from <span class="math inline">V_1</span>. If we observe <span class="math inline">v_1 &lt; 0.8</span>, the realization <span class="math inline">v_0</span> is close to being independent of <span class="math inline">v_1</span>. In climate studies, extreme events could damage the recording instrument in the surrounding regions where they occur, thus the missingness of one variable may depend on others. We initialize the copula <span class="math inline">C_{(V_0,V_1)}</span> with the following line:</p>
<div id="3ab73c85" class="cell" data-execution_count="11">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode" id="cb11"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>  copula_miss <span class="op">=</span> archimedean.Joe(theta<span class="op">=</span><span class="fl">2.0</span>, n_samples<span class="op">=</span>n_samples)</span></code></pre></div>
</details>
</div>
<p>For a given <span class="math inline">\lambda \in ]0,1[</span>, we now want to estimate a <span class="math inline">\lambda</span>-madogram with a sample from the asymmetric negative logistic model, where some observations are missing due to the missing mechanism described above. We will repeat this step several times to compute an empirical counterpart of the asymptotic variance. The object has been designed for this purpose: we specify the number of iterations <span class="math inline">n_{iter}</span> (take <span class="math inline">n_{iter} = 1024</span>), the chosen extreme value copula (asymmetric negative logistic model), the missing mechanism (described by <span class="math inline">C_{(V_0,V_1)}</span> and <span class="math inline">p_0 = p_1 = 0.9</span>), and <span class="math inline">\lambda</span> (noted <span class="math inline">\texttt{w}</span>). We can write the following lines of code:</p>
<div id="193ff8e7" class="cell" data-execution_count="12">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode" id="cb12"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>  u <span class="op">=</span> np.array([<span class="fl">0.9</span>, <span class="fl">0.9</span>])</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>  n_iter, P, w <span class="op">=</span> <span class="dv">256</span>, [[u[<span class="dv">0</span>], copula_miss._c(</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>      u)], [copula_miss._c(u), u[<span class="dv">1</span>]]], np.array([<span class="fl">0.5</span>,<span class="fl">0.5</span>])</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>  monte <span class="op">=</span> monte_carlo.MonteCarlo(n_iter<span class="op">=</span>n_iter, n_samples<span class="op">=</span>n_samples,</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>                                 copula<span class="op">=</span>copula, copula_miss<span class="op">=</span>copula_miss,</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>                                 weight<span class="op">=</span>w, matp<span class="op">=</span>P)</span></code></pre></div>
</details>
</div>
<p>The <span class="math inline">\texttt{MonteCarlo}</span> object is thus initialized with all parameters needed. We may use the <span class="math inline">\texttt{simu}</span> method to generate a <span class="math inline">\texttt{DataFrame}</span> (a <span class="math inline">\texttt{pandas}</span> object) composed out <span class="math inline">1024</span> rows and <span class="math inline">3</span> columns. Each row contains an estimate of the <span class="math inline">\lambda</span>-madogram, <span class="math inline">\hat{\nu}_n^{\mathcal{H}*}</span> in <a href="#thm-line" class="quarto-xref">Theorem 1</a> (<span class="math inline">\texttt{var\_mado}</span>), the sample length <span class="math inline">n</span> (<span class="math inline">\texttt{n}</span>) and the normalized estimation error (<span class="math inline">\texttt{scaled}</span>). We thus call the <span class="math inline">\texttt{simu}</span> method.</p>
<div id="9c788d31" class="cell" data-execution_count="13">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode" id="cb13"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>  df_wmado <span class="op">=</span> monte.finite_sample(inv_cdf<span class="op">=</span>[norm.ppf, expon.ppf], corr<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(df_wmado.head())</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>      wmado      n    scaled
0  0.148163  512.0 -0.128602
1  0.149337  512.0 -0.102024
2  0.153788  512.0 -0.001322
3  0.153169  512.0 -0.015324
4  0.155756  512.0  0.043209</code></pre>
</div>
</div>
<p>The argument <span class="math inline">\texttt{corr=True}</span> specifies that we compute the corrected estimator, <span class="math inline">\hat{\nu}_n^{\mathcal{H}*}</span> in <a href="#thm-line" class="quarto-xref">Theorem 1</a>. Now, using the <span class="math inline">\texttt{var\_mado}</span> method defined inside in the <strong>Extreme</strong> class, we obtain the asymptotic variance for the given model and parameters from the missing mechanism. We obtain this quantity as follows</p>
<div id="f9091ec9" class="cell" data-execution_count="14">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode" id="cb15"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>  var_mado <span class="op">=</span> copula.var_mado(w, jointp<span class="op">=</span>copula_miss._c(u), matp<span class="op">=</span>P, corr<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(var_mado)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(df_wmado[<span class="st">&#39;scaled&#39;</span>].var())</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>0.015417245591834503
0.01370549107120327</code></pre>
</div>
</div>
<p>We propose here to check numerically the asymptotic normality with variance <span class="math inline">\mathcal{S}^{\mathcal{H}*}</span> of the normalized estimation error of the corrected estimator. We have all data in hand and the asymptotic variance was computed by lines above. We thus write:</p>
<div id="a558946d" class="cell" data-execution_count="15">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode" id="cb17"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>    sigma <span class="op">=</span> np.sqrt(var_mado)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> np.linspace(<span class="bu">min</span>(df_wmado[<span class="st">&#39;scaled&#39;</span>]), <span class="bu">max</span>(df_wmado[<span class="st">&#39;scaled&#39;</span>]), <span class="dv">1000</span>)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    gauss <span class="op">=</span> gauss_function(x, <span class="dv">0</span>, sigma)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    sns.displot(data<span class="op">=</span>df_wmado, x<span class="op">=</span><span class="st">&quot;scaled&quot;</span>, color<span class="op">=</span><span class="st">&#39;#C5C5C5&#39;</span>,</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>                kind<span class="op">=</span><span class="st">&#39;hist&#39;</span>, stat<span class="op">=</span><span class="st">&#39;density&#39;</span>, common_norm<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>                alpha<span class="op">=</span><span class="fl">0.5</span>, fill<span class="op">=</span><span class="va">True</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>, bins<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>    plt.plot(x,gauss, color<span class="op">=</span><span class="st">&#39;#6F6F6F&#39;</span>)</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img src="published-202301-boulin-clayton_files/figure-html/cell-16-output-1.svg" class="img-fluid" /></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="sec-discussion" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Discussion</h1>
<section id="comparison-of-textsfclayton-with-textsfr-packages" class="level2" data-number="5.1">
<h2 data-number="5.1"><span class="header-section-number">5.1</span> Comparison of <span class="math inline">\textsf{clayton}</span> with <span class="math inline">\textsf{R}</span> packages</h2>
<p>To compare to existing packages in <span class="math inline">\textsf{R}</span>, we consider the <span class="math inline">\textsf{copula}</span> package (<span class="citation" data-cites="kojadinovic2010modeling">Kojadinovic and Yan (<a href="#ref-kojadinovic2010modeling" role="doc-biblioref">2010</a>)</span>) and <span class="math inline">\textsf{mev}</span> (<span class="citation" data-cites="mevR">Belzile et al. (<a href="#ref-mevR" role="doc-biblioref">2022</a>)</span>) for sampling from Archimedean and multivariate extreme value distributions, respectively. To run the experiment, we use two computer clusters. The first cluster consists of five nodes, each with two 18-core Xeon Gold 3.1 GHz processors and 192 GB of memory, with 2933 MHz per socket. The second cluster has two CPU sockets, each containing a Xeon Platinum 8268 2.90 GHz processor with 24 cores. These configurations provide a significant amount of computational power and are well-suited for handling complex, data-intensive tasks. We use the first cluster to install the <span class="math inline">\textsf{copula}</span> package and sample from the <span class="math inline">\textbf{Clayton}</span>, <span class="math inline">\textbf{Frank}</span>, and <span class="math inline">\textbf{Joe}</span> models. We consider an increasing dimension <span class="math inline">d \in \{50, 100, \dots, 1600\}</span> for a fixed sample size of <span class="math inline">n=1000</span>. For the copula package, we compute the average time spent across 100 runs in order to cancel out variability. We use the second cluster to install the <span class="math inline">\textsf{mev}</span> package and call some of its methods to sample from the <span class="math inline">\textbf{Husler Reiss}</span>, <span class="math inline">\textbf{Logistic}</span>, and <span class="math inline">\textbf{TEV}</span> distributions. Sampling from the latter is fast, but sampling from the two others is time consuming. Therefore, we only consider dimensions <span class="math inline">d \in \{25, 50, \dots, 250\}</span> for a fixed sample size of <span class="math inline">n=1000</span>.</p>
<div id="fig-num_res" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-num_res-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img src="figures/discussion/num_time_arch.png" class="img-fluid" /></p>
<figcaption>Archimedean</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img src="figures/discussion/num_time_evd.png" class="img-fluid" /></p>
<figcaption>Multivariate extreme value</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-num_res-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure 4: Comparison results. Time spent (in seconds) to sample from the corresponding models with respect to the dimension <span class="math inline">d</span>. The left panel shows the results for sampling from <span class="math inline">\textbf{Clayton}</span>, <span class="math inline">\textbf{Frank}</span> and <span class="math inline">\textbf{Joe}</span> using <span class="math inline">\textsf{clayton}</span> in <span class="math inline">\textsf{Python}</span> and <span class="math inline">\textsf{copula}</span> in <span class="math inline">\textsf{R}</span>. The right panel shows the results for sampling from <span class="math inline">\textbf{HuslerReiss}</span>, <span class="math inline">\textbf{Logistic}</span> and <span class="math inline">\textbf{TEV}</span> by <span class="math inline">\textsf{clayton}</span> in <span class="math inline">\textsf{Python}</span> and <span class="math inline">\textsf{mev}</span> in <span class="math inline">\textsf{R}</span>. In both cases, <span class="math inline">1000</span> vectors are generated for each model.
</figcaption>
</figure>
</div>
<p>The figure shows the results of a comparison between the <span class="math inline">\textsf{clayton}</span> and <span class="math inline">\textsf{copula}</span> packages in <span class="math inline">\textsf{R}</span>, and the <span class="math inline">\textsf{mev}</span> package in <span class="math inline">\textsf{Python}</span>. The comparison shows that the <span class="math inline">\textsf{clayton}</span> package is more efficient at sampling from <span class="math inline">\textbf{Clayton}</span>, <span class="math inline">\textbf{Frank}</span> and <span class="math inline">\textbf{Joe}</span> copulae than the <span class="math inline">\textsf{copula}</span> package. The gap in efficiency may be due to the choice of algorithms used in the <span class="math inline">\textsf{clayton}</span> package, which uses frailty distributions. The time required for sampling increases linearly with the dimension for the <span class="math inline">\textsf{clayton}</span> package, but shows a more erratic behavior for the <span class="math inline">\textsf{copula}</span> package.</p>
</section>
<section id="conclusion" class="level2" data-number="5.2">
<h2 data-number="5.2"><span class="header-section-number">5.2</span> Conclusion</h2>
<p>This paper presents the construction and some implementations of the <span class="math inline">\textsf{Python}</span> package <span class="math inline">\textsf{clayton}</span> for random copula sampling. This is a seminal work in the field of software implementation of copula modeling in <span class="math inline">\textsf{Python}</span> and there is much more potential for growth. It is hoped that the potential diffusion of the software through those who need it may bring further implementations for multivariate modeling with copulae under <span class="math inline">\textsf{Python}</span>. For example, choosing a copula to fit the data is an important but difficult problem. A robust approach to estimating copulae has been investigated recently by <span class="citation" data-cites="alquier2020estimation">Alquier et al. (<a href="#ref-alquier2020estimation" role="doc-biblioref">2022</a>)</span> using Maximum Mean Discrepancy. In relation to our example, semiparametric estimation of copulae with missing data could be of great interest, as proposed by <span class="citation" data-cites="HAMORI201985">Hamori, Motegi, and Zhang (<a href="#ref-HAMORI201985" role="doc-biblioref">2019</a>)</span>.</p>
<p>Additionally, implementation of the algorithm proposed by <span class="citation" data-cites="10.1214/07-AOS556">McNeil and Nešlehová (<a href="#ref-10.1214/07-AOS556" role="doc-biblioref">2009</a>)</span> for generating random vectors for Archimedean copulae has been tackled, but as expected, numerical inversion gives spurious results, especially when the parameter <span class="math inline">\theta</span> and the dimension <span class="math inline">d</span> are high. Furthermore, as the support of the radial distribution is contained in the real line, numerical inversion leads to increased computational time. Further investigation is needed in order to generate random vectors from classical Archimedan models using the radial distribution.</p>
<p>A direction of improvement for the <span class="math inline">\textsf{clayton}</span> package is dependence modeling with Vine copulae, which have recently been a tool of high interest in the machine learning community (see, e.g., <span class="citation" data-cites="lopez2013gaussian">Lopez-Paz, Hernández-Lobato, and Zoubin (<a href="#ref-lopez2013gaussian" role="doc-biblioref">2013</a>)</span>, <span class="citation" data-cites="Veeramachaneni2015CopulaGM">Veeramachaneni, Cuesta-Infante, and O’Reilly (<a href="#ref-Veeramachaneni2015CopulaGM" role="doc-biblioref">2015</a>)</span>, <span class="citation" data-cites="Carrera2016VineCC">Carrera, Santana, and Lozano (<a href="#ref-Carrera2016VineCC" role="doc-biblioref">2016</a>)</span>, <span class="citation" data-cites="10.5555/2946645.2946678">Gonçalves, Von Zuben, and Banerjee (<a href="#ref-10.5555/2946645.2946678" role="doc-biblioref">2016</a>)</span> or <span class="citation" data-cites="SunCuesta-InfanteVeeramachaneni2019">Sun, Cuesta-Infante, and Veeramachaneni (<a href="#ref-SunCuesta-InfanteVeeramachaneni2019" role="doc-biblioref">2019</a>)</span>). This highlights the need for dependence modeling with copulae in <span class="math inline">\textsf{Python}</span>, as a significant part of the machine learning community uses this language. In relation to this paper, Vine copulae may be useful for modeling dependencies between extreme events, as suggested by <span class="citation" data-cites="SIMPSON2021104736">Simpson, Wadsworth, and Tawn (<a href="#ref-SIMPSON2021104736" role="doc-biblioref">2021</a>)</span>, <span class="citation" data-cites="nolde2021linking">Nolde and Wadsworth (<a href="#ref-nolde2021linking" role="doc-biblioref">2021</a>)</span>. Furthermore, other copula models could be implemented to model further dependencies. These implementations will expand the scope of dependence modeling with <span class="math inline">\textsf{Python}</span> and provide high-quality, usable tools for anyone who needs them.</p>
</section>
</section>
<section id="references" class="level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-quantrisk" class="csl-entry" role="listitem">
Alexander J. McNeil, Paul Embrechts, Rudiger Frey. 2005. <em>Quantitative Risk Management - Concepts, Techniques and Tools</em>. Princeton Series in Finance. Princeton University Press. <a href="https://libgen.li/file.php?md5=478a0059673fecd0c76229cd3d8884e7">libgen.li/file.php?md5=478a0059673fecd0c76229cd3d8884e7</a>.
</div>
<div id="ref-ALI1978405" class="csl-entry" role="listitem">
Ali, Mir M, N. N Mikhail, and M.Safiul Haq. 1978. <span>“A Class of Bivariate Distributions Including the Bivariate Logistic.”</span> <em>Journal of Multivariate Analysis</em> 8 (3): 405–12. https://doi.org/<a href="https://doi.org/10.1016/0047-259X(78)90063-5">https://doi.org/10.1016/0047-259X(78)90063-5</a>.
</div>
<div id="ref-alquier2020estimation" class="csl-entry" role="listitem">
Alquier, Pierre, Badr-Eddine Chérief-Abdellatif, Alexis Derumigny, and Jean-David Fermanian. 2022. <span>“Estimation of Copulas via Maximum Mean Discrepancy.”</span> <em>Journal of the American Statistical Association</em>, 1–16.
</div>
<div id="ref-copulasPy" class="csl-entry" role="listitem">
Alvarez, M., C. Sala, Y. Sun, J. D. Pérez, K. A. Zhang, A. Montanez, G. Bonomi, K. Veeramachaneni, I. Ramírez, and F. A. Hofman. 2021. <span>“Copulas.”</span> <em>GitHub Repository</em>. <a href="https://github.com/sdv-dev/Copulas" class="uri">https://github.com/sdv-dev/Copulas</a>; GitHub.
</div>
<div id="ref-BADOR201517" class="csl-entry" role="listitem">
Bador, Margot, Philippe Naveau, Eric Gilleland, Mercè Castellà, and Tatiana Arivelo. 2015. <span>“Spatial Clustering of Summer Temperature Maxima from the <span>CNRM-CM5</span> Climate Model Ensembles &amp; <span>E-OBS</span> over <span>Europe</span>.”</span> <em>Weather and Climate Extremes</em> 9: 17–24. https://doi.org/<a href="https://doi.org/10.1016/j.wace.2015.05.003">https://doi.org/10.1016/j.wace.2015.05.003</a>.
</div>
<div id="ref-baudin2017openturns" class="csl-entry" role="listitem">
Baudin, Michaël, Anne Dutfoy, Bertrand Iooss, and Anne-Laure Popelin. 2017. <span>“Openturns: An Industrial Software for Uncertainty Quantification in Simulation.”</span> In <em>Handbook of Uncertainty Quantification</em>, 2001–38. Springer.
</div>
<div id="ref-mevR" class="csl-entry" role="listitem">
Belzile, Leo et al. 2022. <em><span class="nocase">mev</span>: Modelling Extreme Values</em>. <a href="https://CRAN.R-project.org/package=mev">https://CRAN.R-project.org/package=mev</a>.
</div>
<div id="ref-bernard:hal-03207469" class="csl-entry" role="listitem">
Bernard, Elsa, Philippe Naveau, Mathieu Vrac, and Olivier Mestre. 2013. <span>“<span class="nocase">Clustering of Maxima: Spatial Dependencies among Heavy Rainfall in France</span>.”</span> <em><span>Journal of Climate</span></em> 26 (20): 7929–37. <a href="https://doi.org/10.1175/JCLI-D-12-00836.1">https://doi.org/10.1175/JCLI-D-12-00836.1</a>.
</div>
<div id="ref-copulaePy" class="csl-entry" role="listitem">
Bock, Daniel, and Jacob Chapman. 2021. <span>“Copulae.”</span> <em>GitHub Repository</em>. <a href="https://github.com/DanielBok/copulae" class="uri">https://github.com/DanielBok/copulae</a>; GitHub.
</div>
<div id="ref-chauvet2015" class="csl-entry" role="listitem">
Boistard, Helene, Guillaume Chauvet, and David Haziza. 2016. <span>“Doubly Robust Inference for the Distribution Function in the Presence of Missing Survey Data.”</span> <em>Scandinavian Journal of Statistics</em> 43 (3): 683–99. https://doi.org/<a href="https://doi.org/10.1111/sjos.12198">https://doi.org/10.1111/sjos.12198</a>.
</div>
<div id="ref-boulin2021non" class="csl-entry" role="listitem">
Boulin, Alexis, Elena Di Bernardino, Thomas Laloë, and Gwladys Toulemonde. 2022. <span>“Non-Parametric Estimator of a Multivariate Madogram for Missing-Data and Extreme Value Framework.”</span> <em>Journal of Multivariate Analysis</em> 192: 105059.
</div>
<div id="ref-bucher2011new" class="csl-entry" role="listitem">
Bücher, Axel, Holger Dette, and Stanislav Volgushev. 2011. <span>“New Estimators of the Pickands Dependence Function and a Test for Extreme-Value Dependence.”</span> <em>The Annals of Statistics</em> 39 (4): 1963–2006.
</div>
<div id="ref-Carrera2016VineCC" class="csl-entry" role="listitem">
Carrera, Diana, Roberto Santana, and José Antonio Lozano. 2016. <span>“Vine Copula Classifiers for the Mind Reading Problem.”</span> <em>Progress in Artificial Intelligence</em> 5: 289–305.
</div>
<div id="ref-10.2307/2335289" class="csl-entry" role="listitem">
Clayton, D. G. 1978. <span>“A Model for Association in Bivariate Life Tables and Its Application in Epidemiological Studies of Familial Tendency in Chronic Disease Incidence.”</span> <em>Biometrika</em> 65 (1): 141–51. <a href="http://www.jstor.org/stable/2335289">http://www.jstor.org/stable/2335289</a>.
</div>
<div id="ref-Demarta_Mcneil" class="csl-entry" role="listitem">
Demarta, Stefano, and Alexander J. McNeil. 2005. <span>“The t <span>Copula</span> and <span>Related</span> <span>Copulas</span>.”</span> <em>International Statistical Review</em> 73 (1): 111–29. https://doi.org/<a href="https://doi.org/10.1111/j.1751-5823.2005.tb00254.x">https://doi.org/10.1111/j.1751-5823.2005.tb00254.x</a>.
</div>
<div id="ref-10.1093/biomet/asw008" class="csl-entry" role="listitem">
Dombry, Clément, Sebastian Engelke, and Marco Oesting. 2016. <span>“<span class="nocase">Exact simulation of max-stable processes</span>.”</span> <em>Biometrika</em> 103 (2): 303–17. <a href="https://doi.org/10.1093/biomet/asw008">https://doi.org/10.1093/biomet/asw008</a>.
</div>
<div id="ref-10.2307/25463423" class="csl-entry" role="listitem">
Einmahl, John H. J., and Tao Lin. 2006. <span>“Asymptotic Normality of Extreme Value Estimators on <span class="math inline">\mathcal{C}([0, 1])</span>.”</span> <em>The Annals of Statistics</em> 34 (1): 469–92. <a href="http://www.jstor.org/stable/25463423">http://www.jstor.org/stable/25463423</a>.
</div>
<div id="ref-10.1214/21-AOS2050" class="csl-entry" role="listitem">
Einmahl, John H. J., and Johan Segers. 2021. <span>“<span class="nocase">Empirical tail copulas for functional data</span>.”</span> <em>The Annals of Statistics</em> 49 (5): 2672–96. <a href="https://doi.org/10.1214/21-AOS2050">https://doi.org/10.1214/21-AOS2050</a>.
</div>
<div id="ref-10.2307/3318798" class="csl-entry" role="listitem">
Fermanian, Jean-David, Dragan Radulović, and Marten Wegkamp. 2004. <span>“Weak Convergence of Empirical Copula Processes.”</span> <em>Bernoulli</em> 10 (5): 847–60. <a href="https://doi.org/10.3150/bj/1099579158">https://doi.org/10.3150/bj/1099579158</a>.
</div>
<div id="ref-Frank1979" class="csl-entry" role="listitem">
Frank, M. J. 1979. <span>“On the Simultaneous Associativity of f(x, y) and x + y - f(x, y).”</span> <em>Aequationes Mathematicae</em> 19: 194–226. <a href="http://eudml.org/doc/136825">http://eudml.org/doc/136825</a>.
</div>
<div id="ref-frees1998understanding" class="csl-entry" role="listitem">
Frees, Edward W, and Emiliano A Valdez. 1998. <span>“Understanding Relationships Using Copulas.”</span> <em>North American Actuarial Journal</em> 2 (1): 1–25.
</div>
<div id="ref-alma991005826659705596" class="csl-entry" role="listitem">
Gaetan, Carlo, and Xavier Guyon. 2008. <em>Modélisation Et Statistique Spatiales</em>. Mathématiques &amp; Applications. Berlin Heidelberg New York: Springer.
</div>
<div id="ref-10.2307/2337532" class="csl-entry" role="listitem">
Genest, C., K. Ghoudi, and L.-P. Rivest. 1995. <span>“A Semiparametric Estimation Procedure of Dependence Parameters in Multivariate Families of Distributions.”</span> <em>Biometrika</em> 82 (3): 543–52. <a href="http://www.jstor.org/stable/2337532">http://www.jstor.org/stable/2337532</a>.
</div>
<div id="ref-10.2307/24586878" class="csl-entry" role="listitem">
Gijbels, Irène, Marek Omelka, and Noël Veraverbeke. 2015. <span>“Estimation of a Copula When a Covariate Affects Only Marginal Distributions.”</span> <em>Scandinavian Journal of Statistics</em> 42 (4): 1109–26. <a href="http://www.jstor.org/stable/24586878">http://www.jstor.org/stable/24586878</a>.
</div>
<div id="ref-10.5555/2946645.2946678" class="csl-entry" role="listitem">
Gonçalves, André R., Fernando J. Von Zuben, and Arindam Banerjee. 2016. <span>“Multi-Task Sparse Structure Learning with Gaussian Copula Models.”</span> <em>J. Mach. Learn. Res.</em> 17 (1): 1205–34.
</div>
<div id="ref-gudendorf2009extremevalue" class="csl-entry" role="listitem">
Gudendorf, Gordon, and Johan Segers. 2010. <span>“Extreme-Value Copulas.”</span> In <em>Copula Theory and Its Applications</em>, 198:127–45. Lect. Notes Stat. Proc. Springer, Heidelberg. <a href="https://doi.org/10.1007/978-3-642-12465-5\_6">https://doi.org/10.1007/978-3-642-12465-5\_6</a>.
</div>
<div id="ref-GUDENDORF20123073" class="csl-entry" role="listitem">
———. 2012. <span>“Nonparametric Estimation of Multivariate Extreme-Value Copulas.”</span> <em>Journal of Statistical Planning and Inference</em> 142 (12): 3073–85. https://doi.org/<a href="https://doi.org/10.1016/j.jspi.2012.05.007">https://doi.org/10.1016/j.jspi.2012.05.007</a>.
</div>
<div id="ref-1960" class="csl-entry" role="listitem">
Gumbel, E. J. 1960. <span>“Distributions de Valeurs Extrêmes En Plusieurs Dimensions.”</span> <em>Publications de l’institut de Statistique de l’Université de Paris</em> 9: 171–73.
</div>
<div id="ref-HAMORI201985" class="csl-entry" role="listitem">
Hamori, Shigeyuki, Kaiji Motegi, and Zheng Zhang. 2019. <span>“Calibration Estimation of Semiparametric Copula Models with Data Missing at Random.”</span> <em>Journal of Multivariate Analysis</em> 173: 85–109. https://doi.org/<a href="https://doi.org/10.1016/j.jmva.2019.02.003">https://doi.org/10.1016/j.jmva.2019.02.003</a>.
</div>
<div id="ref-harris2020array" class="csl-entry" role="listitem">
Harris, Charles R, K Jarrod Millman, Stéfan J Van Der Walt, Ralf Gommers, Pauli Virtanen, David Cournapeau, Eric Wieser, et al. 2020. <span>“Array Programming with NumPy.”</span> <em>Nature</em> 585 (7825): 357–62.
</div>
<div id="ref-hofert2012likelihood" class="csl-entry" role="listitem">
Hofert, Marius, Martin Mächler, and Alexander J McNeil. 2012. <span>“Likelihood Inference for Archimedean Copulas in High Dimensions Under Known Margins.”</span> <em>Journal of Multivariate Analysis</em> 110: 133–50.
</div>
<div id="ref-HUSLER1989283" class="csl-entry" role="listitem">
Hüsler, Jürg, and Rolf-Dieter Reiss. 1989. <span>“Maxima of Normal Random Vectors: Between Independence and Complete Dependence.”</span> <em>Statistics &amp; Probability Letters</em> 7 (4): 283–86. https://doi.org/<a href="https://doi.org/10.1016/0167-7152(89)90106-5">https://doi.org/10.1016/0167-7152(89)90106-5</a>.
</div>
<div id="ref-Joe1990FamiliesOM" class="csl-entry" role="listitem">
Joe, H. 1990. <span>“Families of Min-Stable Multivariate Exponential and Multivariate Extreme Value Distributions.”</span> <em>Statistics &amp; Probability Letters</em> 9: 75–81.
</div>
<div id="ref-joe1997multivariate" class="csl-entry" role="listitem">
———. 1997. <em>Multivariate Models and Multivariate Dependence Concepts</em>. Chapman &amp; Hall/CRC Monographs on Statistics &amp; Applied Probability. Taylor &amp; Francis. <a href="https://books.google.fr/books?id=iJbRZL2QzMAC">https://books.google.fr/books?id=iJbRZL2QzMAC</a>.
</div>
<div id="ref-copulaR" class="csl-entry" role="listitem">
Jun Yan. 2007. <span>“Enjoy the Joy of Copulas: With a Package <span class="nocase">copula</span>.”</span> <em>Journal of Statistical Software</em> 21 (4): 1–21. <a href="https://www.jstatsoft.org/v21/i04/">https://www.jstatsoft.org/v21/i04/</a>.
</div>
<div id="ref-kojadinovic2010modeling" class="csl-entry" role="listitem">
Kojadinovic, Ivan, and Jun Yan. 2010. <span>“Modeling Multivariate Distributions with Continuous Margins Using the Copula r Package.”</span> <em>Journal of Statistical Software</em> 34: 1–20.
</div>
<div id="ref-lopez2013gaussian" class="csl-entry" role="listitem">
Lopez-Paz, David, Jose Miguel Hernández-Lobato, and Ghahramani Zoubin. 2013. <span>“Gaussian Process Vine Copulas for Multivariate Dependence.”</span> In <em>International Conference on Machine Learning</em>, 10–18. PMLR.
</div>
<div id="ref-MARCON20171" class="csl-entry" role="listitem">
Marcon, G., S. A. Padoan, P. Naveau, P. Muliere, and J. Segers. 2017. <span>“Multivariate Nonparametric Estimation of the Pickands Dependence Function Using Bernstein Polynomials.”</span> <em>Journal of Statistical Planning and Inference</em> 183: 1–17. https://doi.org/<a href="https://doi.org/10.1016/j.jspi.2016.10.004">https://doi.org/10.1016/j.jspi.2016.10.004</a>.
</div>
<div id="ref-10.2307/2289314" class="csl-entry" role="listitem">
Marshall, Albert W., and Ingram Olkin. 1988. <span>“Families of Multivariate Distributions.”</span> <em>Journal of the American Statistical Association</em> 83 (403): 834–41. <a href="http://www.jstor.org/stable/2289314">http://www.jstor.org/stable/2289314</a>.
</div>
<div id="ref-10.1214/07-AOS556" class="csl-entry" role="listitem">
McNeil, Alexander J., and Johanna Nešlehová. 2009. <span>“<span class="nocase">Multivariate Archimedean copulas, d-monotone functions and l1-norm symmetric distributions</span>.”</span> <em>The Annals of Statistics</em> 37 (5B): 3059–97. <a href="https://doi.org/10.1214/07-AOS556">https://doi.org/10.1214/07-AOS556</a>.
</div>
<div id="ref-MISHRA2011157" class="csl-entry" role="listitem">
Mishra, Ashok K., and Vijay P. Singh. 2011. <span>“Drought Modeling – a Review.”</span> <em>Journal of Hydrology</em> 403 (1): 157–75. https://doi.org/<a href="https://doi.org/10.1016/j.jhydrol.2011.03.049">https://doi.org/10.1016/j.jhydrol.2011.03.049</a>.
</div>
<div id="ref-naveau:hal-00312758" class="csl-entry" role="listitem">
Naveau, Philippe, Armelle Guillou, Daniel Cooley, and Jean Diebolt. 2009. <span>“Modelling Pairwise Dependence of Maxima in Space.”</span> <em>Biometrika</em> 96 (1): 1–17. <a href="https://doi.org/10.1093/biomet/asp001">https://doi.org/10.1093/biomet/asp001</a>.
</div>
<div id="ref-nelsen2007introduction" class="csl-entry" role="listitem">
Nelsen, Roger B. 2007. <em>An Introduction to Copulas</em>. Springer Science &amp; Business Media.
</div>
<div id="ref-nicolas2022pycop" class="csl-entry" role="listitem">
Nicolas, Maxime LD. 2022. <span>“Pycop: A Python Package for Dependence Modeling with Copulas.”</span> <em>Zenodo Software Package</em> 70: 7030034.
</div>
<div id="ref-nolde2021linking" class="csl-entry" role="listitem">
Nolde, Natalia, and Jennifer L. Wadsworth. 2021. <span>“Linking Representations for Multivariate Extremes via a Limit Set.”</span> <a href="https://arxiv.org/abs/2012.00990">https://arxiv.org/abs/2012.00990</a>.
</div>
<div id="ref-patton2012review" class="csl-entry" role="listitem">
Patton, Andrew J. 2012. <span>“A Review of Copula Models for Economic Time Series.”</span> <em>Journal of Multivariate Analysis</em> 110: 4–18.
</div>
<div id="ref-PORTIER2018160" class="csl-entry" role="listitem">
Portier, François, and Johan Segers. 2018. <span>“On the Weak Convergence of the Empirical Conditional Copula Under a Simplifying Assumption.”</span> <em>Journal of Multivariate Analysis</em> 166: 160–81. https://doi.org/<a href="https://doi.org/10.1016/j.jmva.2018.03.002">https://doi.org/10.1016/j.jmva.2018.03.002</a>.
</div>
<div id="ref-saunders" class="csl-entry" role="listitem">
Saunders, K., A. Stephenson, and David Karoly. 2021. <span>“A Regionalisation Approach for Rainfall Based on Extremal Dependence.”</span> <em>Extremes</em> 24 (June). <a href="https://doi.org/10.1007/s10687-020-00395-y">https://doi.org/10.1007/s10687-020-00395-y</a>.
</div>
<div id="ref-VineCopulaR" class="csl-entry" role="listitem">
Schepsmeier, U., J. Stoeber, E. C. Brechmann, B. Graeler, T. Nagler, T. Erhardt, C. Almeida, et al. 2019. <span>“VineCopula : Statistical Inference of Vine Copulas.”</span> <em>Package "VineCopula". R Package, Version 2.3.0</em>. <a href="https://cran.r-project.org/web/packages/VineCopula/index.html">https://cran.r-project.org/web/packages/VineCopula/index.html</a>.
</div>
<div id="ref-SIMPSON2021104736" class="csl-entry" role="listitem">
Simpson, Emma S., Jennifer L. Wadsworth, and Jonathan A. Tawn. 2021. <span>“A Geometric Investigation into the Tail Dependence of Vine Copulas.”</span> <em>Journal of Multivariate Analysis</em> 184: 104736. https://doi.org/<a href="https://doi.org/10.1016/j.jmva.2021.104736">https://doi.org/10.1016/j.jmva.2021.104736</a>.
</div>
<div id="ref-Skla59" class="csl-entry" role="listitem">
Sklar, Abe. 1959. <span>“Fonctions de Répartition à n Dimensions Et Leurs Marges.”</span> <em>Publications de l’Institut de Statistique de l’Université de Paris</em> 8: 229–31.
</div>
<div id="ref-Smith1990" class="csl-entry" role="listitem">
Smith, R. L. 1990. <em>Extreme Value Theory</em>. Handbook of Applicable Mathematics (ed. W. Ledermann), vol. 7. Chichester: John Wiley, pp. 437–471.
</div>
<div id="ref-evdR" class="csl-entry" role="listitem">
Stephenson, A. G. 2002. <span>“<span class="nocase">evd</span>: <span>Extreme</span> <span>Value</span> <span>Distributions</span>.”</span> <em>R News</em> 2 (2). <a href="https://CRAN.R-project.org/doc/Rnews/">https://CRAN.R-project.org/doc/Rnews/</a>.
</div>
<div id="ref-stephenson2003simulating" class="csl-entry" role="listitem">
Stephenson, Alec. 2003. <span>“Simulating Multivariate Extreme Value Distributions of Logistic Type.”</span> <em>Extremes</em> 6 (1): 49–59.
</div>
<div id="ref-SunCuesta-InfanteVeeramachaneni2019" class="csl-entry" role="listitem">
Sun, Yi, Alfredo Cuesta-Infante, and Kalyan Veeramachaneni. 2019. <span>“Learning Vine Copula Models for Synthetic Data Generation.”</span> <em>Proceedings of the AAAI Conference on Artificial Intelligence</em> 33 (01): 5049–57. <a href="https://doi.org/10.1609/aaai.v33i01.33015049">https://doi.org/10.1609/aaai.v33i01.33015049</a>.
</div>
<div id="ref-10.1093/biomet/75.3.397" class="csl-entry" role="listitem">
Tawn, Jonathan A. 1988. <span>“<span class="nocase">Bivariate extreme value theory: Models and estimation</span>.”</span> <em>Biometrika</em> 75 (3): 397–415. <a href="https://doi.org/10.1093/biomet/75.3.397">https://doi.org/10.1093/biomet/75.3.397</a>.
</div>
<div id="ref-tawn1990" class="csl-entry" role="listitem">
———. 1990. <span>“Modelling Multivariate Extreme Value Distributions.”</span> <em>Biometrika</em> 77 (2): 245–53. <a href="http://www.jstor.org/stable/2336802">http://www.jstor.org/stable/2336802</a>.
</div>
<div id="ref-Veeramachaneni2015CopulaGM" class="csl-entry" role="listitem">
Veeramachaneni, Kalyan, Alfredo Cuesta-Infante, and Una-May O’Reilly. 2015. <span>“Copula Graphical Models for Wind Resource Estimation.”</span> In <em>IJCAI</em>.
</div>
<div id="ref-virtanen2020scipy" class="csl-entry" role="listitem">
Virtanen, Pauli, Ralf Gommers, Travis E Oliphant, Matt Haberland, Tyler Reddy, David Cournapeau, Evgeni Burovski, et al. 2020. <span>“SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python.”</span> <em>Nature Methods</em> 17 (3): 261–72.
</div>
<div id="ref-woolridge2007" class="csl-entry" role="listitem">
Wooldridge, Jeffrey M. 2007. <span>“Inverse Probability Weighted Estimation for General Missing Data Problems.”</span> <em>Journal of Econometrics</em> 141 (2): 1281–301. https://doi.org/<a href="https://doi.org/10.1016/j.jeconom.2007.02.002">https://doi.org/10.1016/j.jeconom.2007.02.002</a>.
</div>
</div>
</section>
<section id="appendices" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> Appendix</h1>
<section id="sec-bv_arch" class="level2" data-number="6.1">
<h2 data-number="6.1"><span class="header-section-number">6.1</span> Bivariate Archimedean models</h2>
<div class=" {#fig-bv_arch_1}">
<p><img src="figures/app/arch_table_1.png" class="img-fluid" style="width:100.0%" /></p>
</div>
<div class=" {#fig-bv_arch_2}">
<p><img src="figures/app/arch_table_2.png" class="img-fluid" style="width:100.0%" /></p>
</div>
</section>
<section id="sec-bv_ext" class="level2" data-number="6.2">
<h2 data-number="6.2"><span class="header-section-number">6.2</span> Implemented bivariate extreme models</h2>
<div class=" {#fig-bv_ext}">
<p><img src="figures/app/ext_table.png" class="img-fluid" style="width:100.0%" /></p>
</div>
</section>
<section id="sec-mv_arch" class="level2" data-number="6.3">
<h2 data-number="6.3"><span class="header-section-number">6.3</span> Multivariate Archimedean copulae</h2>
<div class=" {#fig-mv_arch}">
<p><img src="figures/app/arch_mv_table.png" class="img-fluid" style="width:100.0%" /></p>
</div>
</section>
<section id="sec-mv_ext" class="level2" data-number="6.4">
<h2 data-number="6.4"><span class="header-section-number">6.4</span> Multivariate extreme models</h2>
<p>Before giving the main details, we introduce some notations. Let <span class="math inline">B</span> be the set of all nonempty subsets of <span class="math inline">\{1,\dots,d\}</span> and <span class="math inline">B_1 = \{b \in B, |b| = 1\}</span>, where <span class="math inline">|b|</span> denotes the number of elements in thet set <span class="math inline">b</span>. We note by <span class="math inline">B_{(j)} = \{b \in B, j \in b\}</span>. For <span class="math inline">d=3</span>, the Pickands is expressed as</p>
<div id="eq-mv_ext">
<p><span class="math display">\begin{align*}
A(\textbf{w}) =&amp; \alpha_1 w_1 + \psi_1 w_2 + \phi_1 w_3 + \left( (\alpha_2 w_1)^{\theta_1} + (\psi_2w_2)^{\theta_1} \right)^{1/\theta_1} + \left( (\alpha_3 w_2)^{\theta_2} + (\phi_2w_3)^{\theta_2} \right)^{1/\theta_2} \\ &amp;+ \left( (\psi_3 w_2)^{\theta_3} + (\phi_3w_3)^{\theta_3} \right)^{1/\theta_3}
  + \left( (\alpha_4 w_1)^{\theta_4} + (\psi_4 w_2)^{\theta_4} + (\phi_4 w_3)^{\theta_4} \right)^{1/\theta_4},
\end{align*}</span></p>
</div>
<p>where <span class="math inline">\boldsymbol{\alpha} = (\alpha_1, \dots, \alpha_4), \boldsymbol{\psi} = (\psi_1, \dots, \psi_4), \boldsymbol{\phi} = (\phi_1, \dots, \phi_4)</span> are all elements of <span class="math inline">\Delta^3</span>. We take <span class="math inline">\boldsymbol{\alpha} = (0.4,0.3,0.1,0.2)</span>, <span class="math inline">\boldsymbol{\psi} = (0.1, 0.2, 0.4, 0.3)</span>, <span class="math inline">\boldsymbol{\phi} = (0.6,0.1,0.1,0.2)</span> and <span class="math inline">\boldsymbol{\theta} = (\theta_1, \dots, \theta_4) = (0.6,0.5,0.8,0.3)</span> as the dependence parameter.</p>
<p>The Dirichlet model is a mixture of <span class="math inline">m</span> Dirichlet densities, that is <span class="math display">
    h(\textbf{w}) = \sum_{k=1}^m \theta_k \frac{\Gamma(\sum_{j=1}^d \sigma_{kj})}{\Pi_{j=1}^d \Gamma(\sigma_{kj})} \Pi_{j=1}^d w_j^{\sigma_{kj}-1},
</span> with <span class="math inline">\sum_{k=1}^m \theta_k = 1</span>, <span class="math inline">\sigma_{kj} &gt; 0</span> for <span class="math inline">k \in \{1,\dots,m\}</span> and <span class="math inline">j \in \{1, \dots, d\}</span>. Let <span class="math inline">\mathcal{D} \in [0, \infty)^{(d-1)\times (d-1)}</span> denotes the space of symmetric strictly conditionnaly negative definite matrices that is</p>
<div id="striclty_cond_neg">
<p><span class="math display">\begin{align*}
            \mathcal{D}_{k} = \Big\{ \Gamma \in [0,\infty)^{k \times k} : a^\top \Gamma a &lt; 0 \; \textrm{for all } a \in \mathbb{R}^{k} \setminus \{\textbf{0}\}  \, \textrm{with } \sum_{j=1}^{d-1} a_j = 0, \\ \Gamma_{ii} = 0, \Gamma_{ij} = \Gamma_{ji}, \quad 1 \leq i,j\leq k \Big\}.
        \end{align*}</span></p>
</div>
<p>For any <span class="math inline">2 \leq k \leq d</span>, consider <span class="math inline">m&#39; = (m_1, \dots, m_k)</span> with <span class="math inline">1 \leq m_1 &lt;  \dots &lt; m_k \leq d</span> define <span class="math display">
    \Sigma^{(k)}_m = 2 \left( \Gamma_{m_i m_k} + \Gamma_{m_j m_k} - \Gamma_{m_i m_j} \right)_{m_i m_j \neq m_k} \in [0,\infty)^{(d-1)\times(d-1)}.
</span> Furthermore, note <span class="math inline">S(\cdot | \Sigma^{(k)}_m)</span> denote the survival function of a normal random vector with mean vector <span class="math inline">\textbf{0}</span> and covariance matrix <span class="math inline">\Sigma^{(k)}</span>. We now define : <span class="math display">
    h_{km}(\textbf{y}) = \int_{y_k}^\infty S\left( (y_i - z + 2\Gamma_{m_i m_k})_{i=1}^{k-1} | \Gamma_{km}\right) e^{-z}dz
</span> for <span class="math inline">2 \leq k \leq d</span>. We denote by <span class="math inline">\Sigma^{(k)}</span> the summation over all <span class="math inline">k</span>-vectors <span class="math inline">m=(m_1,\dots,m_k)</span> with <span class="math inline">1\leq m_1 &lt; \dots &lt; m_k \leq d</span>.</p>
<div class=" {#fig-mv_ext}">
<p><img src="figures/app/ext_mv_table.png" class="img-fluid" style="width:100.0%" /></p>
</div>
</section>
<section id="sec-mv_ellip" class="level2" data-number="6.5">
<h2 data-number="6.5"><span class="header-section-number">6.5</span> Multivariate elliptical dependencies</h2>
<p>Let <span class="math inline">\textbf{X} \sim \textbf{E}_d(\boldsymbol{\mu}, \Sigma, \psi)</span> be an elliptical distributed random vector with cumulative distribution <span class="math inline">F</span> and marginal <span class="math inline">F_0, \dots, F_{d-1}</span>. Then, the copula <span class="math inline">C</span> of <span class="math inline">F</span> is called an elliptical copula. We denote by <span class="math inline">\phi</span> the standard normal distribution function and <span class="math inline">\boldsymbol{\phi}_\Sigma</span> the joint distribution function of <span class="math inline">\textbf{X} \sim \mathcal{N}_d(\textbf{0}, \Sigma)</span>, where <span class="math inline">\textbf{0}</span> is the <span class="math inline">d</span>-dimensional vector composed out of <span class="math inline">0</span>. In the same way, we note <span class="math inline">t_{\theta}</span> the distribution function of a standard univariate distribution <span class="math inline">t</span> distribution and by <span class="math inline">\boldsymbol{t}_{\theta, \Sigma}</span> the joint distribution function of the vector <span class="math inline">\textbf{X} \sim \boldsymbol{t}_{d}(\theta, \textbf{0}, \Sigma)</span>. A <span class="math inline">d</span> squared matrix <span class="math inline">\Sigma</span> is said to be positively semi definite if for all <span class="math inline">u \in \mathbb{R}^d</span> we have :</p>
<p><span class="math display">
  u^\top \Sigma u \geq 0
</span></p>
<div class=" {#fig-mv_elli}">
<p><img src="figures/app/elli_table.png" class="img-fluid" style="width:100.0%" /></p>
</div>
<!-- -->
<div class="quarto-embedded-source-code">
<div class="sourceCode" id="cb18" data-shortcodes="false"><pre class="sourceCode markdown"><code class="sourceCode markdown"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> &quot;A Python Package for Sampling from Copulae: clayton&quot;</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle:</span><span class="co"> &quot;A Python Package for Sampling from Copulae: clayton&quot;</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="co">  - name: Alexis Boulin</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="co">    url: https://aleboul.github.io/</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="co">    corresponding: true</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co">    email: aboulin@unice.fr</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="co">    affiliations:</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="co">      - name: Université Côte d&#39;Azur, CNRS, LJAD, France</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="co">        url: https://univ-cotedazur.fr/</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="co">      - name: Inria, Lemon</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="co">        url: https://www.inria.fr/fr/lemon</span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> 2023-01-12</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a><span class="an">date-modified:</span><span class="co"> last-modified</span></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> |</span></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a><span class="co">  The package $\textsf{clayton}$ is designed to be intuitive, user-friendly, and efficient. It offers a wide range of copula models, including Archimedean, Elliptical, and Extreme. The package is implemented in pure $\textsf{Python}$, making it easy to install and use.</span></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a><span class="an">abstract:</span><span class="co"> &gt;+</span></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a><span class="co">  The package $\textsf{clayton}$ is designed to be intuitive, user-friendly, and efficient. It offers a wide range of copula models, including Archimedean, Elliptical, and Extreme. The package is implemented in pure $\textsf{Python}$, making it easy to install and use. In addition, we provide detailed documentation and examples to help users get started quickly. We also conduct a performance comparison with existing $\textsf{R}$ packages, demonstrating the efficiency of our implementation. The $\textsf{clayton}$ package is a valuable tool for researchers and practitioners working with copulae in $\textsf{Python}$.</span></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a><span class="an">keywords:</span><span class="co"> [Copulae, Random number generation]</span></span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a><span class="an">citation:</span></span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a><span class="co">  type: article-journal</span></span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a><span class="co">  container-title: &quot;Computo&quot;</span></span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a><span class="co">  doi: &quot;10.57750/4szh-t752&quot;</span></span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a><span class="co">  publisher: &quot;French Statistical Society&quot;</span></span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a><span class="co">  issn: &quot;2824-7795&quot;</span></span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a><span class="co">  pdf-url: &quot;https://computo.sfds.asso.fr/published-202301-boulin-clayton/published-202301-boulin-clayton.pdf&quot;</span></span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a><span class="co">  url:  &quot;https://computo.sfds.asso.fr/published-202301-boulin-clayton/&quot;</span></span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a><span class="an">google-scholar:</span><span class="co"> true</span></span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a><span class="an">bibliography:</span><span class="co"> references.bib</span></span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a><span class="an">github-user:</span><span class="co"> computorg</span></span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a><span class="an">repo:</span><span class="co"> &quot;published-202301-boulin-clayton&quot;</span></span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a><span class="an">draft:</span><span class="co"> false </span></span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a><span class="an">published:</span><span class="co"> true</span></span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a><span class="co">  computo-html: default</span></span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a><span class="co">  computo-pdf: default</span></span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a><span class="fu"># Introduction</span></span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a>Modeling dependence relations between random variables is a topic of interest in probability theory and statistics. The most popular approach is based on the second moment of the underlying random variables, namely, the covariance. It is well known that only linear dependence can be captured by the covariance and it is only characteristic for a few models, e.g., the multivariate normal distribution or binary random variables. As a beneficial alternative to dependence, the concept of copulae, going back to @Skla59, has drawn a lot of attention. The copula $C: <span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>^d \rightarrow <span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>$ of a random vector $\mathbf{X} = (X_0, \dots, X_{d-1})$ with $d \geq 2$ allows us to separate the effect of dependence from the effect of the marginal distribution, such that:</span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-45"><a href="#cb18-45" aria-hidden="true" tabindex="-1"></a>    \mathbb{P}\left<span class="sc">\{</span> X_0 \leq x_0, \dots, X_{d-1} \leq x_{d-1} \right<span class="sc">\}</span> = C\left(\mathbb{P} <span class="sc">\{</span>X_0 \leq x_0<span class="sc">\}</span>, \dots, \mathbb{P}<span class="sc">\{</span>X_{d-1} \leq x_{d-1} <span class="sc">\}</span>\right),</span>
<span id="cb18-46"><a href="#cb18-46" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-47"><a href="#cb18-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-48"><a href="#cb18-48" aria-hidden="true" tabindex="-1"></a>where $(x_0, \dots, x_{d-1}) \in \mathbb{R}^d$. The main consequence of this identity is that the copula completely characterizes the stochastic dependence between the margins of $\mathbf{X}$.</span>
<span id="cb18-49"><a href="#cb18-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-50"><a href="#cb18-50" aria-hidden="true" tabindex="-1"></a>In other words, copulae allow us to model marginal distributions and dependence structure separately. Furthermore, motivated by Sklar&#39;s theorem, the problem of investigating stochastic dependence is reduced to the study of multivariate distribution functions under the unit hypercube $<span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>^d$ with uniform margins. The theory of copulae has been of prime interest for many applied fields of science, such as quantitative finance (@patton2012review) or environmental sciences (@MISHRA2011157). This increasing number of applications has led to a demand for statistical methods. For example, semiparametric estimation (@10.2307/2337532), nonparametric estimation (@10.2307/3318798) of copulae or nonparametric estimation of conditional copulae (@10.2307/24586878, @PORTIER2018160) have been investigated. These results are established for a fixed arbitrary dimension $d \geq 2$, but several investigations (e.g. @10.2307/25463423, @10.1214/21-AOS2050) are done for functional data for the tail copula, which captures dependence in the upper tail.</span>
<span id="cb18-51"><a href="#cb18-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-52"><a href="#cb18-52" aria-hidden="true" tabindex="-1"></a>Software implementation of copulae has been extensively studied in $\textsf{R}$, for example in the packages @evdR, @copulaR, @VineCopulaR. However, methods for working with copulae in $\textsf{Python}$ are still limited. As far as we know, copula-dedicated packages in $\textsf{Python}$ are mainly designed for modeling, such as @copulasPy and @copulaePy. These packages use maximum likelihood methods to estimate the copula parameters from observed data and generate synthetic data using the estimated copula model. Other packages provide sampling methods for copulae, but they are typically restricted to the bivariate case and the conditional simulation method (see, for example, @baudin2017openturns). Additionally, if the multivariate case is considered only Archimedean and elliptical copulae are under interest and those packages (see @nicolas2022pycop) do not include the extreme value class in arbitrary dimensions $d \geq 2$. In this paper, we propose to implement a wide range of copulae, including the extreme value class, in arbitrary fixed dimension $d \geq 2$.</span>
<span id="cb18-53"><a href="#cb18-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-54"><a href="#cb18-54" aria-hidden="true" tabindex="-1"></a>Through this paper we adopt the following notational conventions: all the indices will start at $0$ as in $\textsf{Python}$. Consider $(\Omega, \mathcal{A}, \mathbb{P})$ a probability space and let $\textbf{X} = (X_0, \dots, X_{d-1})$ be a $d$-dimensional random vector with values in $(\mathbb{R}^d, \mathcal{B}(\mathbb{R}^d))$, with $d \geq 2$ and $\mathcal{B}(\mathbb{R}^d)$ the Borel $\sigma$-algebra of $\mathbb{R}^d$. This random vector has a joint distribution $F$ with copula $C$ and its margins are denoted by $F_j(x) = \mathbb{P}<span class="sc">\{</span>X_j \leq x<span class="sc">\}</span>$ for all $x \in \mathbb{R}$ and $j \in <span class="sc">\{</span>0, \dots, d-1<span class="sc">\}</span>$. Denote by $\textbf{U} = (U_0, \dots, U_{d-1})$ a $d$ random vector with copula $C$ and uniform margins. All bold letters $\textbf{x}$ will denote a vector of $\mathbb{R}^d$.</span>
<span id="cb18-55"><a href="#cb18-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-56"><a href="#cb18-56" aria-hidden="true" tabindex="-1"></a>The $\textsf{clayton}$ package, whose Python code can be found in <span class="co">[</span><span class="ot">https://github.com/Aleboul/clayton</span><span class="co">](https://github.com/Aleboul/clayton)</span>, uses object-oriented features of the Python language. The package contains classes for Archimedean, elliptical, and extreme value copulae. In @sec-classes, we briefly describe the classes defined in the package. @sec-rng presents methods for generating random vectors. In @sec-pairwise, we apply the $\textsf{clayton}$ package to model pairwise dependence between maxima. @sec-discussion discusses potential improvements to the package and provides concluding remarks. Sections from @sec-bv_arch to @sec-mv_ellip define and illustrate all the parametric copula models implemented in the package.</span>
<span id="cb18-57"><a href="#cb18-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-58"><a href="#cb18-58" aria-hidden="true" tabindex="-1"></a><span class="fu"># Classes {#sec-classes}</span></span>
<span id="cb18-59"><a href="#cb18-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-60"><a href="#cb18-60" aria-hidden="true" tabindex="-1"></a>:::{#fig-diagram}</span>
<span id="cb18-61"><a href="#cb18-61" aria-hidden="true" tabindex="-1"></a><span class="al">![](figures/diagram.png)</span></span>
<span id="cb18-62"><a href="#cb18-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-63"><a href="#cb18-63" aria-hidden="true" tabindex="-1"></a>The figure shows a object diagram that structures the code. The $\textbf{Multivariate}$ class serves as the root and is used to instantiate all its child classes $\textbf{Archimedean}$, $\textbf{Extreme}$, $\textbf{Gaussian}$, and $\textbf{Student}$ in red. The blue-colored classes correspond to various parametric copula models, and the green-colored classes represent examples of methods. Symbols $\varphi, \varphi^\leftarrow, \dot{\varphi}$ correspond to the generator function, its inverse, and its derivative, respectively, while $A, \dot{A}$ refer to the Pickands dependence function and its derivative.</span>
<span id="cb18-64"><a href="#cb18-64" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-65"><a href="#cb18-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-66"><a href="#cb18-66" aria-hidden="true" tabindex="-1"></a>The architecture of the code is shown in @fig-diagram. At the third level of the architecture, we find important parametric models of Archimedean and extreme value copulae (depicted as blue in the figure). These parametric models contain methods such as the generator function $\varphi$ (see @sec-arch) for Archimedean copulae and the Pickands dependence function $A$ (see @sec-extreme) for extreme value copulae (depicted as green in the figure). We provide a brief overview of Archimedean copulae and some of their properties in high-dimensional spaces in @sec-arch. A characterization of extreme value copulae is given in @sec-extreme. The from @sec-bv_arch to @sec-mv_ellip define and illustrate all the copula models implemented in the package.</span>
<span id="cb18-67"><a href="#cb18-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-68"><a href="#cb18-68" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Archimedean class {#sec-arch}</span></span>
<span id="cb18-69"><a href="#cb18-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-70"><a href="#cb18-70" aria-hidden="true" tabindex="-1"></a>Let $\varphi$ be a generator that is a strictly decreasing, convex function from $<span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>$ to $<span class="co">[</span><span class="ot">0, \infty</span><span class="co">]</span>$ such that $\varphi(1) = 0$ and $\varphi(0) = \infty$. We denote the generalized inverse of $\varphi$ by $\varphi^\leftarrow$. Consider the following equation:</span>
<span id="cb18-71"><a href="#cb18-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-72"><a href="#cb18-72" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-73"><a href="#cb18-73" aria-hidden="true" tabindex="-1"></a>    C(\textbf{u}) = \varphi^\leftarrow (\varphi(u_0)+ \dots + \varphi(u_{d-1})).</span>
<span id="cb18-74"><a href="#cb18-74" aria-hidden="true" tabindex="-1"></a>$$ {#eq-arch_cop}</span>
<span id="cb18-75"><a href="#cb18-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-76"><a href="#cb18-76" aria-hidden="true" tabindex="-1"></a>If this relation holds and $C$ is a copula function, then $C$ is called an Archimedean copula. A necessary condition for @eq-arch_cop to be a copula is that the generator $\varphi$ is a $d$-monotonic function, i.e., it is differentiable up to the order $d$ and its derivatives satisfy</span>
<span id="cb18-77"><a href="#cb18-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-78"><a href="#cb18-78" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-79"><a href="#cb18-79" aria-hidden="true" tabindex="-1"></a>  (-1)^k \left(\varphi\right)^{(k)}(x) \geq 0, \quad k \in <span class="sc">\{</span>1, \dots, d<span class="sc">\}</span></span>
<span id="cb18-80"><a href="#cb18-80" aria-hidden="true" tabindex="-1"></a>$$ {#eq-dmono}</span>
<span id="cb18-81"><a href="#cb18-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-82"><a href="#cb18-82" aria-hidden="true" tabindex="-1"></a>for $x \in (0, \infty)$ (see Corollary 2.1 of @10.1214/07-AOS556). Note that $d$-monotonic Archimedean inverse generators do not necessarily generate Archimedean copulae in dimensions higher than $d$ (see @10.1214/07-AOS556). As a result, some Archimedean subclasses are only implemented for the bivariate case as they do not generate an Archimedean copula in higher dimensions. In the bivariate case, @eq-dmono can be interpreted as $\varphi$ being a convex function.</span>
<span id="cb18-83"><a href="#cb18-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-84"><a href="#cb18-84" aria-hidden="true" tabindex="-1"></a>The $\textsf{clayton}$ package implements common one-parameter families of Archimedean copulae, such as the Clayton (@10.2307/2335289), Gumbel (@1960), Joe (@joe1997multivariate), Frank (@Frank1979), and AMH (@ALI1978405) copulae for the multivariate case. It is worth noting that all Archimedean copulae are symmetric, and in dimensions 3 or higher, only positive associations are allowed. For the specific bivariate case, the package also implements other families, such as those numbered from 4.2.9 to 4.2.15 and 4.2.22 in Section 4.2 of @nelsen2007introduction. Definitions and illustrations of these parametric copula models can be found in @sec-bv_arch and @sec-mv_arch.</span>
<span id="cb18-85"><a href="#cb18-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-86"><a href="#cb18-86" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Extreme class {#sec-extreme}</span></span>
<span id="cb18-87"><a href="#cb18-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-88"><a href="#cb18-88" aria-hidden="true" tabindex="-1"></a>Investigating the notion of copulae within the framework of multivariate extreme value theory leads to the extreme value copulae (see @gudendorf2009extremevalue for an overview) defined as </span>
<span id="cb18-89"><a href="#cb18-89" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-90"><a href="#cb18-90" aria-hidden="true" tabindex="-1"></a>C(\textbf{u}) = \exp \left( - \ell(-\ln(u_0), \dots, -\ln(u_{d-1})) \right), \quad \textbf{u} \in (0,1]^d,</span>
<span id="cb18-91"><a href="#cb18-91" aria-hidden="true" tabindex="-1"></a>$$ {#eq-evc}</span>
<span id="cb18-92"><a href="#cb18-92" aria-hidden="true" tabindex="-1"></a>where $\ell: <span class="co">[</span><span class="ot">0,\infty)^d \rightarrow [0,\infty)$ the stable tail dependence function which is convex, homogeneous of order one, namely $\ell(c\textbf{x}) = c \ell(\textbf{x})$ for $c &gt; 0$ and satisfies $\max(x_0,\dots,x_{d-1})  \leq \ell(x_0,\dots,x_{d-1}) \leq x_0+\dots+x_{d-1}, \forall \textbf{x} \in [0,\infty)^d$. Let $\Delta^{d-1} = \{\textbf{w} \in [0,1</span><span class="co">]</span>^d: w_0 + \dots + w_{d-1} = 1<span class="sc">\}</span>$ be the unit simplex. The Pickands dependence function $A: \Delta^{d-1} \rightarrow <span class="co">[</span><span class="ot">1/d,1</span><span class="co">]</span>$ characterizes $\ell$ by its homogeneity, which is the restriction of $\ell$ to the unit simplex $\Delta^{d-1}$:</span>
<span id="cb18-93"><a href="#cb18-93" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-94"><a href="#cb18-94" aria-hidden="true" tabindex="-1"></a>  \ell(x_0, \dots,x_{d-1}) = (x_0 + \dots + x_{d-1}) A(w_0, \dots, w_{d-1}), \quad w_j = \frac{x_j}{x_0 + \dots + x_{d-1}},</span>
<span id="cb18-95"><a href="#cb18-95" aria-hidden="true" tabindex="-1"></a>$${#eq-tail_dependence_pickands}</span>
<span id="cb18-96"><a href="#cb18-96" aria-hidden="true" tabindex="-1"></a>for $j \in <span class="sc">\{</span>1,\dots,d-1<span class="sc">\}</span>$ and $w_0 = 1 - w_1 - \dots - w_{d-1}$ with $\textbf{x} \in [0, \infty)^d \setminus <span class="sc">\{</span>\textbf{0}<span class="sc">\}</span>$. The Pickands dependence function characterizes the extremal dependence structure of an extreme value random vector and verifies $\max<span class="sc">\{</span>w_0,\dots,w_{d-1}<span class="sc">\}</span> \leq A(w_0,\dots,w_{d-1}) \leq 1$ where the lower bound corresponds to comonotonicity and the upper bound corresponds to independence. Estimating this function is an active area of research, with many compelling studies having been conducted on the topic (see, for example, @bucher2011new, @GUDENDORF20123073).</span>
<span id="cb18-97"><a href="#cb18-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-98"><a href="#cb18-98" aria-hidden="true" tabindex="-1"></a>From a practical point of view, the family of extreme value copulae is very rich and arises naturally as the limiting distribution of properly normalised componentwise maxima. Furthermore, it contains a rich variety of parametric models and allows asymmetric dependence, that is, for the bivariate case:</span>
<span id="cb18-99"><a href="#cb18-99" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-100"><a href="#cb18-100" aria-hidden="true" tabindex="-1"></a>  \exists (u_0,u_1) \in <span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>^2, \quad C(u_0,u_1) \neq C(u_1,u_0).</span>
<span id="cb18-101"><a href="#cb18-101" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-102"><a href="#cb18-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-103"><a href="#cb18-103" aria-hidden="true" tabindex="-1"></a>In the multivariate framework, the logistic copula (or Gumbel, see @1960), the asymmetric logistic copula (@tawn1990), the Hüsler and Reiss distribution (@HUSLER1989283), the t-EV copula (@Demarta_Mcneil), Bilogistic model (@Smith1990) are implemented. It&#39;s worth noting that the logistic copula is the sole model that is both Archimedean and extreme value. The library includes bivariate extreme value copulae such as asymmetric negative logistic (@Joe1990FamiliesOM), asymmetric mixed (@10.1093/biomet/75.3.397). The reader is again invited to read from @sec-bv_ext to @sec-mv_ext for precise definitions of these models.</span>
<span id="cb18-104"><a href="#cb18-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-105"><a href="#cb18-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-106"><a href="#cb18-106" aria-hidden="true" tabindex="-1"></a><span class="fu"># Random number generator {#sec-rng}</span></span>
<span id="cb18-107"><a href="#cb18-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-108"><a href="#cb18-108" aria-hidden="true" tabindex="-1"></a>We propose a $\textsf{Python}$-based implementation for generating random numbers from a wide variety of copulae. The $\textsf{clayton}$ package requires a few external libraries that are commonly used in scientific computing in $\textsf{Python}$.</span>
<span id="cb18-109"><a href="#cb18-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-110"><a href="#cb18-110" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`numpy`</span> version 1.6.1 or newer. This is the fundamental package for scientific computing, it contains linear algebra functions and matrix / vector objects (@harris2020array).</span>
<span id="cb18-111"><a href="#cb18-111" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`scipy`</span> version 1.7.1 or newer. A library of open-source software for mathematics, science and engineering (@virtanen2020scipy).</span>
<span id="cb18-112"><a href="#cb18-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-113"><a href="#cb18-113" aria-hidden="true" tabindex="-1"></a>The $\textsf{clayton}$ package provides two methods for generating random vectors: $\texttt{sample<span class="sc">\_</span>unimargin}$ and $\texttt{sample}$. The first method generates a sample where the margins are uniformly distributed on the unit interval $<span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>$, while the second method generates a sample from the chosen margins.</span>
<span id="cb18-114"><a href="#cb18-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-115"><a href="#cb18-115" aria-hidden="true" tabindex="-1"></a>In @sec-biv_case, we present an algorithm that uses the conditioning method to sample from a copula. This method is very general and can be used for any copula that is sufficiently smooth (see @eq-cond_sim and @eq-cond_dist_mv below). However, the practical infeasibility of the algorithm in dimensions higher than $2$ and the computational intensity of numerical inversion call for more efficient ways to sample in higher dimensions. The purpose of @sec-mv_case is to present such methods and to provide details on the methods used in the $\textsf{clayton}$ package. In each section, we provide examples of code to illustrate how to instantiate a copula and how to sample with $\textsf{clayton}$.</span>
<span id="cb18-116"><a href="#cb18-116" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-117"><a href="#cb18-117" aria-hidden="true" tabindex="-1"></a>In the following sections, we will use $\textsf{Python}$ code that assumes that the following packages have been loaded:</span>
<span id="cb18-118"><a href="#cb18-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-119"><a href="#cb18-119" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb18-120"><a href="#cb18-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-121"><a href="#cb18-121" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb18-122"><a href="#cb18-122" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> clayton</span>
<span id="cb18-123"><a href="#cb18-123" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> clayton.rng <span class="im">import</span> base, evd, archimedean, monte_carlo</span>
<span id="cb18-124"><a href="#cb18-124" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb18-125"><a href="#cb18-125" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb18-126"><a href="#cb18-126" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb18-127"><a href="#cb18-127" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm, expon</span>
<span id="cb18-128"><a href="#cb18-128" aria-hidden="true" tabindex="-1"></a>plt.style.use(<span class="st">&#39;qb-light.mplstyle&#39;</span>) <span class="co"># for fancy figures</span></span>
<span id="cb18-129"><a href="#cb18-129" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">10</span>)</span>
<span id="cb18-130"><a href="#cb18-130" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-131"><a href="#cb18-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-132"><a href="#cb18-132" aria-hidden="true" tabindex="-1"></a><span class="fu">## The bivariate case {#sec-biv_case}</span></span>
<span id="cb18-133"><a href="#cb18-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-134"><a href="#cb18-134" aria-hidden="true" tabindex="-1"></a>In this subsection, we address the problem of generating a bivariate sample from a specified joint distribution with $d=2$. Suppose that we want to sample a bivariate random vector $\textbf{X}$ with copula $C$. In the case where the components are independent, the sampling procedure is straightforward: we can independently sample $X_0$ and $X_1$. However, in the general case where the copula is not the independent copula, this approach is not applicable.</span>
<span id="cb18-135"><a href="#cb18-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-136"><a href="#cb18-136" aria-hidden="true" tabindex="-1"></a>One solution to this problem is to use the conditioning method to sample from the copula. This method relies on the fact that given $(U_0, U_1)$ with copula $C$, the conditonal law of $U_1$ given $U_0$ is written as: </span>
<span id="cb18-137"><a href="#cb18-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-138"><a href="#cb18-138" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-139"><a href="#cb18-139" aria-hidden="true" tabindex="-1"></a>  c_{u_0}(u_1) \triangleq \mathbb{P}\left<span class="sc">\{</span> U_1 \leq u_1 | U_0 = u_0 \right<span class="sc">\}</span> = \frac{\partial C(u_0,u_1)}{\partial u_0}.</span>
<span id="cb18-140"><a href="#cb18-140" aria-hidden="true" tabindex="-1"></a>$$ {#eq-cond_sim}</span>
<span id="cb18-141"><a href="#cb18-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-142"><a href="#cb18-142" aria-hidden="true" tabindex="-1"></a>This allows us to first sample $U_0$ from a uniform distribution on the unit interval, and then to use the copula to generate $U_1$ given $U_0$. Finally, we can transform the resulting sample $(U_0, U_1)$ into the original space by applying the inverse marginal distributions $F_0^{-1}$ and $F_1^{-1}$ to $U_0$ and $U_1$ respectively. Thus, an algorithm for sampling bivariate copulae is given in @fig-alg_1. Algorithm in @fig-alg_1 presents a procedure for generating a bivariate sample from a copula. The algorithm takes as input the length of the sample $n$, as well as the parameters of the copula ($\theta, \psi_1, \psi_2$). The output is a bivariate sample from the desired copula model, denoted $<span class="sc">\{</span>(u_0^{(1)},u_1^{(1)}), \dots, (u_0^{(n)},u_1^{(n)})<span class="sc">\}</span>$. This algorithm is applicable as long as the copula has a first partial derivative with respect to its first component.</span>
<span id="cb18-143"><a href="#cb18-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-144"><a href="#cb18-144" aria-hidden="true" tabindex="-1"></a>::: {#fig-alg_1}</span>
<span id="cb18-145"><a href="#cb18-145" aria-hidden="true" tabindex="-1"></a><span class="al">![](figures/alg_1.png)</span></span>
<span id="cb18-146"><a href="#cb18-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-147"><a href="#cb18-147" aria-hidden="true" tabindex="-1"></a>Conditional sampling from copula</span>
<span id="cb18-148"><a href="#cb18-148" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-149"><a href="#cb18-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-150"><a href="#cb18-150" aria-hidden="true" tabindex="-1"></a>For step 6 of the algorithm, we need to find $u_1 \in <span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>$ such that $c_{u_0}(u_1) - t_1 = 0$ holds. This $u_1$ always exists because for every $u \in ]0,1<span class="co">[</span><span class="ot">$, we have $0 \leq c_{u_0}(u) \leq 1$, and the function $u \mapsto c_{u_0}(u)$ is increasing (see Theorem 2.2.7 of @nelsen2007introduction for a proof). This step can be solved using the \textsf{brentq} function from the \textsf{scipy} package. A sufficient condition for a copula to have a first partial derivative with respect to its first component in the Archimedean and extreme value cases is that the generator $\varphi$ and the Pickands dependence function $A$ are continuously differentiable on $</span><span class="co">]</span>0,1[$, respectively. In this case, the first partial derivatives of the copula are given by:</span>
<span id="cb18-151"><a href="#cb18-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-152"><a href="#cb18-152" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-153"><a href="#cb18-153" aria-hidden="true" tabindex="-1"></a>    \frac{\partial C}{\partial u_0}(u_0,u_1) = \frac{\varphi&#39;(u_0)}{\varphi&#39;(C(u_0,u_1))}, \quad (u_0,u_1) \in ]0,1[^2,</span>
<span id="cb18-154"><a href="#cb18-154" aria-hidden="true" tabindex="-1"></a>$$ {#eq-partial_deriv_arch}</span>
<span id="cb18-155"><a href="#cb18-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-156"><a href="#cb18-156" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-157"><a href="#cb18-157" aria-hidden="true" tabindex="-1"></a>    \frac{\partial C}{\partial u_0}(u_0,u_1) = \frac{\varphi&#39;(u_0)}{\varphi&#39;(C(u_0,u_1))}, \quad (u_0,u_1) \in ]0,1[^2,</span>
<span id="cb18-158"><a href="#cb18-158" aria-hidden="true" tabindex="-1"></a>$$ {#eq-partial_deriv_pick}</span>
<span id="cb18-159"><a href="#cb18-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-160"><a href="#cb18-160" aria-hidden="true" tabindex="-1"></a>where $t = \ln(u_1) / \ln(u_0u_1) \in (0,1)$ and $\mu(t) = A(t) - tA&#39;(t)$.</span>
<span id="cb18-161"><a href="#cb18-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-162"><a href="#cb18-162" aria-hidden="true" tabindex="-1"></a>We now have all the necessary theoretical tools to give details on how the $\textsf{clayton}$ package is designed. The file $\texttt{base.py}$ contains the $\textbf{Multivariate}$ class and the $\texttt{sample}$ method to generate random numbers from $\textbf{X}$ with copula $C$. To do so, we use the inversion method that is to sample from $\textbf{U}$ using algorithm in @fig-alg_1 and we compose the corresponding uniform margins by $F_j^\leftarrow$. \eqref{eq:cond_sim} indicates that the sole knowledge of $A$ and $\varphi$ and their respective derivatives are needed in order to perform the sixth step of algorithm in @fig-alg_1. For that purpose, $\texttt{cond<span class="sc">\_</span>sim}$ method located inside $\textbf{Archimedean}$ and $\textbf{Extreme}$ classes performs algorithm in @fig-alg_1. Then each child of the bivariate $\textbf{Archimedean}$ (resp. $\textbf{Extreme}$) class is thus defined by its generator $\varphi$ (resp. $A$), it&#39;s derivative $\varphi&#39;$ (resp. $A&#39;$) and it&#39;s inverse $\varphi^\leftarrow$ as emphasized in green in @fig-diagram. Namely, we perform algorithm in @fig-alg_1 for the $\textbf{Archimedean}$ subclasses $\texttt{Frank}$, $\texttt{AMH}$, $\texttt{Clayton}$ (when $\theta &lt; 0$ for the previous three), $\texttt{Nelsen<span class="sc">\_</span>9}$, $\texttt{Nelsen<span class="sc">\_</span>10}$, $\texttt{Nelsen<span class="sc">\_</span>11}$, $\texttt{Nelsen<span class="sc">\_</span>12}$, $\texttt{Nelsen<span class="sc">\_</span>13}$, $\texttt{Nelsen<span class="sc">\_</span>14}$, $\texttt{Nelsen<span class="sc">\_</span>15}$ and $\texttt{Nelsen<span class="sc">\_</span>22}$. For the $\textbf{Extreme}$ class, such algorithm is performed for the $\texttt{AsyNegLog}$ and $\texttt{AsyMix}$. For other models, faster algorithms are known and thus implemented, we refer to @sec-mv_case for details.</span>
<span id="cb18-163"><a href="#cb18-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-164"><a href="#cb18-164" aria-hidden="true" tabindex="-1"></a>The following code illustrates the random vector generation for a bivariate Archimedean copula. By defining the parameter of the copula and the sample&#39;s length, the constructor for this copula is available and can be called using the $\texttt{Clayton}$ method, such as:</span>
<span id="cb18-165"><a href="#cb18-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-166"><a href="#cb18-166" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb18-167"><a href="#cb18-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-168"><a href="#cb18-168" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb18-169"><a href="#cb18-169" aria-hidden="true" tabindex="-1"></a>  n_samples, theta <span class="op">=</span> <span class="dv">1024</span>, <span class="op">-</span><span class="fl">0.5</span></span>
<span id="cb18-170"><a href="#cb18-170" aria-hidden="true" tabindex="-1"></a>  copula <span class="op">=</span> archimedean.Clayton(theta<span class="op">=</span>theta, n_samples<span class="op">=</span>n_samples)</span>
<span id="cb18-171"><a href="#cb18-171" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-172"><a href="#cb18-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-173"><a href="#cb18-173" aria-hidden="true" tabindex="-1"></a>To obtain a sample with uniform margins and a Clayton copula, we can use the $\texttt{sample<span class="sc">\_</span>unimargin}$ method, as follows:</span>
<span id="cb18-174"><a href="#cb18-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-175"><a href="#cb18-175" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb18-176"><a href="#cb18-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-177"><a href="#cb18-177" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb18-178"><a href="#cb18-178" aria-hidden="true" tabindex="-1"></a>  sample <span class="op">=</span> copula.sample_unimargin()</span>
<span id="cb18-179"><a href="#cb18-179" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-180"><a href="#cb18-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-181"><a href="#cb18-181" aria-hidden="true" tabindex="-1"></a>Here, the $\texttt{sample}$ object is a $\textsf{numpy}$ array with $2$ columns and $1024$ rows, where each row contains a realization from a Clayton copula (see below)</span>
<span id="cb18-182"><a href="#cb18-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-183"><a href="#cb18-183" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb18-184"><a href="#cb18-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-185"><a href="#cb18-185" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb18-186"><a href="#cb18-186" aria-hidden="true" tabindex="-1"></a>  fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb18-187"><a href="#cb18-187" aria-hidden="true" tabindex="-1"></a>  ax.scatter(sample[:,<span class="dv">0</span>], sample[:,<span class="dv">1</span>],</span>
<span id="cb18-188"><a href="#cb18-188" aria-hidden="true" tabindex="-1"></a>             edgecolors<span class="op">=</span><span class="st">&#39;#6F6F6F&#39;</span>, color<span class="op">=</span><span class="st">&#39;#C5C5C5&#39;</span>, s<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb18-189"><a href="#cb18-189" aria-hidden="true" tabindex="-1"></a>  ax.set_xlabel(<span class="vs">r&#39;$u_0$&#39;</span>)</span>
<span id="cb18-190"><a href="#cb18-190" aria-hidden="true" tabindex="-1"></a>  ax.set_ylabel(<span class="vs">r&#39;$u_1$&#39;</span>)</span>
<span id="cb18-191"><a href="#cb18-191" aria-hidden="true" tabindex="-1"></a>  plt.show()</span>
<span id="cb18-192"><a href="#cb18-192" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-193"><a href="#cb18-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-194"><a href="#cb18-194" aria-hidden="true" tabindex="-1"></a><span class="fu">## The multivariate case {#sec-mv_case}</span></span>
<span id="cb18-195"><a href="#cb18-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-196"><a href="#cb18-196" aria-hidden="true" tabindex="-1"></a>We will now address the generation of multivariate Archimedean and Extreme value copulae proposed in the Clayton package. In the multivariate case, the link between partial derivatives and the conditional law remains. Indeed, let $(U_0, \dots, U_{d-1})$ be a $d$-dimensional random vector with uniform margins and copula $C$. The conditional distribution of $U_k$ given the values of $U_0, \dots, U_{k-1}$ is</span>
<span id="cb18-197"><a href="#cb18-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-198"><a href="#cb18-198" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-199"><a href="#cb18-199" aria-hidden="true" tabindex="-1"></a>  \mathbb{P}\left<span class="sc">\{</span> U_k \leq u_k | U_0 = u_0, \dots, U_{k-1} = u_{k-1} \right<span class="sc">\}</span> = \frac{\partial^{k-1} C(u_0, \dots, u_k,1,\dots,1)/\partial u_0 \dots \partial u_{k-1}}{\partial^{k-1} C(u_0, \dots, u_{k-1},1,\dots,1) / \partial u_0 \dots \partial u_{k-1}}.</span>
<span id="cb18-200"><a href="#cb18-200" aria-hidden="true" tabindex="-1"></a>$$ {#eq-cond_dist_mv}</span>
<span id="cb18-201"><a href="#cb18-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-202"><a href="#cb18-202" aria-hidden="true" tabindex="-1"></a>for $k \in {1,\dots, d-1}$. The conditional simulation algorithm may be written as follows.</span>
<span id="cb18-203"><a href="#cb18-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-204"><a href="#cb18-204" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Generate $d$ independent uniform random on $<span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>$ variates $v_0, \dots, v_{d-1}$.</span>
<span id="cb18-205"><a href="#cb18-205" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Set $u_0 = v_0$.</span>
<span id="cb18-206"><a href="#cb18-206" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>For $k = 1, \dots, d-1$, evaluate the inverse of the conditional distribution given by \eqref{eq:cond_dist_mv} at $v_k$, to generate $u_k$.</span>
<span id="cb18-207"><a href="#cb18-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-208"><a href="#cb18-208" aria-hidden="true" tabindex="-1"></a>Nevertheless, the evaluation of the inverse conditional distribution becomes increasingly complicated as the dimension $d$ increases. Furthermore, it can be difficult for some models to derive a closed form of @eq-cond_dist_mv that makes it impossible to implement it in a general algorithm with only the dimension $d$ as an input. For multivariate Archimedean copulae, @10.1214/07-AOS556 give a method to generate a random vector from the $d$-dimensional copula $C$ with generator $\varphi$ (see Section 5.2 of @10.1214/07-AOS556). A stochastic representation for Archimedean copulae generated by a $d$-monotone generator is given by</span>
<span id="cb18-209"><a href="#cb18-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-210"><a href="#cb18-210" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-211"><a href="#cb18-211" aria-hidden="true" tabindex="-1"></a>\textbf{U} = \left( \varphi^\leftarrow(R S_1), \dots, \varphi^\leftarrow(RS_d) \right) \sim C,</span>
<span id="cb18-212"><a href="#cb18-212" aria-hidden="true" tabindex="-1"></a>$$ {#eq-radial}</span>
<span id="cb18-213"><a href="#cb18-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-214"><a href="#cb18-214" aria-hidden="true" tabindex="-1"></a>where $R \sim F_R$, the radial distribution which is independent of $S$ and $S$ is distributed uniformly in the unit simplex $\Delta^{d-1}$. One challenging aspect of this algorithm is to have an accurate evaluation of the radial distribution of the Archimedean copula and thus to numerically inverse this distribution. The associated radial distribution for the $\textsf{Clayton}$ copula is given in Example 3.3 @10.1214/07-AOS556 while those of the $\textsf{Joe}$, $\textsf{AMH}$, $\textsf{Gumbel}$ and $\textsf{Frank}$ copulae are given in @hofert2012likelihood. In general, one can use numerical inversion algorithms for computing the inverse of the radial distribution, however it will lead to spurious numerical errors. Other algorithms exist when the generator is known to be the Laplace-Stieltjes transform, denoted as $\mathcal{LS}$, of some positive random variables (see @10.2307/2289314, @frees1998understanding). This positive random variable is often referenced as the frailty distribution. In this framework, Archimedean copulae allow for the stochastic representation</span>
<span id="cb18-215"><a href="#cb18-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-216"><a href="#cb18-216" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-217"><a href="#cb18-217" aria-hidden="true" tabindex="-1"></a>  \textbf{U} = \left( \varphi^\leftarrow (E_1/V), \dots, \varphi^\leftarrow(E_d /V)\right) \sim C,</span>
<span id="cb18-218"><a href="#cb18-218" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb18-219"><a href="#cb18-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-220"><a href="#cb18-220" aria-hidden="true" tabindex="-1"></a>with $V \sim F = \mathcal{LS}^{-1}<span class="co">[</span><span class="ot">\varphi^\leftarrow</span><span class="co">]</span>$ the frailty and $E_1, \dots, E_d$ are distributed i.i.d. according to a standard exponential and independent of $V$. Algorithm in @fig-alg_2 presents a procedure for generating a multivariate sample from an Archimedean copula where the frailty distribution is known. The algorithm takes as an input the length of the sample $n$, as well as the parameter of the copula $\theta$. The output is a $d$-variate sample from the desired copula model, denoted $<span class="sc">\{</span>(u_0^{(1)}, \dots, u_{d-1}^{(1)}), \dots, (u_0^{(n)},\dots,u_{d-1}^{(n)})<span class="sc">\}</span>$.</span>
<span id="cb18-221"><a href="#cb18-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-222"><a href="#cb18-222" aria-hidden="true" tabindex="-1"></a>::: {#fig-alg_2}</span>
<span id="cb18-223"><a href="#cb18-223" aria-hidden="true" tabindex="-1"></a><span class="al">![](figures/alg_2.png)</span></span>
<span id="cb18-224"><a href="#cb18-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-225"><a href="#cb18-225" aria-hidden="true" tabindex="-1"></a>Sampling from Archimedean copula using frailty distribution</span>
<span id="cb18-226"><a href="#cb18-226" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-227"><a href="#cb18-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-228"><a href="#cb18-228" aria-hidden="true" tabindex="-1"></a>In this framework, we define $\texttt{<span class="sc">\_</span>frailty<span class="sc">\_</span>sim}$ method defined inside the $\textbf{Archimedean}$ class which performs algorithm in @fig-alg_2. Then, each Archimedean copula is defined by the generator $\varphi$, it&#39;s inverse $\varphi^\leftarrow$ and the frailty distribution denoted as $\mathcal{LS}^{-1}<span class="co">[</span><span class="ot">\varphi^\leftarrow</span><span class="co">]</span>$ as long as we know the frailty. This is the case for $\texttt{Joe}$, $\texttt{Clayton}$, $\texttt{AMH}$ or $\texttt{Frank}$.</span>
<span id="cb18-229"><a href="#cb18-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-230"><a href="#cb18-230" aria-hidden="true" tabindex="-1"></a>For the extreme value case, algorithms have been proposed, as in @stephenson2003simulating (see Algorithms 2.1 and 2.2), who proposes sampling methods for the Gumbel and the asymmetric logistic model. These algorithms are implemented in the $\textsf{clayton}$ package. Note that these algorithms are model-specific, thus the $\texttt{sample<span class="sc">\_</span>unimargin}$ method is exceptionally located in the corresponding child of the multivariate $\textbf{Extreme}$ class. Another procedure designed by @10.1093/biomet/asw008 to sample from multivariate extreme value models using extremal functions (see Algorithm 2 in @10.1093/biomet/asw008) is also of prime interest. For the implemented models using this algorithm, namely $\textbf{Hüsler-Reiss}$, $\textbf{tEV}$, $\textbf{Bilogistic}$ and $\textbf{Dirichlet}$ models, a method called $\texttt{<span class="sc">\_</span>rextfunc}$ is located inside each classes which allows to generate an observation from the according law of the extremal function.</span>
<span id="cb18-231"><a href="#cb18-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-232"><a href="#cb18-232" aria-hidden="true" tabindex="-1"></a>Samples from the Gaussian and Student copula are directly given by Algorithm 5.9 and 5.10 respectively of @quantrisk. As each algorithm is model specific, the $\texttt{sample<span class="sc">\_</span>unimargin}$ method is located inside the $\textbf{Gaussian}$ and $\textbf{Student}$ classes.</span>
<span id="cb18-233"><a href="#cb18-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-234"><a href="#cb18-234" aria-hidden="true" tabindex="-1"></a>We present how to construct a multivariate Archimedean copula and to generate random vectors from this model. Introducing the parameters of the copula, we appeal the following lines to construct our copula object:</span>
<span id="cb18-235"><a href="#cb18-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-236"><a href="#cb18-236" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb18-237"><a href="#cb18-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-238"><a href="#cb18-238" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb18-239"><a href="#cb18-239" aria-hidden="true" tabindex="-1"></a>d, theta, n_samples <span class="op">=</span> <span class="dv">3</span>, <span class="fl">2.0</span>, <span class="dv">1024</span></span>
<span id="cb18-240"><a href="#cb18-240" aria-hidden="true" tabindex="-1"></a>copula <span class="op">=</span> archimedean.Clayton(theta<span class="op">=</span>theta, n_samples<span class="op">=</span>n_samples, dim<span class="op">=</span>d)</span>
<span id="cb18-241"><a href="#cb18-241" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-242"><a href="#cb18-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-243"><a href="#cb18-243" aria-hidden="true" tabindex="-1"></a>We now call the $\texttt{sample<span class="sc">\_</span>unimargin}$ method to obtain randomly generated vectors.</span>
<span id="cb18-244"><a href="#cb18-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-245"><a href="#cb18-245" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb18-246"><a href="#cb18-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-247"><a href="#cb18-247" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb18-248"><a href="#cb18-248" aria-hidden="true" tabindex="-1"></a>sample <span class="op">=</span> copula.sample_unimargin()</span>
<span id="cb18-249"><a href="#cb18-249" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-250"><a href="#cb18-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-251"><a href="#cb18-251" aria-hidden="true" tabindex="-1"></a>We thus represent in three dimensions these realizations below.</span>
<span id="cb18-252"><a href="#cb18-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-253"><a href="#cb18-253" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb18-254"><a href="#cb18-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-255"><a href="#cb18-255" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb18-256"><a href="#cb18-256" aria-hidden="true" tabindex="-1"></a>  fig <span class="op">=</span> plt.figure()</span>
<span id="cb18-257"><a href="#cb18-257" aria-hidden="true" tabindex="-1"></a>  ax <span class="op">=</span> fig.add_subplot(<span class="dv">111</span>, projection <span class="op">=</span> <span class="st">&#39;3d&#39;</span>)</span>
<span id="cb18-258"><a href="#cb18-258" aria-hidden="true" tabindex="-1"></a>  ax.scatter3D(sample[:,<span class="dv">0</span>], sample[:,<span class="dv">1</span>], sample[:,<span class="dv">2</span>], s<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb18-259"><a href="#cb18-259" aria-hidden="true" tabindex="-1"></a>               edgecolors<span class="op">=</span><span class="st">&#39;#6F6F6F&#39;</span>, color<span class="op">=</span><span class="st">&#39;#C5C5C5&#39;</span>)</span>
<span id="cb18-260"><a href="#cb18-260" aria-hidden="true" tabindex="-1"></a>  ax.set_xlabel(<span class="vs">r&#39;$u_0$&#39;</span>)</span>
<span id="cb18-261"><a href="#cb18-261" aria-hidden="true" tabindex="-1"></a>  ax.set_ylabel(<span class="vs">r&#39;$u_1$&#39;</span>)</span>
<span id="cb18-262"><a href="#cb18-262" aria-hidden="true" tabindex="-1"></a>  ax.set_zlabel(<span class="vs">r&#39;$u_2$&#39;</span>)</span>
<span id="cb18-263"><a href="#cb18-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-264"><a href="#cb18-264" aria-hidden="true" tabindex="-1"></a>  plt.show()</span>
<span id="cb18-265"><a href="#cb18-265" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-266"><a href="#cb18-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-267"><a href="#cb18-267" aria-hidden="true" tabindex="-1"></a><span class="fu"># Case study : Modeling pairwise dependence between spatial maximas with missing data {#sec-pairwise}</span></span>
<span id="cb18-268"><a href="#cb18-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-269"><a href="#cb18-269" aria-hidden="true" tabindex="-1"></a>We now proceed to a case study where we use our \textsf{python} package to assess, under a finite sample framework, the asymptotic properties of an estimator of the $\lambda$-madogram when data are completely missing at random (MCAR). This case study comes from numerical results of @boulin2021non. The $\lambda$-madogram belongs to a family of estimators, namely the madogram, which is of prime interest in environmental sciences, as it is designed to model pairwise dependence between maxima in space, see, e.g., @bernard:hal-03207469, @BADOR201517, @saunders where the madogram was used as a dissimilarity measure to perform clustering. Where in several fields, for example econometrics (@woolridge2007) or survey theory (@chauvet2015), the MCAR hypothesis appears to be a strong hypothesis, this hypothesis is more realistic in environmental research as the missingness of one observation is usually due to instruments, communication and processing errors that may be reasonably supposed independent of the quantity of interest. In @sec-background, we define objects and properties of interest while in @sec-num we describe a detailed tutorial in $\textsf{python}$ and with $\textsf{clayton}$ package to compare the asymptotic variance with an empirical counterpart of the $\lambda$-madogram with $\lambda = 0.5$.</span>
<span id="cb18-270"><a href="#cb18-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-271"><a href="#cb18-271" aria-hidden="true" tabindex="-1"></a><span class="fu">## Background {#sec-background}</span></span>
<span id="cb18-272"><a href="#cb18-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-273"><a href="#cb18-273" aria-hidden="true" tabindex="-1"></a>It was emphasized that the possible dependence between maxima can be described with the extreme value copula. This function is completely characterized by the Pickands dependence function (see @eq-tail_dependence_pickands) where the latter is equivalent to the $\lambda$-madogram introduced by @naveau:hal-00312758 and defined as  </span>
<span id="cb18-274"><a href="#cb18-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-275"><a href="#cb18-275" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb18-276"><a href="#cb18-276" aria-hidden="true" tabindex="-1"></a>  \nu(\lambda) = \mathbb{E}\left<span class="co">[</span><span class="ot"> \left|\{F_0(X_0)\}^{1/\lambda} - \{F_1(X_1)\}^{1/(1-\lambda)} \right|\right</span><span class="co">]</span>,</span>
<span id="cb18-277"><a href="#cb18-277" aria-hidden="true" tabindex="-1"></a>$$ {#eq-lmbd_mado}</span>
<span id="cb18-278"><a href="#cb18-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-279"><a href="#cb18-279" aria-hidden="true" tabindex="-1"></a>with $\lambda \in (0,1)$, and if $\lambda = 0$ and $0&lt;u&lt;1$, then $u^{1/\lambda} = 0$ by convention. The $\lambda$-madogram took its inspiration from the extensively used geostatistics tool, the variogram (see Chapter 1.3 of @alma991005826659705596 for a definition and some classical properties). The $\lambda$-madogram can be interpreted as the $L_1$-distance between the uniform margins elevated to the inverse of the corresponding weights $\lambda$ and $1-\lambda$. This quantity describes the dependence structure between extremes by its relation with the Pickands dependence function. If we suppose that $C$ is an extreme value copula as in \eqref{eq:evc}, we have</span>
<span id="cb18-280"><a href="#cb18-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-281"><a href="#cb18-281" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb18-282"><a href="#cb18-282" aria-hidden="true" tabindex="-1"></a>  A(\lambda) = \frac{\nu(\lambda) + c(\lambda)}{1-\nu(\lambda) - c(\lambda)},</span>
<span id="cb18-283"><a href="#cb18-283" aria-hidden="true" tabindex="-1"></a>$$ {#eq-pickands_mado}</span>
<span id="cb18-284"><a href="#cb18-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-285"><a href="#cb18-285" aria-hidden="true" tabindex="-1"></a>with $c(\lambda) = 2^{-1} (\lambda / (1-\lambda) + (1-\lambda)/\lambda)$ (see Proposition 3 of @MARCON20171 for details).</span>
<span id="cb18-286"><a href="#cb18-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-287"><a href="#cb18-287" aria-hidden="true" tabindex="-1"></a>We consider independent and identically distributed i.i.d. copies $\textbf{X}_1, \dots, \textbf{X}_n$ of $\textbf{X}$. In presence of missing data, we do not observe a complete vector $\textbf{X}_i$ for $i \in \{1,\dots,n\}$. We introduce $\textbf{I}_i \in \{0,1\}^2$ which satisfies, $\forall j \in \{0,1\}$, if $X_{i,j}$ is not observed then $I_{i,j} = 0$. To formalize incomplete observations, we introduce the incomplete vector $\tilde{\textbf{X}}_i$ with values in the product space $\bigotimes_{j=1}^2 (\mathbb{R} \cup <span class="sc">\{</span>\textsf{NA}<span class="sc">\}</span>)$ such as</span>
<span id="cb18-288"><a href="#cb18-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-289"><a href="#cb18-289" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-290"><a href="#cb18-290" aria-hidden="true" tabindex="-1"></a>  \tilde{X}_{i,j} = X_{i,j} I_{i,j} + \textsf{NA} (1-I_{i,j}), \quad i \in <span class="sc">\{</span>1,\dots,n<span class="sc">\}</span>, \, j \in <span class="sc">\{</span>0,\dots, d-1<span class="sc">\}</span>.</span>
<span id="cb18-291"><a href="#cb18-291" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-292"><a href="#cb18-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-293"><a href="#cb18-293" aria-hidden="true" tabindex="-1"></a>We thus suppose that we observe a $4$-tuple such as</span>
<span id="cb18-294"><a href="#cb18-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-295"><a href="#cb18-295" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb18-296"><a href="#cb18-296" aria-hidden="true" tabindex="-1"></a>  (\textbf{I}_i, \tilde{\textbf{X}}_i), \quad i \in <span class="sc">\{</span>1,\dots,n<span class="sc">\}</span>,</span>
<span id="cb18-297"><a href="#cb18-297" aria-hidden="true" tabindex="-1"></a>$$ {#eq-missing_2}</span>
<span id="cb18-298"><a href="#cb18-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-299"><a href="#cb18-299" aria-hidden="true" tabindex="-1"></a>i.e. at each $i \in <span class="sc">\{</span>1,\dots,n<span class="sc">\}</span>$, several entries may be missing. We also suppose that for all $i \in <span class="sc">\{</span>1, \dots,n <span class="sc">\}</span>$, $\textbf{I}_{i}$ are i.i.d copies from $\textbf{I} = (I_0, I_1)$ where $I_j$ is distributed according to a Bernoulli random variable $\mathcal{B}(p_j)$ with $p_j = \mathbb{P}(I_j = 1)$ for $j \in <span class="sc">\{</span>0,1<span class="sc">\}</span>$. We denote by $p$ the probability of observing completely a realization from $\textbf{X}$, that is $p = \mathbb{P}(I_0=1, I_1 = 1)$. In @boulin2021non, hybrid and corrected estimators, respectively denoted as $\hat{\nu}_n^{\mathcal{H}}$ and $\hat{\nu}_n^{\mathcal{H*}}$, are proposed to estimate nonparametrically the $\lambda$-madogram in presence of missing data completely at random. Furthermore, a closed expression of their asymptotic variances for $\lambda \in ]0,1[$ is also given. This result is summarized in the following proposition.</span>
<span id="cb18-300"><a href="#cb18-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-301"><a href="#cb18-301" aria-hidden="true" tabindex="-1"></a>::: {#thm-line}</span>
<span id="cb18-302"><a href="#cb18-302" aria-hidden="true" tabindex="-1"></a><span class="fu">## @boulin2021non</span></span>
<span id="cb18-303"><a href="#cb18-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-304"><a href="#cb18-304" aria-hidden="true" tabindex="-1"></a>Let $(\textbf{I}_i, \tilde{\textbf{X}_i})_{i=1}^n$ be a samble given by @eq-missing_2. For $\lambda \in ]0,1[$, if $C$ is </span>
<span id="cb18-305"><a href="#cb18-305" aria-hidden="true" tabindex="-1"></a>an extreme value copula with Pickands dependence function $A$, we have as $n \rightarrow \infty$</span>
<span id="cb18-306"><a href="#cb18-306" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb18-307"><a href="#cb18-307" aria-hidden="true" tabindex="-1"></a>    &amp;\sqrt{n} \left(\hat{\nu}_n^{\mathcal{H}}(\lambda) - \nu( \lambda)\right) \overset{d}{\rightarrow} \mathcal{N}\left(0, \mathcal{S}^{\mathcal{H}}(p_1,p_2,p, \lambda)\right), <span class="sc">\\</span> </span>
<span id="cb18-308"><a href="#cb18-308" aria-hidden="true" tabindex="-1"></a>    &amp;\sqrt{n} \left(\hat{\nu}_n^{\mathcal{H}*}(\lambda) - \nu( \lambda)\right) \overset{d}{\rightarrow} \mathcal{N}\left(0, \mathcal{S}^{\mathcal{H}*}(p_1,p_2,p, \lambda)\right),</span>
<span id="cb18-309"><a href="#cb18-309" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb18-310"><a href="#cb18-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-311"><a href="#cb18-311" aria-hidden="true" tabindex="-1"></a>where $\mathcal{S}^{\mathcal{H}}(p_1,p_2,p, \lambda)$ and $\mathcal{S}^{\mathcal{H}*}(p_1,p_2,p, \lambda)$ are the </span>
<span id="cb18-312"><a href="#cb18-312" aria-hidden="true" tabindex="-1"></a>asymptoptic variances of the random variables.</span>
<span id="cb18-313"><a href="#cb18-313" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-314"><a href="#cb18-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-315"><a href="#cb18-315" aria-hidden="true" tabindex="-1"></a><span class="fu">## Numerical results {#sec-num}</span></span>
<span id="cb18-316"><a href="#cb18-316" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-317"><a href="#cb18-317" aria-hidden="true" tabindex="-1"></a>Benefiting from generating data with $\textsf{clayton}$ we are thus able, with Monte Carlo simulation, to assess theoretical results given by @thm-line in a finite sample setting. For that purpose, we implement a $\textsf{MonteCarlo}$ class (in $\texttt{monte<span class="sc">\_</span>carlo.py}$ file) which contains some methods to perform some Monte Carlo iterations for a given extreme value copula. Now, we set up parameters to sample our bivariate dataset. For this subsection, we choose the asymmetric negative logistic model (see @sec-bv_ext for a definition) with parameters $\theta = 10, \psi_1 = 0.1, \psi_2 = 1.0$ and we define the following function:</span>
<span id="cb18-318"><a href="#cb18-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-319"><a href="#cb18-319" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb18-320"><a href="#cb18-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-321"><a href="#cb18-321" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb18-322"><a href="#cb18-322" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> gauss_function(x, x0, sigma):</span>
<span id="cb18-323"><a href="#cb18-323" aria-hidden="true" tabindex="-1"></a>      <span class="cf">return</span> (np.sqrt(<span class="fl">1.</span> <span class="op">/</span> (<span class="dv">2</span><span class="op">*</span>np.pi <span class="op">*</span> sigma<span class="op">**</span><span class="dv">2</span>)) <span class="op">*</span></span>
<span id="cb18-324"><a href="#cb18-324" aria-hidden="true" tabindex="-1"></a>              np.exp(<span class="op">-</span>(x <span class="op">-</span> x0) <span class="op">**</span> <span class="dv">2</span> <span class="op">/</span> (<span class="dv">2</span> <span class="op">*</span> sigma<span class="op">**</span><span class="dv">2</span>)))</span>
<span id="cb18-325"><a href="#cb18-325" aria-hidden="true" tabindex="-1"></a>  n_samples <span class="op">=</span> <span class="dv">512</span></span>
<span id="cb18-326"><a href="#cb18-326" aria-hidden="true" tabindex="-1"></a>  theta, psi1, psi2 <span class="op">=</span> <span class="dv">10</span>, <span class="fl">0.1</span>, <span class="fl">1.0</span></span>
<span id="cb18-327"><a href="#cb18-327" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-328"><a href="#cb18-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-329"><a href="#cb18-329" aria-hidden="true" tabindex="-1"></a>We choose the standard normal and exponential as margins. To simulate this sample, the following lines should be typed:</span>
<span id="cb18-330"><a href="#cb18-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-331"><a href="#cb18-331" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb18-332"><a href="#cb18-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-333"><a href="#cb18-333" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb18-334"><a href="#cb18-334" aria-hidden="true" tabindex="-1"></a>  copula <span class="op">=</span> evd.AsyNegLog(theta<span class="op">=</span>theta, psi1<span class="op">=</span>psi1,</span>
<span id="cb18-335"><a href="#cb18-335" aria-hidden="true" tabindex="-1"></a>                         psi2<span class="op">=</span>psi2, n_samples<span class="op">=</span>n_samples)</span>
<span id="cb18-336"><a href="#cb18-336" aria-hidden="true" tabindex="-1"></a>  sample <span class="op">=</span> copula.sample(inv_cdf<span class="op">=</span>[norm.ppf, expon.ppf])</span>
<span id="cb18-337"><a href="#cb18-337" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-338"><a href="#cb18-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-339"><a href="#cb18-339" aria-hidden="true" tabindex="-1"></a>The $1024 \times 2$ array $\texttt{sample}$ contains $1024$ realization of the $\textbf{asymmetric negative logistic}$ model where the first column is distributed according to a standard normal random variable and the second column as a standard exponential. This distribution is depicted below. To obtain it, one needs the following lines of command:</span>
<span id="cb18-340"><a href="#cb18-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-341"><a href="#cb18-341" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb18-342"><a href="#cb18-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-343"><a href="#cb18-343" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb18-344"><a href="#cb18-344" aria-hidden="true" tabindex="-1"></a>  fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb18-345"><a href="#cb18-345" aria-hidden="true" tabindex="-1"></a>  ax.scatter(sample[:,<span class="dv">0</span>], sample[:,<span class="dv">1</span>],</span>
<span id="cb18-346"><a href="#cb18-346" aria-hidden="true" tabindex="-1"></a>             edgecolors<span class="op">=</span><span class="st">&quot;#6F6F6F&quot;</span>, color<span class="op">=</span><span class="st">&quot;#C5C5C5&quot;</span>, s<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb18-347"><a href="#cb18-347" aria-hidden="true" tabindex="-1"></a>  ax.set_xlabel(<span class="vs">r&#39;$x_0$&#39;</span>)</span>
<span id="cb18-348"><a href="#cb18-348" aria-hidden="true" tabindex="-1"></a>  ax.set_ylabel(<span class="vs">r&#39;$x_1$&#39;</span>)</span>
<span id="cb18-349"><a href="#cb18-349" aria-hidden="true" tabindex="-1"></a>  plt.show()</span>
<span id="cb18-350"><a href="#cb18-350" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-351"><a href="#cb18-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-352"><a href="#cb18-352" aria-hidden="true" tabindex="-1"></a>Before going into further details, we will present the missing mechanism. Let $V_0$ and $V_1$ be random variables uniformly distributed under the $]0,1[$ segment with copula $C_{(V_0,V_1)}$. We set $I_0 = 1<span class="sc">\{</span>{V_0 \leq p_0}<span class="sc">\}</span>$ and $I_1 = 1<span class="sc">\{</span>{V_1 \leq p_1}<span class="sc">\}</span>$. It is thus immediate that $I_0 \sim \mathcal{B}(p_0)$ and $I_1 \sim \mathcal{B}(p_1)$ and $p \triangleq \mathbb{P}<span class="sc">\{</span>I_0 = 1, I_1 =1 <span class="sc">\}</span> = C_{(V_0,V_1)}(p_0, p_1)$. For our illustration, we will take $C_{(V_0,V_1)}$ as a \texttt{Joe} copula with parameter $\theta = 2.0$ (we refer to @sec-bv_arch for a definition of this copula). For this copula, it is more likely to observe a realization $v_0 \geq 0.8$ from $V_0$ if $v_1 \geq 0.8$ from $V_1$. If we observe $v_1 &lt; 0.8$, the realization $v_0$ is close to being independent of $v_1$. In climate studies, extreme events could damage the recording instrument in the surrounding regions where they occur, thus the missingness of one variable may depend on others. We initialize the copula $C_{(V_0,V_1)}$ with the following line:</span>
<span id="cb18-353"><a href="#cb18-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-354"><a href="#cb18-354" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb18-355"><a href="#cb18-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-356"><a href="#cb18-356" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb18-357"><a href="#cb18-357" aria-hidden="true" tabindex="-1"></a>  copula_miss <span class="op">=</span> archimedean.Joe(theta<span class="op">=</span><span class="fl">2.0</span>, n_samples<span class="op">=</span>n_samples)</span>
<span id="cb18-358"><a href="#cb18-358" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-359"><a href="#cb18-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-360"><a href="#cb18-360" aria-hidden="true" tabindex="-1"></a>For a given $\lambda \in ]0,1[$, we now want to estimate a $\lambda$-madogram with a sample from the asymmetric negative logistic model, where some observations are missing due to the missing mechanism described above. We will repeat this step several times to compute an empirical counterpart of the asymptotic variance. The \texttt{MonteCarlo} object has been designed for this purpose: we specify the number of iterations $n_{iter}$ (take $n_{iter} = 1024$), the chosen extreme value copula (asymmetric negative logistic model), the missing mechanism (described by $C_{(V_0,V_1)}$ and $p_0 = p_1 = 0.9$), and $\lambda$ (noted $\texttt{w}$). We can write the following lines of code:</span>
<span id="cb18-361"><a href="#cb18-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-362"><a href="#cb18-362" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb18-363"><a href="#cb18-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-364"><a href="#cb18-364" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb18-365"><a href="#cb18-365" aria-hidden="true" tabindex="-1"></a>  u <span class="op">=</span> np.array([<span class="fl">0.9</span>, <span class="fl">0.9</span>])</span>
<span id="cb18-366"><a href="#cb18-366" aria-hidden="true" tabindex="-1"></a>  n_iter, P, w <span class="op">=</span> <span class="dv">256</span>, [[u[<span class="dv">0</span>], copula_miss._c(</span>
<span id="cb18-367"><a href="#cb18-367" aria-hidden="true" tabindex="-1"></a>      u)], [copula_miss._c(u), u[<span class="dv">1</span>]]], np.array([<span class="fl">0.5</span>,<span class="fl">0.5</span>])</span>
<span id="cb18-368"><a href="#cb18-368" aria-hidden="true" tabindex="-1"></a>  monte <span class="op">=</span> monte_carlo.MonteCarlo(n_iter<span class="op">=</span>n_iter, n_samples<span class="op">=</span>n_samples,</span>
<span id="cb18-369"><a href="#cb18-369" aria-hidden="true" tabindex="-1"></a>                                 copula<span class="op">=</span>copula, copula_miss<span class="op">=</span>copula_miss,</span>
<span id="cb18-370"><a href="#cb18-370" aria-hidden="true" tabindex="-1"></a>                                 weight<span class="op">=</span>w, matp<span class="op">=</span>P)</span>
<span id="cb18-371"><a href="#cb18-371" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-372"><a href="#cb18-372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-373"><a href="#cb18-373" aria-hidden="true" tabindex="-1"></a>The $\texttt{MonteCarlo}$ object is thus initialized with all parameters needed. We may use the $\texttt{simu}$ method to generate a $\texttt{DataFrame}$ (a $\texttt{pandas}$ object) composed out $1024$ rows and $3$ columns. Each row contains an estimate of the $\lambda$-madogram, $\hat{\nu}_n^{\mathcal{H}*}$ in @thm-line ($\texttt{var<span class="sc">\_</span>mado}$), the sample length $n$ ($\texttt{n}$) and the normalized estimation error ($\texttt{scaled}$). We thus call the $\texttt{simu}$ method.</span>
<span id="cb18-374"><a href="#cb18-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-375"><a href="#cb18-375" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb18-376"><a href="#cb18-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-377"><a href="#cb18-377" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb18-378"><a href="#cb18-378" aria-hidden="true" tabindex="-1"></a>  df_wmado <span class="op">=</span> monte.finite_sample(inv_cdf<span class="op">=</span>[norm.ppf, expon.ppf], corr<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb18-379"><a href="#cb18-379" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(df_wmado.head())</span>
<span id="cb18-380"><a href="#cb18-380" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-381"><a href="#cb18-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-382"><a href="#cb18-382" aria-hidden="true" tabindex="-1"></a>The argument $\texttt{corr=True}$ specifies that we compute the corrected estimator, $\hat{\nu}_n^{\mathcal{H}*}$ in @thm-line. Now, using the $\texttt{var\_mado}$ method defined inside in the **Extreme** class, we obtain the asymptotic variance for the given model and parameters from the missing mechanism. We obtain this quantity as follows</span>
<span id="cb18-383"><a href="#cb18-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-384"><a href="#cb18-384" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb18-385"><a href="#cb18-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-386"><a href="#cb18-386" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb18-387"><a href="#cb18-387" aria-hidden="true" tabindex="-1"></a>  var_mado <span class="op">=</span> copula.var_mado(w, jointp<span class="op">=</span>copula_miss._c(u), matp<span class="op">=</span>P, corr<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb18-388"><a href="#cb18-388" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(var_mado)</span>
<span id="cb18-389"><a href="#cb18-389" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(df_wmado[<span class="st">&#39;scaled&#39;</span>].var())</span>
<span id="cb18-390"><a href="#cb18-390" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-391"><a href="#cb18-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-392"><a href="#cb18-392" aria-hidden="true" tabindex="-1"></a>We propose here to check numerically the asymptotic normality with variance $\mathcal{S}^{\mathcal{H}*}$ of the normalized estimation error of the corrected estimator. We have all data in hand and the asymptotic variance was computed by lines above. We thus write:</span>
<span id="cb18-393"><a href="#cb18-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-394"><a href="#cb18-394" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb18-395"><a href="#cb18-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-396"><a href="#cb18-396" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb18-397"><a href="#cb18-397" aria-hidden="true" tabindex="-1"></a>    sigma <span class="op">=</span> np.sqrt(var_mado)</span>
<span id="cb18-398"><a href="#cb18-398" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> np.linspace(<span class="bu">min</span>(df_wmado[<span class="st">&#39;scaled&#39;</span>]), <span class="bu">max</span>(df_wmado[<span class="st">&#39;scaled&#39;</span>]), <span class="dv">1000</span>)</span>
<span id="cb18-399"><a href="#cb18-399" aria-hidden="true" tabindex="-1"></a>    gauss <span class="op">=</span> gauss_function(x, <span class="dv">0</span>, sigma)</span>
<span id="cb18-400"><a href="#cb18-400" aria-hidden="true" tabindex="-1"></a>    sns.displot(data<span class="op">=</span>df_wmado, x<span class="op">=</span><span class="st">&quot;scaled&quot;</span>, color<span class="op">=</span><span class="st">&#39;#C5C5C5&#39;</span>,</span>
<span id="cb18-401"><a href="#cb18-401" aria-hidden="true" tabindex="-1"></a>                kind<span class="op">=</span><span class="st">&#39;hist&#39;</span>, stat<span class="op">=</span><span class="st">&#39;density&#39;</span>, common_norm<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb18-402"><a href="#cb18-402" aria-hidden="true" tabindex="-1"></a>                alpha<span class="op">=</span><span class="fl">0.5</span>, fill<span class="op">=</span><span class="va">True</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>, bins<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb18-403"><a href="#cb18-403" aria-hidden="true" tabindex="-1"></a>    plt.plot(x,gauss, color<span class="op">=</span><span class="st">&#39;#6F6F6F&#39;</span>)</span>
<span id="cb18-404"><a href="#cb18-404" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-405"><a href="#cb18-405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-406"><a href="#cb18-406" aria-hidden="true" tabindex="-1"></a><span class="fu"># Discussion {#sec-discussion}</span></span>
<span id="cb18-407"><a href="#cb18-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-408"><a href="#cb18-408" aria-hidden="true" tabindex="-1"></a><span class="fu">## Comparison of $\textsf{clayton}$ with $\textsf{R}$ packages</span></span>
<span id="cb18-409"><a href="#cb18-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-410"><a href="#cb18-410" aria-hidden="true" tabindex="-1"></a>To compare \textsf{clayton} to existing packages in $\textsf{R}$, we consider the $\textsf{copula}$ package (@kojadinovic2010modeling) and $\textsf{mev}$ (@mevR) for sampling from Archimedean and multivariate extreme value distributions, respectively. To run the experiment, we use two computer clusters. The first cluster consists of five nodes, each with two 18-core Xeon Gold 3.1 GHz processors and 192 GB of memory, with 2933 MHz per socket. The second cluster has two CPU sockets, each containing a Xeon Platinum 8268 2.90 GHz processor with 24 cores. These configurations provide a significant amount of computational power and are well-suited for handling complex, data-intensive tasks. We use the first cluster to install the $\textsf{copula}$ package and sample from the $\textbf{Clayton}$, $\textbf{Frank}$, and $\textbf{Joe}$ models. We consider an increasing dimension $d \in <span class="sc">\{</span>50, 100, \dots, 1600<span class="sc">\}</span>$ for a fixed sample size of $n=1000$. For the copula package, we compute the average time spent across 100 runs in order to cancel out variability. We use the second cluster to install the $\textsf{mev}$ package and call some of its methods to sample from the $\textbf{Husler Reiss}$, $\textbf{Logistic}$, and $\textbf{TEV}$ distributions. Sampling from the latter is fast, but sampling from the two others is time consuming. Therefore, we only consider dimensions $d \in <span class="sc">\{</span>25, 50, \dots, 250<span class="sc">\}</span>$ for a fixed sample size of $n=1000$.</span>
<span id="cb18-411"><a href="#cb18-411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-412"><a href="#cb18-412" aria-hidden="true" tabindex="-1"></a>::: {#fig-num_res layout-ncol=2}</span>
<span id="cb18-413"><a href="#cb18-413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-414"><a href="#cb18-414" aria-hidden="true" tabindex="-1"></a><span class="al">![Archimedean](figures/discussion/num_time_arch.png)</span></span>
<span id="cb18-415"><a href="#cb18-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-416"><a href="#cb18-416" aria-hidden="true" tabindex="-1"></a><span class="al">![Multivariate extreme value](figures/discussion/num_time_evd.png)</span></span>
<span id="cb18-417"><a href="#cb18-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-418"><a href="#cb18-418" aria-hidden="true" tabindex="-1"></a>Comparison results. Time spent (in seconds) to sample from the corresponding models with respect to the dimension $d$. The left panel shows the results for sampling from $\textbf{Clayton}$, $\textbf{Frank}$ and $\textbf{Joe}$ using $\textsf{clayton}$ in $\textsf{Python}$ and $\textsf{copula}$ in $\textsf{R}$. The right panel shows the results for sampling from $\textbf{HuslerReiss}$, $\textbf{Logistic}$ and $\textbf{TEV}$ by $\textsf{clayton}$ in $\textsf{Python}$ and $\textsf{mev}$ in $\textsf{R}$. In both cases, $1000$ vectors are generated for each model.</span>
<span id="cb18-419"><a href="#cb18-419" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-420"><a href="#cb18-420" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-421"><a href="#cb18-421" aria-hidden="true" tabindex="-1"></a>The figure shows the results of a comparison between the $\textsf{clayton}$ and $\textsf{copula}$ packages in $\textsf{R}$, and the $\textsf{mev}$ package in $\textsf{Python}$. The comparison shows that the $\textsf{clayton}$ package is more efficient at sampling from $\textbf{Clayton}$, $\textbf{Frank}$ and $\textbf{Joe}$ copulae than the $\textsf{copula}$ package. The gap in efficiency may be due to the choice of algorithms used in the $\textsf{clayton}$ package, which uses frailty distributions. The time required for sampling increases linearly with the dimension for the $\textsf{clayton}$ package, but shows a more erratic behavior for the $\textsf{copula}$ package.</span>
<span id="cb18-422"><a href="#cb18-422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-423"><a href="#cb18-423" aria-hidden="true" tabindex="-1"></a><span class="fu">## Conclusion</span></span>
<span id="cb18-424"><a href="#cb18-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-425"><a href="#cb18-425" aria-hidden="true" tabindex="-1"></a>This paper presents the construction and some implementations of the $\textsf{Python}$ package $\textsf{clayton}$ for random copula sampling. This is a seminal work in the field of software implementation of copula modeling in $\textsf{Python}$ and there is much more potential for growth. It is hoped that the potential diffusion of the software through those who need it may bring further implementations for multivariate modeling with copulae under $\textsf{Python}$. For example, choosing a copula to fit the data is an important but difficult problem. A robust approach to estimating copulae has been investigated recently by @alquier2020estimation using Maximum Mean Discrepancy. In relation to our example, semiparametric estimation of copulae with missing data could be of great interest, as proposed by @HAMORI201985.</span>
<span id="cb18-426"><a href="#cb18-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-427"><a href="#cb18-427" aria-hidden="true" tabindex="-1"></a>Additionally, implementation of the algorithm proposed by @10.1214/07-AOS556 for generating random vectors for Archimedean copulae has been tackled, but as expected, numerical inversion gives spurious results, especially when the parameter $\theta$ and the dimension $d$ are high. Furthermore, as the support of the radial distribution is contained in the real line, numerical inversion leads to increased computational time. Further investigation is needed in order to generate random vectors from classical Archimedan models using the radial distribution.</span>
<span id="cb18-428"><a href="#cb18-428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-429"><a href="#cb18-429" aria-hidden="true" tabindex="-1"></a>A direction of improvement for the $\textsf{clayton}$ package is dependence modeling with Vine copulae, which have recently been a tool of high interest in the machine learning community (see, e.g., @lopez2013gaussian, @Veeramachaneni2015CopulaGM, @Carrera2016VineCC, @10.5555/2946645.2946678 or @SunCuesta-InfanteVeeramachaneni2019). This highlights the need for dependence modeling with copulae in $\textsf{Python}$, as a significant part of the machine learning community uses this language. In relation to this paper, Vine copulae may be useful for modeling dependencies between extreme events, as suggested by @SIMPSON2021104736, @nolde2021linking. Furthermore, other copula models could be implemented to model further dependencies. These implementations will expand the scope of dependence modeling with $\textsf{Python}$ and provide high-quality, usable tools for anyone who needs them.</span>
<span id="cb18-430"><a href="#cb18-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-431"><a href="#cb18-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-432"><a href="#cb18-432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-433"><a href="#cb18-433" aria-hidden="true" tabindex="-1"></a><span class="fu"># References {.unnumbered}</span></span>
<span id="cb18-434"><a href="#cb18-434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-435"><a href="#cb18-435" aria-hidden="true" tabindex="-1"></a>::: {#refs}</span>
<span id="cb18-436"><a href="#cb18-436" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-437"><a href="#cb18-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-438"><a href="#cb18-438" aria-hidden="true" tabindex="-1"></a><span class="fu"># Appendix {#appendices}</span></span>
<span id="cb18-439"><a href="#cb18-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-440"><a href="#cb18-440" aria-hidden="true" tabindex="-1"></a><span class="fu">## Bivariate Archimedean models {#sec-bv_arch}</span></span>
<span id="cb18-441"><a href="#cb18-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-442"><a href="#cb18-442" aria-hidden="true" tabindex="-1"></a>::: {#fig-bv_arch_1}</span>
<span id="cb18-443"><a href="#cb18-443" aria-hidden="true" tabindex="-1"></a><span class="al">![](figures/app/arch_table_1.png)</span>{width=100%}</span>
<span id="cb18-444"><a href="#cb18-444" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-445"><a href="#cb18-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-446"><a href="#cb18-446" aria-hidden="true" tabindex="-1"></a>::: {#fig-bv_arch_2}</span>
<span id="cb18-447"><a href="#cb18-447" aria-hidden="true" tabindex="-1"></a><span class="al">![](figures/app/arch_table_2.png)</span>{width=100%}</span>
<span id="cb18-448"><a href="#cb18-448" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-449"><a href="#cb18-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-450"><a href="#cb18-450" aria-hidden="true" tabindex="-1"></a><span class="fu">## Implemented bivariate extreme models {#sec-bv_ext}</span></span>
<span id="cb18-451"><a href="#cb18-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-452"><a href="#cb18-452" aria-hidden="true" tabindex="-1"></a>::: {#fig-bv_ext}</span>
<span id="cb18-453"><a href="#cb18-453" aria-hidden="true" tabindex="-1"></a><span class="al">![](figures/app/ext_table.png)</span>{width=100%}</span>
<span id="cb18-454"><a href="#cb18-454" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-455"><a href="#cb18-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-456"><a href="#cb18-456" aria-hidden="true" tabindex="-1"></a><span class="fu">## Multivariate Archimedean copulae {#sec-mv_arch}</span></span>
<span id="cb18-457"><a href="#cb18-457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-458"><a href="#cb18-458" aria-hidden="true" tabindex="-1"></a>::: {#fig-mv_arch}</span>
<span id="cb18-459"><a href="#cb18-459" aria-hidden="true" tabindex="-1"></a><span class="al">![](figures/app/arch_mv_table.png)</span>{width=100%}</span>
<span id="cb18-460"><a href="#cb18-460" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-461"><a href="#cb18-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-462"><a href="#cb18-462" aria-hidden="true" tabindex="-1"></a><span class="fu">## Multivariate extreme models {#sec-mv_ext}</span></span>
<span id="cb18-463"><a href="#cb18-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-464"><a href="#cb18-464" aria-hidden="true" tabindex="-1"></a>Before giving the main details, we introduce some notations. Let $B$ be the set of all nonempty subsets of $<span class="sc">\{</span>1,\dots,d<span class="sc">\}</span>$ </span>
<span id="cb18-465"><a href="#cb18-465" aria-hidden="true" tabindex="-1"></a>and $B_1 = <span class="sc">\{</span>b \in B, |b| = 1<span class="sc">\}</span>$, where $|b|$ denotes the number of elements in thet set $b$. We note by $B_{(j)} = <span class="sc">\{</span>b \in B, j \in b<span class="sc">\}</span>$. </span>
<span id="cb18-466"><a href="#cb18-466" aria-hidden="true" tabindex="-1"></a>For $d=3$, the Pickands is expressed as</span>
<span id="cb18-467"><a href="#cb18-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-468"><a href="#cb18-468" aria-hidden="true" tabindex="-1"></a>::: {#eq-mv_ext}</span>
<span id="cb18-469"><a href="#cb18-469" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb18-470"><a href="#cb18-470" aria-hidden="true" tabindex="-1"></a> A(\textbf{w}) =&amp; \alpha_1 w_1 + \psi_1 w_2 + \phi_1 w_3 + \left( (\alpha_2 w_1)^{\theta_1} + (\psi_2w_2)^{\theta_1} \right)^{1/\theta_1} + \left( (\alpha_3 w_2)^{\theta_2} + (\phi_2w_3)^{\theta_2} \right)^{1/\theta_2} <span class="sc">\\</span> &amp;+ \left( (\psi_3 w_2)^{\theta_3} + (\phi_3w_3)^{\theta_3} \right)^{1/\theta_3} </span>
<span id="cb18-471"><a href="#cb18-471" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>\left( (\alpha_4 w_1)^{\theta_4} + (\psi_4 w_2)^{\theta_4} + (\phi_4 w_3)^{\theta_4} \right)^{1/\theta_4},</span>
<span id="cb18-472"><a href="#cb18-472" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb18-473"><a href="#cb18-473" aria-hidden="true" tabindex="-1"></a>::: </span>
<span id="cb18-474"><a href="#cb18-474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-475"><a href="#cb18-475" aria-hidden="true" tabindex="-1"></a>where $\boldsymbol{\alpha} = (\alpha_1, \dots, \alpha_4), \boldsymbol{\psi} = (\psi_1, \dots, \psi_4), \boldsymbol{\phi} = (\phi_1, \dots, \phi_4)$ are all elements of $\Delta^3$. </span>
<span id="cb18-476"><a href="#cb18-476" aria-hidden="true" tabindex="-1"></a>We take $\boldsymbol{\alpha} = (0.4,0.3,0.1,0.2)$, $\boldsymbol{\psi} = (0.1, 0.2, 0.4, 0.3)$, $\boldsymbol{\phi} = (0.6,0.1,0.1,0.2)$ and </span>
<span id="cb18-477"><a href="#cb18-477" aria-hidden="true" tabindex="-1"></a>$\boldsymbol{\theta} = (\theta_1, \dots, \theta_4) = (0.6,0.5,0.8,0.3)$ as the dependence parameter.</span>
<span id="cb18-478"><a href="#cb18-478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-479"><a href="#cb18-479" aria-hidden="true" tabindex="-1"></a>The Dirichlet model is a mixture of $m$ Dirichlet densities, that is</span>
<span id="cb18-480"><a href="#cb18-480" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-481"><a href="#cb18-481" aria-hidden="true" tabindex="-1"></a>    h(\textbf{w}) = \sum_{k=1}^m \theta_k \frac{\Gamma(\sum_{j=1}^d \sigma_{kj})}{\Pi_{j=1}^d \Gamma(\sigma_{kj})} \Pi_{j=1}^d w_j^{\sigma_{kj}-1},</span>
<span id="cb18-482"><a href="#cb18-482" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-483"><a href="#cb18-483" aria-hidden="true" tabindex="-1"></a>with $\sum_{k=1}^m \theta_k = 1$, $\sigma_{kj} &gt; 0$ for $k \in <span class="sc">\{</span>1,\dots,m<span class="sc">\}</span>$ and $j \in <span class="sc">\{</span>1, \dots, d<span class="sc">\}</span>$. Let $\mathcal{D} \in [0, \infty)^{(d-1)\times (d-1)}$ denotes the space of symmetric strictly conditionnaly negative definite matrices that is</span>
<span id="cb18-484"><a href="#cb18-484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-485"><a href="#cb18-485" aria-hidden="true" tabindex="-1"></a>::: {#striclty_cond_neg}</span>
<span id="cb18-486"><a href="#cb18-486" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb18-487"><a href="#cb18-487" aria-hidden="true" tabindex="-1"></a>            \mathcal{D}_{k} = \Big\{ \Gamma \in [0,\infty)^{k \times k} : a^\top \Gamma a &lt; 0 \; \textrm{for all } a \in \mathbb{R}^{k} \setminus \{\textbf{0}\}  \, \textrm{with } \sum_{j=1}^{d-1} a_j = 0, \\ \Gamma_{ii} = 0, \Gamma_{ij} = \Gamma_{ji}, \quad 1 \leq i,j\leq k \Big<span class="sc">\}</span>.</span>
<span id="cb18-488"><a href="#cb18-488" aria-hidden="true" tabindex="-1"></a>        \end{align*}</span>
<span id="cb18-489"><a href="#cb18-489" aria-hidden="true" tabindex="-1"></a>::: </span>
<span id="cb18-490"><a href="#cb18-490" aria-hidden="true" tabindex="-1"></a>For any $2 \leq k \leq d$, consider $m&#39; = (m_1, \dots, m_k)$ with $1 \leq m_1 &lt;  \dots &lt; m_k \leq d$ define</span>
<span id="cb18-491"><a href="#cb18-491" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-492"><a href="#cb18-492" aria-hidden="true" tabindex="-1"></a>    \Sigma^{(k)}_m = 2 \left( \Gamma_{m_i m_k} + \Gamma_{m_j m_k} - \Gamma_{m_i m_j} \right)_{m_i m_j \neq m_k} \in [0,\infty)^{(d-1)\times(d-1)}.</span>
<span id="cb18-493"><a href="#cb18-493" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-494"><a href="#cb18-494" aria-hidden="true" tabindex="-1"></a>Furthermore, note $S(\cdot | \Sigma^{(k)}_m)$ denote the survival function of a normal random vector with mean vector $\textbf{0}$ and covariance matrix $\Sigma^{(k)}$. We now define :</span>
<span id="cb18-495"><a href="#cb18-495" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-496"><a href="#cb18-496" aria-hidden="true" tabindex="-1"></a>    h_{km}(\textbf{y}) = \int_{y_k}^\infty S\left( (y_i - z + 2\Gamma_{m_i m_k})_{i=1}^{k-1} | \Gamma_{km}\right) e^{-z}dz </span>
<span id="cb18-497"><a href="#cb18-497" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-498"><a href="#cb18-498" aria-hidden="true" tabindex="-1"></a>for $2 \leq k \leq d$. We denote by $\Sigma^{(k)}$ the summation over all $k$-vectors $m=(m_1,\dots,m_k)$ with $1\leq m_1 &lt; \dots &lt; m_k \leq d$.</span>
<span id="cb18-499"><a href="#cb18-499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-500"><a href="#cb18-500" aria-hidden="true" tabindex="-1"></a>::: {#fig-mv_ext}</span>
<span id="cb18-501"><a href="#cb18-501" aria-hidden="true" tabindex="-1"></a><span class="al">![](figures/app/ext_mv_table.png)</span>{width=100%}</span>
<span id="cb18-502"><a href="#cb18-502" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-503"><a href="#cb18-503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-504"><a href="#cb18-504" aria-hidden="true" tabindex="-1"></a><span class="fu">## Multivariate elliptical dependencies {#sec-mv_ellip}</span></span>
<span id="cb18-505"><a href="#cb18-505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-506"><a href="#cb18-506" aria-hidden="true" tabindex="-1"></a>Let $\textbf{X} \sim \textbf{E}_d(\boldsymbol{\mu}, \Sigma, \psi)$ be an elliptical distributed random vector with cumulative distribution $F$ </span>
<span id="cb18-507"><a href="#cb18-507" aria-hidden="true" tabindex="-1"></a>and marginal $F_0, \dots, F_{d-1}$. Then, the copula $C$ of $F$ is called an elliptical copula. We denote by  $\phi$ the standard normal distribution </span>
<span id="cb18-508"><a href="#cb18-508" aria-hidden="true" tabindex="-1"></a>function and $\boldsymbol{\phi}_\Sigma$ the joint distribution function of $\textbf{X} \sim \mathcal{N}_d(\textbf{0}, \Sigma)$, where $\textbf{0}$ is </span>
<span id="cb18-509"><a href="#cb18-509" aria-hidden="true" tabindex="-1"></a>the $d$-dimensional vector composed out of $0$. In the same way, we note $t_{\theta}$ the distribution function of a standard univariate distribution </span>
<span id="cb18-510"><a href="#cb18-510" aria-hidden="true" tabindex="-1"></a>$t$ distribution and by $\boldsymbol{t}_{\theta, \Sigma}$ the joint distribution function of the vector $\textbf{X} \sim \boldsymbol{t}_{d}(\theta, \textbf{0}, \Sigma)$. </span>
<span id="cb18-511"><a href="#cb18-511" aria-hidden="true" tabindex="-1"></a>A $d$ squared matrix $\Sigma$ is said to be positively semi definite if for all $u \in \mathbb{R}^d$ we have :</span>
<span id="cb18-512"><a href="#cb18-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-513"><a href="#cb18-513" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-514"><a href="#cb18-514" aria-hidden="true" tabindex="-1"></a>  u^\top \Sigma u \geq 0</span>
<span id="cb18-515"><a href="#cb18-515" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-516"><a href="#cb18-516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-517"><a href="#cb18-517" aria-hidden="true" tabindex="-1"></a>::: {#fig-mv_elli}</span>
<span id="cb18-518"><a href="#cb18-518" aria-hidden="true" tabindex="-1"></a><span class="al">![](figures/app/elli_table.png)</span>{width=100%}</span>
<span id="cb18-519"><a href="#cb18-519" aria-hidden="true" tabindex="-1"></a>:::</span></code></pre></div>
</div>
</section>
</section>

</main>
<!-- /main column -->
<script id = "quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->

</body>

</html>
