<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.537">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Alexis Boulin">
<meta name="dcterms.date" content="2023-01-12">
<meta name="keywords" content="Copulae, Random number generation">
<meta name="description" content="The package \textsf{clayton} is designed to be intuitive, user-friendly, and efficient. It offers a wide range of copula models, including Archimedean, Elliptical, and Extreme. The package is implemented in pure \textsf{Python}, making it easy to install and use.">

<title>A Python Package for Sampling from Copulae: clayton</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="published-202301-boulin-clayton_files/libs/clipboard/clipboard.min.js"></script>
<script src="published-202301-boulin-clayton_files/libs/quarto-html/quarto.js"></script>
<script src="published-202301-boulin-clayton_files/libs/quarto-html/popper.min.js"></script>
<script src="published-202301-boulin-clayton_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="published-202301-boulin-clayton_files/libs/quarto-html/anchor.min.js"></script>
<link href="published-202301-boulin-clayton_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="published-202301-boulin-clayton_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="published-202301-boulin-clayton_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="published-202301-boulin-clayton_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="published-202301-boulin-clayton_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<style>

      .quarto-title-block .quarto-title-banner h1,
      .quarto-title-block .quarto-title-banner h2,
      .quarto-title-block .quarto-title-banner h3,
      .quarto-title-block .quarto-title-banner h4,
      .quarto-title-block .quarto-title-banner h5,
      .quarto-title-block .quarto-title-banner h6
      {
        color: #FFFFFF;
      }

      .quarto-title-block .quarto-title-banner {
        color: #FFFFFF;
background: #034E79;
      }
</style>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta name="citation_title" content="A Python Package for Sampling from Copulae: clayton">
<meta name="citation_abstract" content="The package $\textsf{clayton}$ is designed to be intuitive, user-friendly, and efficient. It offers a wide range of copula models, including Archimedean, Elliptical, and Extreme. The package is implemented in pure $\textsf{Python}$, making it easy to install and use. In addition, we provide detailed documentation and examples to help users get started quickly. We also conduct a performance comparison with existing $\textsf{R}$ packages, demonstrating the efficiency of our implementation. The $\textsf{clayton}$ package is a valuable tool for researchers and practitioners working with copulae in $\textsf{Python}$.
">
<meta name="citation_keywords" content="Copulae,Random number generation">
<meta name="citation_author" content="Alexis Boulin">
<meta name="citation_publication_date" content="2023-01-12">
<meta name="citation_cover_date" content="2023-01-12">
<meta name="citation_year" content="2023">
<meta name="citation_online_date" content="2023-01-12">
<meta name="citation_fulltext_html_url" content="https://computo.sfds.asso.fr/published-202301-boulin-clayton/">
<meta name="citation_pdf_url" content="https://computo.sfds.asso.fr/published-202301-boulin-clayton/published-202301-boulin-clayton.pdf">
<meta name="citation_doi" content="10.57750/4szh-t752">
<meta name="citation_issn" content="2824-7795">
<meta name="citation_language" content="en">
<meta name="citation_journal_title" content="Computo">
<meta name="citation_publisher" content="French Statistical Society">
<meta name="citation_reference" content="citation_title=Modelling pairwise dependence of maxima in space;,citation_author=Philippe Naveau;,citation_author=Armelle Guillou;,citation_author=Daniel Cooley;,citation_author=Jean Diebolt;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_fulltext_html_url=https://doi.org/10.1093/biomet/asp001;,citation_issue=1;,citation_doi=10.1093/biomet/asp001;,citation_issn=0006-3444;,citation_volume=96;,citation_journal_title=Biometrika;">
<meta name="citation_reference" content="citation_title=Hybrid copula estimators;,citation_author=Johan Segers;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_fulltext_html_url=https://doi.org/10.1016/j.jspi.2014.11.006;,citation_doi=10.1016/j.jspi.2014.11.006;,citation_issn=0378-3758;,citation_volume=160;,citation_journal_title=J. Statist. Plann. Inference;">
<meta name="citation_reference" content="citation_title=Weak convergence of empirical copula processes;,citation_author=Jean-David Fermanian;,citation_author=Dragan Radulović;,citation_author=Marten Wegkamp;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_fulltext_html_url=https://doi.org/10.3150/bj/1099579158;,citation_issue=5;,citation_doi=10.3150/bj/1099579158;,citation_issn=1350-7265;,citation_volume=10;,citation_journal_title=Bernoulli;">
<meta name="citation_reference" content="citation_title=Weak convergence and empirical process: With applications to statistics;,citation_author=Aad W. Vaart;,citation_author=Jon A. Wellner;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;">
<meta name="citation_reference" content="citation_title=Conditional empirical copula processes and generalized dependence measures;,citation_author=Alexis Derumigny;,citation_author=Jean-David Fermanian;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_fulltext_html_url=https://arxiv.org/abs/2008.09480;">
<meta name="citation_reference" content="citation_title=Extreme-value copulas;,citation_author=Gordon Gudendorf;,citation_author=Johan Segers;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_fulltext_html_url=https://doi.org/10.1007/978-3-642-12465-5_6;,citation_doi=10.1007/978-3-642-12465-5\_6;,citation_volume=198;,citation_inbook_title=Copula theory and its applications;,citation_series_title=Lect. Notes stat. proc.;">
<meta name="citation_reference" content="citation_title=Madogram and asymptotic independence among maxima;,citation_author=Armelle Guillou;,citation_author=Philippe Naveau;,citation_author=Antoine Schorgen;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=2;,citation_issn=1645-6726;,citation_volume=12;,citation_journal_title=REVSTAT;">
<meta name="citation_reference" content="citation_title=Asymptotics of empirical copula processes under non-restrictive smoothness assumptions;,citation_author=Johan Segers;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_fulltext_html_url=https://doi.org/10.3150/11-BEJ387;,citation_issue=3;,citation_doi=10.3150/11-BEJ387;,citation_issn=1350-7265;,citation_volume=18;,citation_journal_title=Bernoulli;">
<meta name="citation_reference" content="citation_title=Statistics of extremes: Theory and applications;,citation_author=J. Beirlant;,citation_author=Y. Goegebeur;,citation_author=J. J. J. Segers;,citation_author=J. Teugels;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_isbn=0471976474;">
<meta name="citation_reference" content="citation_title=Modélisation et statistique spatiales;,citation_abstract=La statistique spatiale connaît un développement important du fait de son utilisation dans de nombreux domaines : sciences de la terre, environnement et climatologie, épidémiologie, économétrie, analyse d’image, etc… Ce livre présente les principaux modèles spatiaux utilisés ainsi que leur statistique pour les trois types de données : géostatistiques (observation sur un domaine continu), données sur réseau discret, données ponctuelles. L’objectif est présenter de façon concise mais mathématiquement complète les modèles les plus classiques (second ordre et variogramme ; modèle latticiel et champ de Gibbs-Markov ; processus ponctuels) ainsi que leur simulation par algorithme MCMC. Vient ensuite la présentation des outils statistiques utiles à leur étude. De nombreux exemples utilisant R illustrent les sujets abordés. Chaque chapitre est complété par des exercices et une annexe présente brièvement les outils probabilistes et statistiques utiles à la statistique de champs aléatoires. [4e de couv.];,citation_author=Carlo Gaetan;,citation_author=Xavier Guyon;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_isbn=978-3-540-79225-3;,citation_series_title=Mathématiques &amp;amp;amp; applications;">
<meta name="citation_reference" content="citation_title=Variograms for spatial max-stable random fields;,citation_author=Dan Cooley;,citation_author=Philippe Naveau;,citation_author=Paul Poncet;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_fulltext_html_url=https://doi.org/10.1007/0-387-36062-X_17;,citation_doi=10.1007/0-387-36062-X_17;,citation_isbn=978-0-387-36062-1;,citation_inbook_title=Dependence in probability and statistics;">
<meta name="citation_reference" content="citation_title=Multivariate nonparametric estimation of the pickands dependence function using bernstein polynomials;,citation_abstract=Many applications in risk analysis require the estimation of the dependence among multivariate maxima, especially in environmental sciences. Such dependence can be described by the Pickands dependence function of the underlying extreme-value copula. Here, a nonparametric estimator is constructed as the sample equivalent of a multivariate extension of the madogram. Shape constraints on the family of Pickands dependence functions are taken into account by means of a representation in terms of Bernstein polynomials. The large-sample theory of the estimator is developed and its finite-sample performance is evaluated with a simulation study. The approach is illustrated with a dataset of weekly maxima of hourly rainfall in France recorded from 1993 to 2011 at various weather stations all over the country. The stations are grouped into clusters of seven stations, where our interest is in the extremal dependence within each cluster.;,citation_author=G. Marcon;,citation_author=S. A. Padoan;,citation_author=P. Naveau;,citation_author=P. Muliere;,citation_author=J. Segers;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_fulltext_html_url=https://www.sciencedirect.com/science/article/pii/S0378375816301276;,citation_doi=https://doi.org/10.1016/j.jspi.2016.10.004;,citation_issn=0378-3758;,citation_volume=183;,citation_journal_title=Journal of Statistical Planning and Inference;">
<meta name="citation_reference" content="citation_title=Dependence measures for extreme value analyses;,citation_author=SG Coles;,citation_author=J Heffernan;,citation_author=JA Tawn;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_volume=2;,citation_journal_title=Extremes;">
<meta name="citation_reference" content="citation_title=Clustering of Maxima: Spatial Dependencies among Heavy Rainfall in France;,citation_author=Elsa Bernard;,citation_author=Philippe Naveau;,citation_author=Mathieu Vrac;,citation_author=Olivier Mestre;,citation_publication_date=2013-10;,citation_cover_date=2013-10;,citation_year=2013;,citation_fulltext_html_url=https://hal.archives-ouvertes.fr/hal-03207469;,citation_issue=20;,citation_doi=10.1175/JCLI-D-12-00836.1;,citation_volume=26;,citation_journal_title=Journal of Climate;,citation_publisher=American Meteorological Society;">
<meta name="citation_reference" content="citation_title=A nonparametric estimation procedure for bivariate extreme value copulas;,citation_author=P. Capéraà;,citation_author=A.-L. Fougères;,citation_author=C. Genest;,citation_publication_date=1997;,citation_cover_date=1997;,citation_year=1997;,citation_fulltext_html_url=https://doi.org/10.1093/biomet/84.3.567;,citation_issue=3;,citation_doi=10.1093/biomet/84.3.567;,citation_issn=0006-3444;,citation_volume=84;,citation_journal_title=Biometrika;">
<meta name="citation_reference" content="citation_title=Rank-based inference for bivariate extreme-value copulas;,citation_author=Christian Genest;,citation_author=Johan Segers;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_fulltext_html_url=https://doi.org/10.1214/08-AOS672;,citation_issue=5B;,citation_doi=10.1214/08-AOS672;,citation_volume=37;,citation_journal_title=The Annals of Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Maxima of normal random vectors: Between independence and complete dependence;,citation_abstract=A new approach to the asymptotic treatment of multivariate sample maxima is suggested and exemplified in the particular case of maxima of normal random vectors. In the limit one obtains a class of multivariate maxstable distributions not considered in literature so far.;,citation_author=Jürg Hüsler;,citation_author=Rolf-Dieter Reiss;,citation_publication_date=1989;,citation_cover_date=1989;,citation_year=1989;,citation_fulltext_html_url=https://www.sciencedirect.com/science/article/pii/0167715289901065;,citation_issue=4;,citation_doi=https://doi.org/10.1016/0167-7152(89)90106-5;,citation_issn=0167-7152;,citation_volume=7;,citation_journal_title=Statistics &amp;amp;amp; Probability Letters;">
<meta name="citation_reference" content="citation_title=Fonctions de répartition à n dimensions et leurs marges;,citation_author=Abe Sklar;,citation_publication_date=1959;,citation_cover_date=1959;,citation_year=1959;,citation_volume=8;,citation_journal_title=Publications de l’Institut de Statistique de l’Université de Paris;">
<meta name="citation_reference" content="citation_title=Convergence de mesures et processus de lévy;,citation_author=Pierre-Loïc Méliot;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_fulltext_html_url=https://www.imo.universite-paris-saclay.fr/~meliot/master/poisson.pdf;">
<meta name="citation_reference" content="citation_title=Local robust estimation of the Pickands dependence function;,citation_author=Mikael Escobar-Bach;,citation_author=Yuri Goegebeur;,citation_author=Armelle Guillou;,citation_publication_date=2017-09;,citation_cover_date=2017-09;,citation_year=2017;,citation_fulltext_html_url=https://hal.archives-ouvertes.fr/hal-01340166;">
<meta name="citation_reference" content="citation_title=The t Copula and Related Copulas;,citation_abstract=Summary The t copula and its properties are described with a focus on issues related to the dependence of extreme values. The Gaussian mixture representation of a multivariate t distribution is used as a starting point to construct two new copulas, the skewed t copula and the grouped t copula, which allow more heterogeneity in the modelling of dependent observations. Extreme value considerations are used to derive two further new copulas: the t extreme value copula is the limiting copula of componentwise maxima of t distributed random vectors; the t lower tail copula is the limiting copula of bivariate observations from a t distribution that are conditioned to lie below some joint threshold that is progressively lowered. Both these copulas may be approximated for practical purposes by simpler, better-known copulas, these being the Gumbel and Clayton copulas respectively.;,citation_author=Stefano Demarta;,citation_author=Alexander J. McNeil;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_fulltext_html_url=https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1751-5823.2005.tb00254.x;,citation_issue=1;,citation_doi=https://doi.org/10.1111/j.1751-5823.2005.tb00254.x;,citation_volume=73;,citation_journal_title=International Statistical Review;">
<meta name="citation_reference" content="citation_title=Statistical analysis with missing data;,citation_author=Rubin D. B. Little R. J. A.;,citation_publication_date=1987;,citation_cover_date=1987;,citation_year=1987;,citation_fulltext_html_url=http://gen.lib.rus.ec/book/index.php?md5=be7431d47fa4227d47c8e1775b78250d;,citation_isbn=169-170-183-1,138-139-220-2;">
<meta name="citation_reference" content="citation_title=Sampling techniques, 3Rd edition;,citation_author=W. G. Cochran;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_fulltext_html_url=https://books.google.co.uk/books?id=xbNn41DUrNwC;,citation_isbn=9788126515240;,citation_series_title=A wiley publication in applied statistics;">
<meta name="citation_reference" content="citation_title=Mostly harmless econometrics: An empiricist’s companion;,citation_author=Joshua D. Angrist;,citation_author=Jörn-Steffen Pischke;,citation_publication_date=2008-12;,citation_cover_date=2008-12;,citation_year=2008;,citation_isbn=0691120358;">
<meta name="citation_reference" content="citation_title=Robust statistics;,citation_author=Peter J. Huber;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_fulltext_html_url=https://doi.org/10.1007/978-3-642-04898-2_594;,citation_doi=10.1007/978-3-642-04898-2_594;,citation_isbn=978-3-642-04898-2;,citation_inbook_title=International encyclopedia of statistical science;">
<meta name="citation_reference" content="citation_title=A new method for estimation and model selection: \rho-estimation;,citation_author=Yannick Baraud;,citation_author=Lucien Birgé;,citation_author=Mathieu Sart;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_fulltext_html_url=https://hal.archives-ouvertes.fr/hal-01326224;,citation_journal_title=Inventiones Mathematicae;,citation_publisher=Springer Verlag;">
<meta name="citation_reference" content="citation_title=Robust Estimation of a Location Parameter;,citation_author=Peter J. Huber;,citation_publication_date=1964;,citation_cover_date=1964;,citation_year=1964;,citation_fulltext_html_url=https://doi.org/10.1214/aoms/1177703732;,citation_issue=1;,citation_doi=10.1214/aoms/1177703732;,citation_volume=35;,citation_journal_title=The Annals of Mathematical Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=MONK – Outlier-Robust Mean Embedding Estimation by Median-of-Means;,citation_author=Matthieu Lerasle;,citation_author=Zoltán Szabó;,citation_author=Timothée Mathieu;,citation_author=Guillaume Lecué;,citation_publication_date=2019-06;,citation_cover_date=2019-06;,citation_year=2019;,citation_fulltext_html_url=https://hal.archives-ouvertes.fr/hal-01705881;,citation_conference_title=ICML 2019 - 36th International Conference on Machine Learning;,citation_series_title=Proceedings of machine learning research;">
<meta name="citation_reference" content="citation_title=Problem complexity and method efficiency in optimization;,citation_author=A. Nemirovsky;,citation_author=D. Yudin;,citation_publication_date=1983;,citation_cover_date=1983;,citation_year=1983;">
<meta name="citation_reference" content="citation_title=Local robust estimation of the Pickands dependence function;,citation_author=Mikael Escobar-Bach;,citation_author=Yuri Goegebeur;,citation_author=Armelle Guillou;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_fulltext_html_url=https://doi.org/10.1214/17-AOS1640;,citation_issue=6A;,citation_doi=10.1214/17-AOS1640;,citation_volume=46;,citation_journal_title=The Annals of Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Generalization bounds in the presence of outliers: A median-of-means study;,citation_author=Pierre Laforgue;,citation_author=Guillaume Staerman;,citation_author=Stephan Clémençon;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://arxiv.org/abs/2006.05240;">
<meta name="citation_reference" content="citation_title=Estimation of copulas via maximum mean discrepancy;,citation_author=Pierre Alquier;,citation_author=Badr-Eddine Chérief-Abdellatif;,citation_author=Alexis Derumigny;,citation_author=Jean-David Fermanian;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_journal_title=Journal of the American Statistical Association;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Concentration inequalities. A nonasymptotic theory of independence;,citation_author=S. Boucheron;,citation_author=G. Lugosi;,citation_author=P. Massart;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_fulltext_html_url=https://hal.archives-ouvertes.fr/hal-00794821;">
<meta name="citation_reference" content="citation_title=The Tight Constant in the Dvoretzky-Kiefer-Wolfowitz Inequality;,citation_author=P. Massart;,citation_publication_date=1990;,citation_cover_date=1990;,citation_year=1990;,citation_fulltext_html_url=https://doi.org/10.1214/aop/1176990746;,citation_issue=3;,citation_doi=10.1214/aop/1176990746;,citation_volume=18;,citation_journal_title=The Annals of Probability;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Bivariate extreme value theory: Models and estimation;,citation_abstract=Bivariate extreme value distributions arise as the limiting distributions of renormalized componentwise maxima. No natural parametric family exists for the dependence between the marginal distributions, but there are considerable restrictions on the dependence structure. We consider modelling the dependence function with parametric models, for which two new models are presented. Tests for independence, and discriminating between models, are also given. The estimation procedure, and the flexibility of the new models, are illustrated with an application to sea level data.;,citation_author=Jonathan A. Tawn;,citation_publication_date=1988-09;,citation_cover_date=1988-09;,citation_year=1988;,citation_fulltext_html_url=https://doi.org/10.1093/biomet/75.3.397;,citation_issue=3;,citation_doi=10.1093/biomet/75.3.397;,citation_issn=0006-3444;,citation_volume=75;,citation_journal_title=Biometrika;">
<meta name="citation_reference" content="citation_title=Families of min-stable multivariate exponential and multivariate extreme value distributions;,citation_author=H. Joe;,citation_publication_date=1990;,citation_cover_date=1990;,citation_year=1990;,citation_volume=9;,citation_journal_title=Statistics &amp;amp;amp; Probability Letters;">
<meta name="citation_reference" content="citation_title=The asymptotic theory of extreme order statistics;,citation_author=J. D. T. Oliveira;,citation_author=J. Galambos;,citation_publication_date=1977;,citation_cover_date=1977;,citation_year=1977;,citation_volume=47;,citation_journal_title=International Statistical Review;">
<meta name="citation_reference" content="citation_title=Multivariate extreme value distribution;,citation_author=J. Pickands;,citation_publication_date=1981;,citation_cover_date=1981;,citation_year=1981;,citation_fulltext_html_url=https://ci.nii.ac.jp/naid/10022049959/en/;,citation_journal_title=Proceedings 43th, Session of International Statistical Institution, 1981;">
<meta name="citation_reference" content="citation_title=On the limiting behavior of the pickands estimator for bivariate extreme-value distributions;,citation_abstract=We establish the functional central limit theorem and law of the iterated logarithm for the Pickands estimator of the dependence function of a bivariate extreme-value distribution. Our methods are based on general results for sums of random variables taking values in Banach spaces.;,citation_author=Paul Deheuvels;,citation_publication_date=1991;,citation_cover_date=1991;,citation_year=1991;,citation_fulltext_html_url=https://www.sciencedirect.com/science/article/pii/016771529190032M;,citation_issue=5;,citation_doi=https://doi.org/10.1016/0167-7152(91)90032-M;,citation_issn=0167-7152;,citation_volume=12;,citation_journal_title=Statistics &amp;amp;amp; Probability Letters;">
<meta name="citation_reference" content="citation_title=Distribution and dependence-function estimation for bivariate extreme-value distributions;,citation_author=Peter Hall;,citation_author=Nader Tajvidi;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_fulltext_html_url=http://dml.mathdoc.fr/item/1081282691;,citation_issue=6;,citation_volume=6;,citation_journal_title=Bernoulli;">
<meta name="citation_reference" content="citation_title=A nonparametric estimation procedure for bivariate extreme value copulas;,citation_author=P. Capéraà;,citation_author=Anne-Laure Fougères;,citation_author=C. Genest;,citation_publication_date=1997;,citation_cover_date=1997;,citation_year=1997;,citation_volume=84;,citation_journal_title=Biometrika;">
<meta name="citation_reference" content="citation_title=Spatial clustering of summer temperature maxima from the CNRM-CM5 climate model ensembles &amp;amp;amp; E-OBS over Europe;,citation_abstract=Reducing the dimensionality of the complex spatio-temporal variables associated with climate modeling, especially ensembles of climate models, is a challenging and important objective. For studies of detection and attribution, it is especially important to maintain information related to the extreme values of the atmospheric processes. Typical methods for data reduction involve summarizing climate model output information through means and variances, which does not preserve any information about the extremes. In order to help solve this challenge, a dependence summary measure appropriate for extreme values must be inferred. Here, we adapt one such measure from a recent study to a larger domain with a different variable and gridded data from observations and climate model ensembles, i.e. E-OBS observations and the CNRM-CM5 model. The handling of such ensembles of data is proposed, as well as a comparison of the spatial clusterings between two different ensembles, here a present-day and a future ensemble of climate simulations. This method yields valid information concerning extremes, while greatly reducing the data set.;,citation_author=Margot Bador;,citation_author=Philippe Naveau;,citation_author=Eric Gilleland;,citation_author=Mercè Castellà;,citation_author=Tatiana Arivelo;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_fulltext_html_url=https://www.sciencedirect.com/science/article/pii/S2212094715300013;,citation_doi=https://doi.org/10.1016/j.wace.2015.05.003;,citation_issn=2212-0947;,citation_volume=9;,citation_journal_title=Weather and Climate Extremes;">
<meta name="citation_reference" content="citation_title=Asymptotics of empirical copula processes under non-restrictive smoothness assumptions;,citation_author=Johan Segers;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_fulltext_html_url=https://doi.org/10.3150/11-BEJ387;,citation_issue=3;,citation_doi=10.3150/11-BEJ387;,citation_volume=18;,citation_journal_title=Bernoulli;,citation_publisher=Bernoulli Society for Mathematical Statistics; Probability;">
<meta name="citation_reference" content="citation_title=Max-stable processes and spatial extremes;,citation_author=Richard L. Smith;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_conference_title=None;">
<meta name="citation_reference" content="citation_title=Mathematics and the picturing of data;,citation_author=John W. Tukey;,citation_publication_date=1975;,citation_cover_date=1975;,citation_year=1975;,citation_conference_title=Proceedings of the International Congress of Mathematicians (Vancouver, B. C., 1974), Vol. 2;">
<meta name="citation_reference" content="citation_title=Forest climatology: Estimation of missing values for bavaria, germany;,citation_abstract=Estimation of missing values in climatological time series is an important task. In order to find an appropriate method, we examined six methods for estimating missing climatological data (daily maximum temperature, minimum temperature, air temperature, water vapour pressure, wind speed and precipitation) for different time scales at six German weather stations and three Bavarian forest climate stations. The multiple regression analysis (using the five closest weather stations) with least absolute deviations criteria (REG) predominantly gave the best estimation for daily, weekly, biweekly, and monthly maximum temperature, minimum temperature, mean temperature, water vapour pressure, wind speed, under different topographical conditions (valley, alpine foothills and mountain sites). The six methods gave similar estimates for the averaged precipitation amount. The mean absolute errors (MAE) of estimating climatological data using different techniques are of similar magnitude at the weather stations, but they are significantly different at the forest climate stations. For the same climatological variable (i.e., air temperature) for different time scales, mean absolute errors of estimated data are larger for shorter time scales (e.g., a day) than for longer ones (e.g., a month). For the different climatological variables, the most accurately estimated variables are maximum temperatures, mean temperatures and water vapour pressure, followed by minimum temperature and wind speed. The poorest results were obtained for precipitation data.;,citation_author=Youlong Xia;,citation_author=Peter Fabian;,citation_author=Andreas Stohl;,citation_author=Martin Winterhalter;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_fulltext_html_url=https://www.sciencedirect.com/science/article/pii/S0168192399000568;,citation_issue=1;,citation_doi=https://doi.org/10.1016/S0168-1923(99)00056-8;,citation_issn=0168-1923;,citation_volume=96;,citation_journal_title=Agricultural and Forest Meteorology;">
<meta name="citation_reference" content="citation_title=Estimation of multivariate models for time series of possibly different lenghts;,citation_author=Andrew J. Patton;,citation_author=John Wiley;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_journal_title=Journal of Applied Econometrics;">
<meta name="citation_reference" content="citation_title=On the consistency of supervised learning with missing values;,citation_author=Julie Josse;,citation_author=Nicolas Prost;,citation_author=Erwan Scornet;,citation_author=Gaël Varoquaux;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_fulltext_html_url=https://arxiv.org/abs/1902.06931;">
<meta name="citation_reference" content="citation_title=Nonparametric estimation of multivariate extreme-value copulas;,citation_abstract=Extreme-value copulas arise in the asymptotic theory for componentwise maxima of independent random samples. An extreme-value copula is determined by its Pickands dependence function, which is a function on the unit simplex subject to certain shape constraints that arise from an integral transform of an underlying measure called spectral measure. Multivariate extensions are provided of certain rank-based nonparametric estimators of the Pickands dependence function. The shape constraint that the estimator should itself be a Pickands dependence function is enforced by replacing an initial estimator by its best least-squares approximation in the set of Pickands dependence functions having a discrete spectral measure supported on a sufficiently fine grid. Weak convergence of the standardized estimators is demonstrated and the finite-sample performance of the estimators is investigated by means of a simulation experiment.;,citation_author=Gordon Gudendorf;,citation_author=Johan Segers;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_fulltext_html_url=https://www.sciencedirect.com/science/article/pii/S0378375812001978;,citation_issue=12;,citation_doi=https://doi.org/10.1016/j.jspi.2012.05.007;,citation_issn=0378-3758;,citation_volume=142;,citation_journal_title=Journal of Statistical Planning and Inference;">
<meta name="citation_reference" content="citation_title=Inference for asymptotically independent samples of extremes;,citation_abstract=An important topic in multivariate extreme-value theory is to develop probabilistic models and statistical methods to describe and measure the strength of dependence among extreme observations. The theory is well established for data whose dependence structure is compatible with that of asymptotically dependent models. On the contrary, in many applications data do not comply with asymptotically dependent models and thus new tools are required. This article contributes to the methodological development of such a context, by considering a component-wise maxima approach. First we propose a statistical test based on the classical Pickands dependence function to verify whether asymptotic dependence or independence holds. Then, we present a new Pickands dependence function to describe the extremal dependence under asymptotic independence. Finally, we propose an estimator of the latter, we establish its main asymptotic properties and we illustrate its performance by a simulation study.;,citation_author=Armelle Guillou;,citation_author=Simone A. Padoan;,citation_author=Stefano Rizzelli;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_fulltext_html_url=https://www.sciencedirect.com/science/article/pii/S0047259X17305638;,citation_doi=https://doi.org/10.1016/j.jmva.2018.04.009;,citation_issn=0047-259X;,citation_volume=167;,citation_journal_title=Journal of Multivariate Analysis;">
<meta name="citation_reference" content="citation_title=On the extremes of randomly sub-sampled time series;,citation_author=Andreia Hall;,citation_author=Manuel Scotto;,citation_publication_date=2008-07;,citation_cover_date=2008-07;,citation_year=2008;,citation_volume=6;,citation_journal_title=REVSTAT – Statistical Journal Volume;">
<meta name="citation_reference" content="citation_title=Extremal behaviour of a periodically controlled sequence with imputed values;,citation_author=Helena Ferreira;,citation_author=A. P. Martins;,citation_author=Maria Temido;,citation_publication_date=2021-12;,citation_cover_date=2021-12;,citation_year=2021;,citation_doi=10.1007/s00362-020-01217-w;,citation_volume=62;,citation_journal_title=Statistical Papers;">
<meta name="citation_reference" content="citation_title=La fonction de dépendance empirique et ses propriétés. Un test non paramétrique d’indépendance;,citation_abstract=Nous développons dans cette note la théorie de l’estimation non paramétrique de la fonction de dépendance d’une variable aléatorie. Nous obtenons l’exhaustivité et l’ordre de convergence uniforme presque sûr des estimateurs, leur distribution asymptotique et exacte. Nous appliquons les résultats obtenus afin d’établir un test d’indépendance non paramétrique du type Olmstead-Turey, pour lequel nous obtenons la distribution asymptotique et des propriétés d’optimalité.;,citation_author=Paul Deheuvels;,citation_publication_date=1979;,citation_cover_date=1979;,citation_year=1979;,citation_fulltext_html_url=https://www.persee.fr/doc/barb_0001-4141_1979_num_65_1_58521;,citation_doi=10.3406/barb.1979.58521;,citation_issn=0001-4141;,citation_journal_title=Bulletin Royal Belge de L’Académie des sciences, 65, 274-292;">
<meta name="citation_reference" content="citation_title=Distributions de valeurs extrêmes en plusieurs dimensions.;,citation_author=E. J. Gumbel;,citation_publication_date=1960;,citation_cover_date=1960;,citation_year=1960;,citation_volume=9;,citation_journal_title=Publications de l’institut de Statistique de l’Université de Paris;">
<meta name="citation_reference" content="citation_title=Modelling multivariate extreme value distributions;,citation_abstract=Multivariate extreme value distributions arise as the limiting joint distribution of normalized componentwise maxima/minima. No parametric family exists for the dependence between the margins. This paper extends to more than two variables the models and results for the bivariate case obtained by Tawn (1988). Two new families of physically motivated parametric models for the dependence structure are presented and are illustrated with an application to trivariate extreme sea level data.;,citation_author=Jonathan A. Tawn;,citation_publication_date=1990;,citation_cover_date=1990;,citation_year=1990;,citation_fulltext_html_url=http://www.jstor.org/stable/2336802;,citation_issue=2;,citation_issn=00063444;,citation_volume=77;,citation_journal_title=Biometrika;,citation_publisher=[Oxford University Press, Biometrika Trust];">
<meta name="citation_reference" content="citation_title=Simulating multivariate extreme value distributions of logistic type;,citation_author=Alec Stephenson;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_issue=1;,citation_volume=6;,citation_journal_title=Extremes;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=A regionalisation approach for rainfall based on extremal dependence;,citation_author=K. Saunders;,citation_author=A. Stephenson;,citation_author=David Karoly;,citation_publication_date=2021-06;,citation_cover_date=2021-06;,citation_year=2021;,citation_doi=10.1007/s10687-020-00395-y;,citation_volume=24;,citation_journal_title=Extremes;">
<meta name="citation_reference" content="citation_title=Calibration estimation of semiparametric copula models with data missing at random;,citation_abstract=This paper investigates the estimation of semiparametric copula models with data missing at random. The maximum pseudo-likelihood estimation of Genest et al. (1995) is infeasible if there are missing data. We propose a class of calibration estimators for the nonparametric marginal distributions and the copula parameters of interest by balancing the empirical moments of covariates between observed and whole groups. Our proposed estimators do not require the estimation of the missing mechanism, and they enjoy stable performance even when the sample size is small. We prove that our estimators satisfy consistency and asymptotic normality. We also provide a consistent estimator for the asymptotic variance. We show via extensive simulations that our proposed method dominates existing alternatives.;,citation_author=Shigeyuki Hamori;,citation_author=Kaiji Motegi;,citation_author=Zheng Zhang;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_fulltext_html_url=https://www.sciencedirect.com/science/article/pii/S0047259X18301714;,citation_doi=https://doi.org/10.1016/j.jmva.2019.02.003;,citation_issn=0047-259X;,citation_volume=173;,citation_journal_title=Journal of Multivariate Analysis;">
<meta name="citation_reference" content="citation_title=Copula-based regression models with data missing at random;,citation_abstract=The existing literature of copula-based regression assumes that complete data are available, but this assumption is violated in many real applications. The present paper allows the regressand and regressors to be missing at random (MAR). We formulate a generalized regression model which unifies many prominent cases such as the conditional mean and quantile regressions. A semiparametric copula and the target regression curve are estimated via the calibration approach. The consistency and asymptotic normality of the estimated regression curve are proved. We show via Monte Carlo simulations that the proposed approach operates well in finite samples, while a benchmark equal-weight approach fails with substantial bias under MAR. An empirical application on revenues and R&amp;amp;amp;D expenses of German manufacturing firms highlights a practical use of our approach.;,citation_author=Shigeyuki Hamori;,citation_author=Kaiji Motegi;,citation_author=Zheng Zhang;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_fulltext_html_url=https://www.sciencedirect.com/science/article/pii/S0047259X20302359;,citation_doi=https://doi.org/10.1016/j.jmva.2020.104654;,citation_issn=0047-259X;,citation_volume=180;,citation_journal_title=Journal of Multivariate Analysis;">
<meta name="citation_reference" content="citation_title=A semiparametric estimation procedure of dependence parameters in multivariate families of distributions;,citation_abstract=This paper investigates the properties of a semiparametric method for estimating the dependence parameters in a family of multivariate distributions. The proposed estimator, obtained as a solution of a pseudo-likelihood equation, is shown to be consistent, asymptotically normal and fully efficient at independence. A natural estimator of its asymptotic variance is proved to be consistent. Comparisons are made with alternative semiparametric estimators in the special case of Clayton’s model for association in bivariate data.;,citation_author=C. Genest;,citation_author=K. Ghoudi;,citation_author=L.-P. Rivest;,citation_publication_date=1995;,citation_cover_date=1995;,citation_year=1995;,citation_fulltext_html_url=http://www.jstor.org/stable/2337532;,citation_issue=3;,citation_issn=00063444;,citation_volume=82;,citation_journal_title=Biometrika;,citation_publisher=[Oxford University Press, Biometrika Trust];">
<meta name="citation_reference" content="citation_title=Estimation of a copula when a covariate affects only marginal distributions;,citation_abstract=This paper is concerned with studying the dependence structure between two random variables Y1 and Y2 in the presence of a covariate X, which affects both marginal distributions but not the dependence structure. This is reflected in the property that the conditional copula of Y1 and Y2 given X, does not depend on the value of X. This latter independence often appears as a simplifying assumption in pair-copula constructions. We introduce a general estimator for the copula in this specific setting and establish its consistency. Moreover, we consider some special cases, such as parametric or nonparametric location-scale models for the effect of the covariate X on the marginals of Y1 and Y2 and show that in these cases, weak convergence of the estimator, at \sqrt{\mathrm{n}}-\mathrm{r}\mathrm{a}\mathrm{t}\mathrm{e}, holds. The theoretical results are illustrated by simulations and a real data example.;,citation_author=Irène Gijbels;,citation_author=Marek Omelka;,citation_author=Noël Veraverbeke;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_fulltext_html_url=http://www.jstor.org/stable/24586878;,citation_issue=4;,citation_issn=03036898, 14679469;,citation_volume=42;,citation_journal_title=Scandinavian Journal of Statistics;,citation_publisher=[Board of the Foundation of the Scandinavian Journal of Statistics, Wiley];">
<meta name="citation_reference" content="citation_title=On the weak convergence of the empirical conditional copula under a simplifying assumption;,citation_abstract=A common assumption in pair-copula constructions is that the copula of the conditional distribution of two random variables given a covariate does not depend on the value of that covariate. Two conflicting intuitions arise about the best possible rate of convergence attainable by nonparametric estimators of that copula. On the one hand, the best possible rates for estimating the marginal conditional distribution functions are slower than the parametric one. On the other hand, the invariance of the conditional copula given the value of the covariate suggests the possibility of parametric convergence rates. The more optimistic intuition is shown to be correct, confirming a conjecture supported by extensive Monte Carlo simulations by Hobæk Haff and Segers (2015) and improving upon the nonparametric rate obtained theoretically by Gijbels et al. (2015). The novelty of the proposed approach lies in a double smoothing procedure for the estimator of the marginal conditional distribution functions. The copula estimator itself is asymptotically equivalent to an oracle empirical copula, as if the marginal conditional distribution functions were known.;,citation_author=François Portier;,citation_author=Johan Segers;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_fulltext_html_url=https://www.sciencedirect.com/science/article/pii/S0047259X16301300;,citation_doi=https://doi.org/10.1016/j.jmva.2018.03.002;,citation_issn=0047-259X;,citation_volume=166;,citation_journal_title=Journal of Multivariate Analysis;">
<meta name="citation_reference" content="citation_title=Empirical tail copulas for functional data;,citation_author=John H. J. Einmahl;,citation_author=Johan Segers;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://doi.org/10.1214/21-AOS2050;,citation_issue=5;,citation_doi=10.1214/21-AOS2050;,citation_volume=49;,citation_journal_title=The Annals of Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=evd: Extreme Value Distributions;,citation_author=A. G. Stephenson;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_fulltext_html_url=https://CRAN.R-project.org/doc/Rnews/;,citation_issue=2;,citation_volume=2;,citation_journal_title=R News;">
<meta name="citation_reference" content="citation_title=VineCopula : Statistical inference of vine copulas;,citation_author=U. Schepsmeier;,citation_author=J. Stoeber;,citation_author=E. C. Brechmann;,citation_author=B. Graeler;,citation_author=T. Nagler;,citation_author=T. Erhardt;,citation_author=C. Almeida;,citation_author=A. Min;,citation_author=M. Czado;,citation_author=M. Hofmann;,citation_author=M. Kiliches;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_fulltext_html_url=https://cran.r-project.org/web/packages/VineCopula/index.html;,citation_journal_title=Package &amp;amp;amp;quot;VineCopula&amp;quot;. R package, version 2.3.0;">
<meta name="citation_reference" content="citation_title=Enjoy the joy of copulas: With a package copula;,citation_author=Jun Yan;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_fulltext_html_url=https://www.jstatsoft.org/v21/i04/;,citation_issue=4;,citation_volume=21;,citation_journal_title=Journal of Statistical Software;">
<meta name="citation_reference" content="citation_title=Copulae;,citation_author=Daniel Bock;,citation_author=Jacob Chapman;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_journal_title=GitHub repository;,citation_publisher=https://github.com/DanielBok/copulae; GitHub;">
<meta name="citation_reference" content="citation_title=Copulas;,citation_author=M. Alvarez;,citation_author=C. Sala;,citation_author=Y. Sun;,citation_author=J. D. Pérez;,citation_author=K. A. Zhang;,citation_author=A. Montanez;,citation_author=G. Bonomi;,citation_author=K. Veeramachaneni;,citation_author=I. Ramírez;,citation_author=F. A. Hofman;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_journal_title=GitHub repository;,citation_publisher=https://github.com/sdv-dev/Copulas; GitHub;">
<meta name="citation_reference" content="citation_title=Probabilistic metric spaces;,citation_author=B. Schweizer;,citation_author=A. Sklar;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_fulltext_html_url=https://books.google.fr/books?id=8LUd6Txuu5sC;,citation_isbn=9780486143750;">
<meta name="citation_reference" content="citation_title=An introduction to copulas;,citation_author=Roger B Nelsen;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;">
<meta name="citation_reference" content="citation_title=A model for association in bivariate life tables and its application in epidemiological studies of familial tendency in chronic disease incidence;,citation_abstract=The application of Cox’s (1972) regression model for censored survival data to epidemiological studies of chronic disease incidence is discussed. A related model for association in bivariate survivorship time distributions is proposed for the analysis of familial tendency in disease incidence. The possible extension of the model to general multivariate survivorship distributions is indicated.;,citation_author=D. G. Clayton;,citation_publication_date=1978;,citation_cover_date=1978;,citation_year=1978;,citation_fulltext_html_url=http://www.jstor.org/stable/2335289;,citation_issue=1;,citation_issn=00063444;,citation_volume=65;,citation_journal_title=Biometrika;,citation_publisher=[Oxford University Press, Biometrika Trust];">
<meta name="citation_reference" content="citation_title=Multivariate models and multivariate dependence concepts;,citation_author=H. Joe;,citation_publication_date=1997;,citation_cover_date=1997;,citation_year=1997;,citation_fulltext_html_url=https://books.google.fr/books?id=iJbRZL2QzMAC;,citation_isbn=9780412073311;,citation_series_title=Chapman &amp;amp;amp; hall/CRC monographs on statistics &amp; applied probability;">
<meta name="citation_reference" content="citation_title=On the simultaneous associativity of f(x, y) and x + y - f(x, y).;,citation_author=M. J. Frank;,citation_publication_date=1979;,citation_cover_date=1979;,citation_year=1979;,citation_fulltext_html_url=http://eudml.org/doc/136825;,citation_volume=19;,citation_journal_title=Aequationes mathematicae;">
<meta name="citation_reference" content="citation_title=A class of bivariate distributions including the bivariate logistic;,citation_abstract=A univariate logistic distribution can be specified by considering a suitable form for the odds in favor of a failure against survival. This concept is extended to the bivariate case and a class of distributions, indexed by a parameter of association, having given marginals is proposed. Some properties of the proposed class of distributions are studied.;,citation_author=Mir M Ali;,citation_author=N. N Mikhail;,citation_author=M.Safiul Haq;,citation_publication_date=1978;,citation_cover_date=1978;,citation_year=1978;,citation_fulltext_html_url=https://www.sciencedirect.com/science/article/pii/0047259X78900635;,citation_issue=3;,citation_doi=https://doi.org/10.1016/0047-259X(78)90063-5;,citation_issn=0047-259X;,citation_volume=8;,citation_journal_title=Journal of Multivariate Analysis;">
<meta name="citation_reference" content="citation_title=The NumPy array: a structure for efficient numerical computation;,citation_author=Stefan Van Der Walt;,citation_author=S. Chris Colbert;,citation_author=Gaël Varoquaux;,citation_publication_date=2011-03;,citation_cover_date=2011-03;,citation_year=2011;,citation_fulltext_html_url=https://hal.inria.fr/inria-00564007;,citation_issue=2;,citation_doi=10.1109/MCSE.2011.37;,citation_volume=13;,citation_journal_title=Computing in Science and Engineering;,citation_publisher=Institute of Electrical and Electronics Engineers;">
<meta name="citation_reference" content="citation_title=SciPy: Open source scientific tools for Python;,citation_author=Eric Jones;,citation_author=Travis Oliphant;,citation_author=Pearu Peterson;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_fulltext_html_url=http://www.scipy.org;">
<meta name="citation_reference" content="citation_title=Data structures for statistical computing in python;,citation_author=Wes Mckinney;,citation_publication_date=2010-01;,citation_cover_date=2010-01;,citation_year=2010;,citation_journal_title=Proceedings of the 9th Python in Science Conference;">
<meta name="citation_reference" content="citation_title=Quantitative risk management: Concepts, techniques and tools-revised edition;,citation_author=Alexander J McNeil;,citation_author=Rüdiger Frey;,citation_author=Paul Embrechts;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=Principles of copula theory;,citation_author=Fabrizio Durante;,citation_author=Carlo Sempi;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_volume=474;">
<meta name="citation_reference" content="citation_title=An introduction to copulas;,citation_author=Roger B Nelsen;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;">
<meta name="citation_reference" content="citation_title=Multivariate Archimedean copulas, d-monotone functions and l1-norm symmetric distributions;,citation_author=Alexander J. McNeil;,citation_author=Johanna Nešlehová;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_fulltext_html_url=https://doi.org/10.1214/07-AOS556;,citation_issue=5B;,citation_doi=10.1214/07-AOS556;,citation_volume=37;,citation_journal_title=The Annals of Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Likelihood inference for archimedean copulas in high dimensions under known margins;,citation_author=Marius Hofert;,citation_author=Martin Mächler;,citation_author=Alexander J McNeil;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_volume=110;,citation_journal_title=Journal of Multivariate Analysis;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Max-infinite divisibility;,citation_author=August A Balkema;,citation_author=Sidney I Resnick;,citation_publication_date=1977;,citation_cover_date=1977;,citation_year=1977;,citation_issue=2;,citation_volume=14;,citation_journal_title=Journal of Applied Probability;,citation_publisher=Cambridge University Press;">
<meta name="citation_reference" content="citation_title=Non-parametric estimator of a multivariate madogram for missing-data and extreme value framework;,citation_author=Alexis Boulin;,citation_author=Elena Di Bernardino;,citation_author=Thomas Laloë;,citation_author=Gwladys Toulemonde;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_volume=192;,citation_journal_title=Journal of Multivariate Analysis;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Families of multivariate distributions;,citation_abstract=For many years there has been an interest in families of bivariate distributions with marginals as parameters. Genest and MacKay (1986a, b) showed that several such families that appear in the literature can be derived by a unified method. A similar conclusion is obtained in this article through the use of mixture models. These models might be regarded as multivariate proportional hazards models with random constants of proportionality. The mixture models are useful for two purposes. First, they make some properties of the derived distributions more transparent; the positive-dependency property of association is sometimes exposed, and a method for simulation of data from the distributions is suggested. But the mixture models also allow derivation of several new families of bivariate distributions with marginals as parameters, and they indicate obvious multivariate extensions. Some of the new families of bivariate distributions given in this article extend known distributions by adding a parameter to make them more flexible. Other families are derived that appear to be entirely new.;,citation_author=Albert W. Marshall;,citation_author=Ingram Olkin;,citation_publication_date=1988;,citation_cover_date=1988;,citation_year=1988;,citation_fulltext_html_url=http://www.jstor.org/stable/2289314;,citation_issue=403;,citation_issn=01621459;,citation_volume=83;,citation_journal_title=Journal of the American Statistical Association;,citation_publisher=[American Statistical Association, Taylor &amp;amp;amp; Francis, Ltd.];">
<meta name="citation_reference" content="citation_title=Understanding relationships using copulas;,citation_author=Edward W Frees;,citation_author=Emiliano A Valdez;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_issue=1;,citation_volume=2;,citation_journal_title=North American actuarial journal;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Vine copula classifiers for the mind reading problem;,citation_author=Diana Carrera;,citation_author=Roberto Santana;,citation_author=José Antonio Lozano;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_volume=5;,citation_journal_title=Progress in Artificial Intelligence;">
<meta name="citation_reference" content="citation_title=Gaussian process vine copulas for multivariate dependence;,citation_author=David Lopez-Paz;,citation_author=Jose Miguel Hernández-Lobato;,citation_author=Ghahramani Zoubin;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_conference_title=International conference on machine learning;,citation_conference=PMLR;">
<meta name="citation_reference" content="citation_title=Copula graphical models for wind resource estimation;,citation_author=Kalyan Veeramachaneni;,citation_author=Alfredo Cuesta-Infante;,citation_author=Una-May O’Reilly;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference_title=IJCAI;">
<meta name="citation_reference" content="citation_title=Learning vine copula models for synthetic data generation;,citation_author=Yi Sun;,citation_author=Alfredo Cuesta-Infante;,citation_author=Kalyan Veeramachaneni;,citation_publication_date=2019-07;,citation_cover_date=2019-07;,citation_year=2019;,citation_fulltext_html_url=https://ojs.aaai.org/index.php/AAAI/article/view/4437;,citation_issue=01;,citation_doi=10.1609/aaai.v33i01.33015049;,citation_volume=33;,citation_journal_title=Proceedings of the AAAI Conference on Artificial Intelligence;">
<meta name="citation_reference" content="citation_title=A geometric investigation into the tail dependence of vine copulas;,citation_abstract=Vine copulas are a type of multivariate dependence model, composed of a collection of bivariate copulas that are combined according to a specific underlying graphical structure. Their flexibility and practicality in moderate and high dimensions have contributed to the popularity of vine copulas, but relatively little attention has been paid to their extremal properties. To address this issue, we present results on the tail dependence properties of some of the most widely studied vine copula classes. We focus our study on the coefficient of tail dependence and the asymptotic shape of the sample cloud, which we calculate using the geometric approach of Nolde (2014). We offer new insights by presenting results for trivariate vine copulas constructed from asymptotically dependent and asymptotically independent bivariate copulas, focusing on bivariate extreme value and inverted extreme value copulas, with additional detail provided for logistic and inverted logistic examples. We also present new theory for a class of higher dimensional vine copulas, constructed from bivariate inverted extreme value copulas.;,citation_author=Emma S. Simpson;,citation_author=Jennifer L. Wadsworth;,citation_author=Jonathan A. Tawn;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://www.sciencedirect.com/science/article/pii/S0047259X21000142;,citation_doi=https://doi.org/10.1016/j.jmva.2021.104736;,citation_issn=0047-259X;,citation_volume=184;,citation_journal_title=Journal of Multivariate Analysis;">
<meta name="citation_reference" content="citation_title=Multi-task sparse structure learning with gaussian copula models;,citation_abstract=Multi-task learning (MTL) aims to improve generalization performance by learning multiple related tasks simultaneously. While sometimes the underlying task relationship structure is known, often the structure needs to be estimated from data at hand. In this paper, we present a novel family of models for MTL, applicable to regression and classification problems, capable of learning the structure of tasks relationship. In particular, we consider a joint estimation problem of the tasks relationship structure and the individual task parameters, which is solved using alternating minimization. The task relationship revealed by structure learning is founded on recent advances in Gaussian graphical models endowed with sparse estimators of the precision (inverse covariance) matrix. An extension to include exible Gaussian copula models that relaxes the Gaussian marginal assumption is also proposed. We illustrate the effectiveness of the proposed model on a variety of synthetic and benchmark data sets for regression and classification. We also consider the problem of combining Earth System Model (ESM) outputs for better projections of future climate, with focus on projections of temperature by combining ESMs in South and North America, and show that the proposed model outperforms several existing methods for the problem.;,citation_author=André R. Gonçalves;,citation_author=Fernando J. Von Zuben;,citation_author=Arindam Banerjee;,citation_publication_date=2016-01;,citation_cover_date=2016-01;,citation_year=2016;,citation_issue=1;,citation_issn=1532-4435;,citation_volume=17;,citation_journal_title=J. Mach. Learn. Res.;,citation_publisher=JMLR.org;">
<meta name="citation_reference" content="citation_title=Linking representations for multivariate extremes via a limit set;,citation_author=Natalia Nolde;,citation_author=Jennifer L. Wadsworth;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://arxiv.org/abs/2012.00990;">
<meta name="citation_reference" content="citation_title=Quantitative risk management - concepts, techniques and tools;,citation_author=Paul Embrechts Alexander J. McNeil;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_fulltext_html_url=libgen.li/file.php?md5=478a0059673fecd0c76229cd3d8884e7;,citation_series_title=Princeton series in finance;">
<meta name="citation_reference" content="citation_title=Tails of multivariate archimedean copulas;,citation_abstract=A complete and user-friendly directory of tails of Archimedean copulas is presented which can be used in the selection and construction of appropriate models with desired properties. The results are synthesized in the form of a decision tree: Given the values of some readily computable characteristics of the Archimedean generator, the upper and lower tails of the copula are classified into one of three classes each, one corresponding to asymptotic dependence and the other two to asymptotic independence. For a long list of single-parameter families, the relevant tail quantities are computed so that the corresponding classes in the decision tree can easily be determined. In addition, new models with tailor-made upper and lower tails can be constructed via a number of transformation methods. The frequently occurring category of asymptotic independence turns out to conceal a surprisingly rich variety of tail dependence structures.;,citation_author=Arthur Charpentier;,citation_author=Johan Segers;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_fulltext_html_url=https://www.sciencedirect.com/science/article/pii/S0047259X08002790;,citation_issue=7;,citation_doi=https://doi.org/10.1016/j.jmva.2008.12.015;,citation_issn=0047-259X;,citation_volume=100;,citation_journal_title=Journal of Multivariate Analysis;">
<meta name="citation_reference" content="citation_title=Rank-based inference for bivariate extreme-value copulas;,citation_author=Christian Genest;,citation_author=Johan Segers;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=5B;,citation_volume=37;,citation_journal_title=The Annals of Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Asymptotic normality of extreme value estimators on \mathcal{C}([0, 1]);,citation_abstract=Consider n i.i.d. random elements on C[0, 1]. We show that, under an appropriate strengthening of the domain of attraction condition, natural estimators of the extreme-value index, which is now a continuous function, and the normalizing functions have a Gaussian process as limiting distribution. A key tool is the weak convergence of a weighted tail empirical process, which makes it possible to obtain the results uniformly on [0, 1]. Detailed examples are also presented.;,citation_author=John H. J. Einmahl;,citation_author=Tao Lin;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_fulltext_html_url=http://www.jstor.org/stable/25463423;,citation_issue=1;,citation_issn=00905364;,citation_volume=34;,citation_journal_title=The Annals of Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Inverse probability weighted estimation for general missing data problems;,citation_abstract=I study inverse probability weighted M-estimation under a general missing data scheme. Examples include M-estimation with missing data due to a censored survival time, propensity score estimation of the average treatment effect in the linear exponential family, and variable probability sampling with observed retention frequencies. I extend an important result known to hold in special cases: estimating the selection probabilities is generally more efficient than if the known selection probabilities could be used in estimation. For the treatment effect case, the setup allows a general characterization of a “double robustness” result due to Scharfstein et al. [1999. Rejoinder. Journal of the American Statistical Association 94, 1135–1146].;,citation_author=Jeffrey M. Wooldridge;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_fulltext_html_url=https://www.sciencedirect.com/science/article/pii/S0304407607000437;,citation_issue=2;,citation_doi=https://doi.org/10.1016/j.jeconom.2007.02.002;,citation_issn=0304-4076;,citation_volume=141;,citation_journal_title=Journal of Econometrics;">
<meta name="citation_reference" content="citation_title=Doubly robust inference for the distribution function in the presence of missing survey data;,citation_abstract=Abstract Item non-response in surveys occurs when some, but not all, variables are missing. Unadjusted estimators tend to exhibit some bias, called the non-response bias, if the respondents differ from the non-respondents with respect to the study variables. In this paper, we focus on item non-response, which is usually treated by some form of single imputation. We examine the properties of doubly robust imputation procedures, which are those that lead to an estimator that remains consistent if either the outcome variable or the non-response mechanism is adequately modelled. We establish the double robustness property of the imputed estimator of the finite population distribution function under random hot-deck imputation within classes. We also discuss the links between our approach and that of Chambers and Dunstan. The results of a simulation study support our findings.;,citation_author=Helene Boistard;,citation_author=Guillaume Chauvet;,citation_author=David Haziza;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_fulltext_html_url=https://onlinelibrary.wiley.com/doi/abs/10.1111/sjos.12198;,citation_issue=3;,citation_doi=https://doi.org/10.1111/sjos.12198;,citation_volume=43;,citation_journal_title=Scandinavian Journal of Statistics;">
<meta name="citation_reference" content="citation_title=Exact simulation of max-stable processes;,citation_abstract=Max-stable processes play an important role as models for spatial extreme events. Their complex structure as the pointwise maximum over an infinite number of random functions makes their simulation difficult. Algorithms based on finite approximations are often inexact and computationally inefficient. We present a new algorithm for exact simulation of a max-stable process at a finite number of locations. It relies on the idea of simulating only the extremal functions, that is, those functions in the construction of a max-stable process that effectively contribute to the pointwise maximum. We further generalize the algorithm by Dieker
&amp;amp;amp;amp; Mikosch (2015) for Brown–Resnick processes and use it for exact simulation via the spectral measure. We study the complexity of both algorithms, prove that our new approach via extremal functions is always more efficient, and provide closed-form expressions for their implementation that cover most popular models for max-stable processes and multivariate extreme value distributions. For simulation on dense grids, an adaptive design of the extremal function algorithm is proposed.;,citation_author=Clément Dombry;,citation_author=Sebastian Engelke;,citation_author=Marco Oesting;,citation_publication_date=2016-05;,citation_cover_date=2016-05;,citation_year=2016;,citation_fulltext_html_url=https://doi.org/10.1093/biomet/asw008;,citation_issue=2;,citation_doi=10.1093/biomet/asw008;,citation_issn=0006-3444;,citation_volume=103;,citation_journal_title=Biometrika;">
<meta name="citation_reference" content="citation_title=A mixture model for multivariate extremes;,citation_abstract=Summary. The spectral density function plays a key role in fitting the tail of multivariate extre‐mal data and so in estimating probabilities of rare events. This function satisfies moment con‐straints but unlike the univariate extreme value distributions has no simple parametric form. Parameterized subfamilies of spectral densities have been suggested for use in applications, and non‐parametric estimation procedures have been proposed, but semiparametric models for multivariate extremes have hitherto received little attention. We show that mixtures of Dirichlet distributions satisfying the moment constraints are weakly dense in the class of all non‐parametric spectral densities, and discuss frequentist and Bayesian inference in this class based on the EM algorithm and reversible jump Markov chain Monte Carlo simulation. We illustrate the ideas using simulated and real data.;,citation_author=M.‐O. Boldi;,citation_author=A. C. Davison;,citation_publication_date=2007-04;,citation_cover_date=2007-04;,citation_year=2007;,citation_fulltext_html_url=https://ideas.repec.org/a/bla/jorssb/v69y2007i2p217-229.html;,citation_issue=2;,citation_doi=10.1111/j.1467-9868.2007.;,citation_volume=69;,citation_journal_title=Journal of the Royal Statistical Society Series B;">
<meta name="citation_reference" content="citation_title=Extreme value theory;,citation_author=R. L. Smith;,citation_publication_date=1990;,citation_cover_date=1990;,citation_year=1990;">
<meta name="citation_reference" content="citation_title=Array programming with NumPy;,citation_author=Charles R Harris;,citation_author=K Jarrod Millman;,citation_author=Stéfan J Van Der Walt;,citation_author=Ralf Gommers;,citation_author=Pauli Virtanen;,citation_author=David Cournapeau;,citation_author=Eric Wieser;,citation_author=Julian Taylor;,citation_author=Sebastian Berg;,citation_author=Nathaniel J Smith;,citation_author=others;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_issue=7825;,citation_volume=585;,citation_journal_title=Nature;,citation_publisher=Nature Publishing Group;">
<meta name="citation_reference" content="citation_title=SciPy 1.0: Fundamental algorithms for scientific computing in python;,citation_author=Pauli Virtanen;,citation_author=Ralf Gommers;,citation_author=Travis E Oliphant;,citation_author=Matt Haberland;,citation_author=Tyler Reddy;,citation_author=David Cournapeau;,citation_author=Evgeni Burovski;,citation_author=Pearu Peterson;,citation_author=Warren Weckesser;,citation_author=Jonathan Bright;,citation_author=others;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_issue=3;,citation_volume=17;,citation_journal_title=Nature methods;,citation_publisher=Nature Publishing Group;">
<meta name="citation_reference" content="citation_title=New estimators of the pickands dependence function and a test for extreme-value dependence;,citation_author=Axel Bücher;,citation_author=Holger Dette;,citation_author=Stanislav Volgushev;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=4;,citation_volume=39;,citation_journal_title=The Annals of Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=A review of copula models for economic time series;,citation_author=Andrew J Patton;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_volume=110;,citation_journal_title=Journal of Multivariate Analysis;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Drought modeling – a review;,citation_abstract=Summary In recent years droughts have been occurring frequently, and their impacts are being aggravated by the rise in water demand and the variability in hydro-meteorological variables due to climate change. As a result, drought hydrology has been receiving much attention. A variety of concepts have been applied to modeling droughts, ranging from simplistic approaches to more complex models. It is important to understand different modeling approaches as well as their advantages and limitations. This paper, supplementing the previous paper (Mishra and Singh, 2010) where different concepts of droughts were highlighted, reviews different methodologies used for drought modeling, which include drought forecasting, probability based modeling, spatio-temporal analysis, use of Global Climate Models (GCMs) for drought scenarios, land data assimilation systems for drought modeling, and drought planning. It is found that there have been significant improvements in modeling droughts over the past three decades. Hybrid models, incorporating large scale climate indices, seem to be promising for long lead-time drought forecasting. Further research is needed to understand the spatio-temporal complexity of droughts under climate change due to changes in spatio-temporal variability of precipitation. Applications of copula based models for multivariate drought characterization seem to be promising for better drought characterization. Research on decision support systems should be advanced for issuing warnings, assessing risk, and taking precautionary measures, and the effective ways for the flow of information from decision makers to users need to be developed. Finally, some remarks are made regarding the future outlook for drought research.;,citation_author=Ashok K. Mishra;,citation_author=Vijay P. Singh;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_fulltext_html_url=https://www.sciencedirect.com/science/article/pii/S0022169411002393;,citation_issue=1;,citation_doi=https://doi.org/10.1016/j.jhydrol.2011.03.049;,citation_issn=0022-1694;,citation_volume=403;,citation_journal_title=Journal of Hydrology;">
<meta name="citation_reference" content="citation_title=Openturns: An industrial software for uncertainty quantification in simulation;,citation_author=Michaël Baudin;,citation_author=Anne Dutfoy;,citation_author=Bertrand Iooss;,citation_author=Anne-Laure Popelin;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_inbook_title=Handbook of uncertainty quantification;">
<meta name="citation_reference" content="citation_title=Pycop: A python package for dependence modeling with copulas;,citation_author=Maxime LD Nicolas;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_volume=70;,citation_journal_title=Zenodo Software Package;">
<meta name="citation_reference" content="citation_title=Modeling multivariate distributions with continuous margins using the copula r package;,citation_author=Ivan Kojadinovic;,citation_author=Jun Yan;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_volume=34;,citation_journal_title=Journal of Statistical Software;">
<meta name="citation_reference" content="citation_title=mev: Modelling extreme values;,citation_author=Leo Belzile;,citation_author=others;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://CRAN.R-project.org/package=mev;">
</head>

<body>

<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title"><a href="https://computo.sfds.asso.fr">
        <img src="https://computo.sfds.asso.fr/assets/img/logo_notext_white.png" height="60px">
      </a> &nbsp; A Python Package for Sampling from Copulae: clayton</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> source</button></div></div>
            <p class="subtitle lead">A Python Package for Sampling from Copulae: clayton</p>
            <p><a href="http://creativecommons.org/licenses/by/4.0/"><img src="https://i.creativecommons.org/l/by/4.0/80x15.png" alt="Creative Commons BY License"></a>
ISSN 2824-7795</p>
            <div>
        <div class="description">
          <p>The package <span class="math inline">\textsf{clayton}</span> is designed to be intuitive, user-friendly, and efficient. It offers a wide range of copula models, including Archimedean, Elliptical, and Extreme. The package is implemented in pure <span class="math inline">\textsf{Python}</span>, making it easy to install and use.</p>
        </div>
      </div>
                </div>
  </div>
    
    <div class="quarto-title-meta-author">
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-heading">Affiliations</div>
          
          <div class="quarto-title-meta-contents">
        <a href="https://aleboul.github.io/">Alexis Boulin</a> 
      </div>
          
          <div class="quarto-title-meta-contents">
              <p class="affiliation">
                  <a href="https://univ-cotedazur.fr/">
                  Université Côte d’Azur, CNRS, LJAD, France
                  </a>
                </p>
              <p class="affiliation">
                  <a href="https://www.inria.fr/fr/lemon">
                  Inria, Lemon
                  </a>
                </p>
            </div>
        </div>
                    
  <div class="quarto-title-meta">
                                
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">January 12, 2023</p>
      </div>
    </div>
                                    
      <div>
      <div class="quarto-title-meta-heading">Modified</div>
      <div class="quarto-title-meta-contents">
        <p class="date-modified">January 9, 2024</p>
      </div>
    </div>
      
                  
      <div>
      <div class="quarto-title-meta-heading">Keywords</div>
      <div class="quarto-title-meta-contents">
        <p class="date">Copulae, Random number generation</p>
      </div>
    </div>
    
    <div>
      <div class="quarto-title-meta-heading">Status</div>
      <div class="quarto-title-meta-contents">
              <a href="https://github.com/computorg/published-202301-boulin-clayton"><img src="https://github.com/computorg/published-202301-boulin-clayton/actions/workflows/build.yml/badge.svg" alt="build status"></a>
                    <p class="date"></p>
        <a href="https://github.com/computorg/published-202301-boulin-clayton/issues?q=is%3Aopen+is%3Aissue+label%3Areview"><img src="https://img.shields.io/badge/reviews-reports-blue" alt="reviews"></a>
            </div>
    </div>

  </div>
                                                
  <div>
    <div class="abstract">
    <div class="abstract-title">Abstract</div>
      <p>The package <span class="math inline">\textsf{clayton}</span> is designed to be intuitive, user-friendly, and efficient. It offers a wide range of copula models, including Archimedean, Elliptical, and Extreme. The package is implemented in pure <span class="math inline">\textsf{Python}</span>, making it easy to install and use. In addition, we provide detailed documentation and examples to help users get started quickly. We also conduct a performance comparison with existing <span class="math inline">\textsf{R}</span> packages, demonstrating the efficiency of our implementation. The <span class="math inline">\textsf{clayton}</span> package is a valuable tool for researchers and practitioners working with copulae in <span class="math inline">\textsf{Python}</span>.</p>
    </div>
  </div>

  </header><div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">1</span> Introduction</a></li>
  <li><a href="#sec-classes" id="toc-sec-classes" class="nav-link" data-scroll-target="#sec-classes"><span class="header-section-number">2</span> Classes</a>
  <ul class="collapse">
  <li><a href="#sec-arch" id="toc-sec-arch" class="nav-link" data-scroll-target="#sec-arch"><span class="header-section-number">2.1</span> The Archimedean class</a></li>
  <li><a href="#sec-extreme" id="toc-sec-extreme" class="nav-link" data-scroll-target="#sec-extreme"><span class="header-section-number">2.2</span> The Extreme class</a></li>
  </ul></li>
  <li><a href="#sec-rng" id="toc-sec-rng" class="nav-link" data-scroll-target="#sec-rng"><span class="header-section-number">3</span> Random number generator</a>
  <ul class="collapse">
  <li><a href="#sec-biv_case" id="toc-sec-biv_case" class="nav-link" data-scroll-target="#sec-biv_case"><span class="header-section-number">3.1</span> The bivariate case</a></li>
  <li><a href="#sec-mv_case" id="toc-sec-mv_case" class="nav-link" data-scroll-target="#sec-mv_case"><span class="header-section-number">3.2</span> The multivariate case</a></li>
  </ul></li>
  <li><a href="#sec-pairwise" id="toc-sec-pairwise" class="nav-link" data-scroll-target="#sec-pairwise"><span class="header-section-number">4</span> Case study : Modeling pairwise dependence between spatial maximas with missing data</a>
  <ul class="collapse">
  <li><a href="#sec-background" id="toc-sec-background" class="nav-link" data-scroll-target="#sec-background"><span class="header-section-number">4.1</span> Background</a></li>
  <li><a href="#sec-num" id="toc-sec-num" class="nav-link" data-scroll-target="#sec-num"><span class="header-section-number">4.2</span> Numerical results</a></li>
  </ul></li>
  <li><a href="#sec-discussion" id="toc-sec-discussion" class="nav-link" data-scroll-target="#sec-discussion"><span class="header-section-number">5</span> Discussion</a>
  <ul class="collapse">
  <li><a href="#comparison-of-textsfclayton-with-textsfr-packages" id="toc-comparison-of-textsfclayton-with-textsfr-packages" class="nav-link" data-scroll-target="#comparison-of-textsfclayton-with-textsfr-packages"><span class="header-section-number">5.1</span> Comparison of <span class="math inline">\textsf{clayton}</span> with <span class="math inline">\textsf{R}</span> packages</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="header-section-number">5.2</span> Conclusion</a></li>
  </ul></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  <li><a href="#appendices" id="toc-appendices" class="nav-link" data-scroll-target="#appendices"><span class="header-section-number">6</span> Appendix</a>
  <ul class="collapse">
  <li><a href="#sec-bv_arch" id="toc-sec-bv_arch" class="nav-link" data-scroll-target="#sec-bv_arch"><span class="header-section-number">6.1</span> Bivariate Archimedean models</a></li>
  <li><a href="#sec-bv_ext" id="toc-sec-bv_ext" class="nav-link" data-scroll-target="#sec-bv_ext"><span class="header-section-number">6.2</span> Implemented bivariate extreme models</a></li>
  <li><a href="#sec-mv_arch" id="toc-sec-mv_arch" class="nav-link" data-scroll-target="#sec-mv_arch"><span class="header-section-number">6.3</span> Multivariate Archimedean copulae</a></li>
  <li><a href="#sec-mv_ext" id="toc-sec-mv_ext" class="nav-link" data-scroll-target="#sec-mv_ext"><span class="header-section-number">6.4</span> Multivariate extreme models</a></li>
  <li><a href="#sec-mv_ellip" id="toc-sec-mv_ellip" class="nav-link" data-scroll-target="#sec-mv_ellip"><span class="header-section-number">6.5</span> Multivariate elliptical dependencies</a></li>
  </ul></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="published-202301-boulin-clayton.pdf"><i class="bi bi-file-pdf"></i>PDF (computo)</a></li></ul></div></nav>
</div>
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="introduction" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Introduction</h1>
<p>Modeling dependence relations between random variables is a topic of interest in probability theory and statistics. The most popular approach is based on the second moment of the underlying random variables, namely, the covariance. It is well known that only linear dependence can be captured by the covariance and it is only characteristic for a few models, e.g., the multivariate normal distribution or binary random variables. As a beneficial alternative to dependence, the concept of copulae, going back to <span class="citation" data-cites="Skla59">Sklar (<a href="#ref-Skla59" role="doc-biblioref">1959</a>)</span>, has drawn a lot of attention. The copula <span class="math inline">C: [0,1]^d \rightarrow [0,1]</span> of a random vector <span class="math inline">\mathbf{X} = (X_0, \dots, X_{d-1})</span> with <span class="math inline">d \geq 2</span> allows us to separate the effect of dependence from the effect of the marginal distribution, such that:</p>
<p><span class="math display">
    \mathbb{P}\left\{ X_0 \leq x_0, \dots, X_{d-1} \leq x_{d-1} \right\} = C\left(\mathbb{P} \{X_0 \leq x_0\}, \dots, \mathbb{P}\{X_{d-1} \leq x_{d-1} \}\right),
</span></p>
<p>where <span class="math inline">(x_0, \dots, x_{d-1}) \in \mathbb{R}^d</span>. The main consequence of this identity is that the copula completely characterizes the stochastic dependence between the margins of <span class="math inline">\mathbf{X}</span>.</p>
<p>In other words, copulae allow us to model marginal distributions and dependence structure separately. Furthermore, motivated by Sklar’s theorem, the problem of investigating stochastic dependence is reduced to the study of multivariate distribution functions under the unit hypercube <span class="math inline">[0,1]^d</span> with uniform margins. The theory of copulae has been of prime interest for many applied fields of science, such as quantitative finance (<span class="citation" data-cites="patton2012review">Patton (<a href="#ref-patton2012review" role="doc-biblioref">2012</a>)</span>) or environmental sciences (<span class="citation" data-cites="MISHRA2011157">Mishra and Singh (<a href="#ref-MISHRA2011157" role="doc-biblioref">2011</a>)</span>). This increasing number of applications has led to a demand for statistical methods. For example, semiparametric estimation (<span class="citation" data-cites="10.2307/2337532">Genest, Ghoudi, and Rivest (<a href="#ref-10.2307/2337532" role="doc-biblioref">1995</a>)</span>), nonparametric estimation (<span class="citation" data-cites="10.2307/3318798">Fermanian, Radulović, and Wegkamp (<a href="#ref-10.2307/3318798" role="doc-biblioref">2004</a>)</span>) of copulae or nonparametric estimation of conditional copulae (<span class="citation" data-cites="10.2307/24586878">Gijbels, Omelka, and Veraverbeke (<a href="#ref-10.2307/24586878" role="doc-biblioref">2015</a>)</span>, <span class="citation" data-cites="PORTIER2018160">Portier and Segers (<a href="#ref-PORTIER2018160" role="doc-biblioref">2018</a>)</span>) have been investigated. These results are established for a fixed arbitrary dimension <span class="math inline">d \geq 2</span>, but several investigations (e.g. <span class="citation" data-cites="10.2307/25463423">Einmahl and Lin (<a href="#ref-10.2307/25463423" role="doc-biblioref">2006</a>)</span>, <span class="citation" data-cites="10.1214/21-AOS2050">Einmahl and Segers (<a href="#ref-10.1214/21-AOS2050" role="doc-biblioref">2021</a>)</span>) are done for functional data for the tail copula, which captures dependence in the upper tail.</p>
<p>Software implementation of copulae has been extensively studied in <span class="math inline">\textsf{R}</span>, for example in the packages <span class="citation" data-cites="evdR">A. G. Stephenson (<a href="#ref-evdR" role="doc-biblioref">2002</a>)</span>, <span class="citation" data-cites="copulaR">Jun Yan (<a href="#ref-copulaR" role="doc-biblioref">2007</a>)</span>, <span class="citation" data-cites="VineCopulaR">Schepsmeier et al. (<a href="#ref-VineCopulaR" role="doc-biblioref">2019</a>)</span>. However, methods for working with copulae in <span class="math inline">\textsf{Python}</span> are still limited. As far as we know, copula-dedicated packages in <span class="math inline">\textsf{Python}</span> are mainly designed for modeling, such as <span class="citation" data-cites="copulasPy">Alvarez et al. (<a href="#ref-copulasPy" role="doc-biblioref">2021</a>)</span> and <span class="citation" data-cites="copulaePy">Bock and Chapman (<a href="#ref-copulaePy" role="doc-biblioref">2021</a>)</span>. These packages use maximum likelihood methods to estimate the copula parameters from observed data and generate synthetic data using the estimated copula model. Other packages provide sampling methods for copulae, but they are typically restricted to the bivariate case and the conditional simulation method (see, for example, <span class="citation" data-cites="baudin2017openturns">Baudin et al. (<a href="#ref-baudin2017openturns" role="doc-biblioref">2017</a>)</span>). Additionally, if the multivariate case is considered only Archimedean and elliptical copulae are under interest and those packages (see <span class="citation" data-cites="nicolas2022pycop">Nicolas (<a href="#ref-nicolas2022pycop" role="doc-biblioref">2022</a>)</span>) do not include the extreme value class in arbitrary dimensions <span class="math inline">d \geq 2</span>. In this paper, we propose to implement a wide range of copulae, including the extreme value class, in arbitrary fixed dimension <span class="math inline">d \geq 2</span>.</p>
<p>Through this paper we adopt the following notational conventions: all the indices will start at <span class="math inline">0</span> as in <span class="math inline">\textsf{Python}</span>. Consider <span class="math inline">(\Omega, \mathcal{A}, \mathbb{P})</span> a probability space and let <span class="math inline">\textbf{X} = (X_0, \dots, X_{d-1})</span> be a <span class="math inline">d</span>-dimensional random vector with values in <span class="math inline">(\mathbb{R}^d, \mathcal{B}(\mathbb{R}^d))</span>, with <span class="math inline">d \geq 2</span> and <span class="math inline">\mathcal{B}(\mathbb{R}^d)</span> the Borel <span class="math inline">\sigma</span>-algebra of <span class="math inline">\mathbb{R}^d</span>. This random vector has a joint distribution <span class="math inline">F</span> with copula <span class="math inline">C</span> and its margins are denoted by <span class="math inline">F_j(x) = \mathbb{P}\{X_j \leq x\}</span> for all <span class="math inline">x \in \mathbb{R}</span> and <span class="math inline">j \in \{0, \dots, d-1\}</span>. Denote by <span class="math inline">\textbf{U} = (U_0, \dots, U_{d-1})</span> a <span class="math inline">d</span> random vector with copula <span class="math inline">C</span> and uniform margins. All bold letters <span class="math inline">\textbf{x}</span> will denote a vector of <span class="math inline">\mathbb{R}^d</span>.</p>
<p>The <span class="math inline">\textsf{clayton}</span> package, whose Python code can be found in <a href="https://github.com/Aleboul/clayton">https://github.com/Aleboul/clayton</a>, uses object-oriented features of the Python language. The package contains classes for Archimedean, elliptical, and extreme value copulae. In <a href="#sec-classes" class="quarto-xref">Section&nbsp;2</a>, we briefly describe the classes defined in the package. <a href="#sec-rng" class="quarto-xref">Section&nbsp;3</a> presents methods for generating random vectors. In <a href="#sec-pairwise" class="quarto-xref">Section&nbsp;4</a>, we apply the <span class="math inline">\textsf{clayton}</span> package to model pairwise dependence between maxima. <a href="#sec-discussion" class="quarto-xref">Section&nbsp;5</a> discusses potential improvements to the package and provides concluding remarks. Sections from <a href="#sec-bv_arch" class="quarto-xref">Section&nbsp;6.1</a> to <a href="#sec-mv_ellip" class="quarto-xref">Section&nbsp;6.5</a> define and illustrate all the parametric copula models implemented in the package.</p>
</section>
<section id="sec-classes" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Classes</h1>
<div id="fig-diagram" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-diagram-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/diagram.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-diagram-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: The figure shows a object diagram that structures the code. The <span class="math inline">\textbf{Multivariate}</span> class serves as the root and is used to instantiate all its child classes <span class="math inline">\textbf{Archimedean}</span>, <span class="math inline">\textbf{Extreme}</span>, <span class="math inline">\textbf{Gaussian}</span>, and <span class="math inline">\textbf{Student}</span> in red. The blue-colored classes correspond to various parametric copula models, and the green-colored classes represent examples of methods. Symbols <span class="math inline">\varphi, \varphi^\leftarrow, \dot{\varphi}</span> correspond to the generator function, its inverse, and its derivative, respectively, while <span class="math inline">A, \dot{A}</span> refer to the Pickands dependence function and its derivative.
</figcaption>
</figure>
</div>
<p>The architecture of the code is shown in <a href="#fig-diagram" class="quarto-xref">Figure&nbsp;1</a>. At the third level of the architecture, we find important parametric models of Archimedean and extreme value copulae (depicted as blue in the figure). These parametric models contain methods such as the generator function <span class="math inline">\varphi</span> (see <a href="#sec-arch" class="quarto-xref">Section&nbsp;2.1</a>) for Archimedean copulae and the Pickands dependence function <span class="math inline">A</span> (see <a href="#sec-extreme" class="quarto-xref">Section&nbsp;2.2</a>) for extreme value copulae (depicted as green in the figure). We provide a brief overview of Archimedean copulae and some of their properties in high-dimensional spaces in <a href="#sec-arch" class="quarto-xref">Section&nbsp;2.1</a>. A characterization of extreme value copulae is given in <a href="#sec-extreme" class="quarto-xref">Section&nbsp;2.2</a>. The from <a href="#sec-bv_arch" class="quarto-xref">Section&nbsp;6.1</a> to <a href="#sec-mv_ellip" class="quarto-xref">Section&nbsp;6.5</a> define and illustrate all the copula models implemented in the package.</p>
<section id="sec-arch" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="sec-arch"><span class="header-section-number">2.1</span> The Archimedean class</h2>
<p>Let <span class="math inline">\varphi</span> be a generator that is a strictly decreasing, convex function from <span class="math inline">[0,1]</span> to <span class="math inline">[0, \infty]</span> such that <span class="math inline">\varphi(1) = 0</span> and <span class="math inline">\varphi(0) = \infty</span>. We denote the generalized inverse of <span class="math inline">\varphi</span> by <span class="math inline">\varphi^\leftarrow</span>. Consider the following equation:</p>
<p><span id="eq-arch_cop"><span class="math display">
    C(\textbf{u}) = \varphi^\leftarrow (\varphi(u_0)+ \dots + \varphi(u_{d-1})).
\tag{1}</span></span></p>
<p>If this relation holds and <span class="math inline">C</span> is a copula function, then <span class="math inline">C</span> is called an Archimedean copula. A necessary condition for <a href="#eq-arch_cop" class="quarto-xref">Equation&nbsp;1</a> to be a copula is that the generator <span class="math inline">\varphi</span> is a <span class="math inline">d</span>-monotonic function, i.e., it is differentiable up to the order <span class="math inline">d</span> and its derivatives satisfy</p>
<p><span id="eq-dmono"><span class="math display">
  (-1)^k \left(\varphi\right)^{(k)}(x) \geq 0, \quad k \in \{1, \dots, d\}
\tag{2}</span></span></p>
<p>for <span class="math inline">x \in (0, \infty)</span> (see Corollary 2.1 of <span class="citation" data-cites="10.1214/07-AOS556">McNeil and Nešlehová (<a href="#ref-10.1214/07-AOS556" role="doc-biblioref">2009</a>)</span>). Note that <span class="math inline">d</span>-monotonic Archimedean inverse generators do not necessarily generate Archimedean copulae in dimensions higher than <span class="math inline">d</span> (see <span class="citation" data-cites="10.1214/07-AOS556">McNeil and Nešlehová (<a href="#ref-10.1214/07-AOS556" role="doc-biblioref">2009</a>)</span>). As a result, some Archimedean subclasses are only implemented for the bivariate case as they do not generate an Archimedean copula in higher dimensions. In the bivariate case, <a href="#eq-dmono" class="quarto-xref">Equation&nbsp;2</a> can be interpreted as <span class="math inline">\varphi</span> being a convex function.</p>
<p>The <span class="math inline">\textsf{clayton}</span> package implements common one-parameter families of Archimedean copulae, such as the Clayton (<span class="citation" data-cites="10.2307/2335289">Clayton (<a href="#ref-10.2307/2335289" role="doc-biblioref">1978</a>)</span>), Gumbel (<span class="citation" data-cites="1960">Gumbel (<a href="#ref-1960" role="doc-biblioref">1960</a>)</span>), Joe (<span class="citation" data-cites="joe1997multivariate">Joe (<a href="#ref-joe1997multivariate" role="doc-biblioref">1997</a>)</span>), Frank (<span class="citation" data-cites="Frank1979">Frank (<a href="#ref-Frank1979" role="doc-biblioref">1979</a>)</span>), and AMH (<span class="citation" data-cites="ALI1978405">Ali, Mikhail, and Haq (<a href="#ref-ALI1978405" role="doc-biblioref">1978</a>)</span>) copulae for the multivariate case. It is worth noting that all Archimedean copulae are symmetric, and in dimensions 3 or higher, only positive associations are allowed. For the specific bivariate case, the package also implements other families, such as those numbered from 4.2.9 to 4.2.15 and 4.2.22 in Section 4.2 of <span class="citation" data-cites="nelsen2007introduction">Nelsen (<a href="#ref-nelsen2007introduction" role="doc-biblioref">2007</a>)</span>. Definitions and illustrations of these parametric copula models can be found in <a href="#sec-bv_arch" class="quarto-xref">Section&nbsp;6.1</a> and <a href="#sec-mv_arch" class="quarto-xref">Section&nbsp;6.3</a>.</p>
</section>
<section id="sec-extreme" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="sec-extreme"><span class="header-section-number">2.2</span> The Extreme class</h2>
<p>Investigating the notion of copulae within the framework of multivariate extreme value theory leads to the extreme value copulae (see <span class="citation" data-cites="gudendorf2009extremevalue">Gudendorf and Segers (<a href="#ref-gudendorf2009extremevalue" role="doc-biblioref">2010</a>)</span> for an overview) defined as <span id="eq-evc"><span class="math display">
C(\textbf{u}) = \exp \left( - \ell(-\ln(u_0), \dots, -\ln(u_{d-1})) \right), \quad \textbf{u} \in (0,1]^d,
\tag{3}</span></span> where <span class="math inline">\ell: [0,\infty)^d \rightarrow [0,\infty)</span> the stable tail dependence function which is convex, homogeneous of order one, namely <span class="math inline">\ell(c\textbf{x}) = c \ell(\textbf{x})</span> for <span class="math inline">c &gt; 0</span> and satisfies <span class="math inline">\max(x_0,\dots,x_{d-1})  \leq \ell(x_0,\dots,x_{d-1}) \leq x_0+\dots+x_{d-1}, \forall \textbf{x} \in [0,\infty)^d</span>. Let <span class="math inline">\Delta^{d-1} = \{\textbf{w} \in [0,1]^d: w_0 + \dots + w_{d-1} = 1\}</span> be the unit simplex. The Pickands dependence function <span class="math inline">A: \Delta^{d-1} \rightarrow [1/d,1]</span> characterizes <span class="math inline">\ell</span> by its homogeneity, which is the restriction of <span class="math inline">\ell</span> to the unit simplex <span class="math inline">\Delta^{d-1}</span>: <span id="eq-tail_dependence_pickands"><span class="math display">
  \ell(x_0, \dots,x_{d-1}) = (x_0 + \dots + x_{d-1}) A(w_0, \dots, w_{d-1}), \quad w_j = \frac{x_j}{x_0 + \dots + x_{d-1}},
\tag{4}</span></span> for <span class="math inline">j \in \{1,\dots,d-1\}</span> and <span class="math inline">w_0 = 1 - w_1 - \dots - w_{d-1}</span> with <span class="math inline">\textbf{x} \in [0, \infty)^d \setminus \{\textbf{0}\}</span>. The Pickands dependence function characterizes the extremal dependence structure of an extreme value random vector and verifies <span class="math inline">\max\{w_0,\dots,w_{d-1}\} \leq A(w_0,\dots,w_{d-1}) \leq 1</span> where the lower bound corresponds to comonotonicity and the upper bound corresponds to independence. Estimating this function is an active area of research, with many compelling studies having been conducted on the topic (see, for example, <span class="citation" data-cites="bucher2011new">Bücher, Dette, and Volgushev (<a href="#ref-bucher2011new" role="doc-biblioref">2011</a>)</span>, <span class="citation" data-cites="GUDENDORF20123073">Gudendorf and Segers (<a href="#ref-GUDENDORF20123073" role="doc-biblioref">2012</a>)</span>).</p>
<p>From a practical point of view, the family of extreme value copulae is very rich and arises naturally as the limiting distribution of properly normalised componentwise maxima. Furthermore, it contains a rich variety of parametric models and allows asymmetric dependence, that is, for the bivariate case: <span class="math display">
  \exists (u_0,u_1) \in [0,1]^2, \quad C(u_0,u_1) \neq C(u_1,u_0).
</span></p>
<p>In the multivariate framework, the logistic copula (or Gumbel, see <span class="citation" data-cites="1960">Gumbel (<a href="#ref-1960" role="doc-biblioref">1960</a>)</span>), the asymmetric logistic copula (<span class="citation" data-cites="tawn1990">Tawn (<a href="#ref-tawn1990" role="doc-biblioref">1990</a>)</span>), the Hüsler and Reiss distribution (<span class="citation" data-cites="HUSLER1989283">Hüsler and Reiss (<a href="#ref-HUSLER1989283" role="doc-biblioref">1989</a>)</span>), the t-EV copula (<span class="citation" data-cites="Demarta_Mcneil">Demarta and McNeil (<a href="#ref-Demarta_Mcneil" role="doc-biblioref">2005</a>)</span>), Bilogistic model (<span class="citation" data-cites="Smith1990">Smith (<a href="#ref-Smith1990" role="doc-biblioref">1990</a>)</span>) are implemented. It’s worth noting that the logistic copula is the sole model that is both Archimedean and extreme value. The library includes bivariate extreme value copulae such as asymmetric negative logistic (<span class="citation" data-cites="Joe1990FamiliesOM">Joe (<a href="#ref-Joe1990FamiliesOM" role="doc-biblioref">1990</a>)</span>), asymmetric mixed (<span class="citation" data-cites="10.1093/biomet/75.3.397">Tawn (<a href="#ref-10.1093/biomet/75.3.397" role="doc-biblioref">1988</a>)</span>). The reader is again invited to read from <a href="#sec-bv_ext" class="quarto-xref">Section&nbsp;6.2</a> to <a href="#sec-mv_ext" class="quarto-xref">Section&nbsp;6.4</a> for precise definitions of these models.</p>
</section>
</section>
<section id="sec-rng" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Random number generator</h1>
<p>We propose a <span class="math inline">\textsf{Python}</span>-based implementation for generating random numbers from a wide variety of copulae. The <span class="math inline">\textsf{clayton}</span> package requires a few external libraries that are commonly used in scientific computing in <span class="math inline">\textsf{Python}</span>.</p>
<ul>
<li><code>numpy</code> version 1.6.1 or newer. This is the fundamental package for scientific computing, it contains linear algebra functions and matrix / vector objects (<span class="citation" data-cites="harris2020array">Harris et al. (<a href="#ref-harris2020array" role="doc-biblioref">2020</a>)</span>).</li>
<li><code>scipy</code> version 1.7.1 or newer. A library of open-source software for mathematics, science and engineering (<span class="citation" data-cites="virtanen2020scipy">Virtanen et al. (<a href="#ref-virtanen2020scipy" role="doc-biblioref">2020</a>)</span>).</li>
</ul>
<p>The <span class="math inline">\textsf{clayton}</span> package provides two methods for generating random vectors: <span class="math inline">\texttt{sample\_unimargin}</span> and <span class="math inline">\texttt{sample}</span>. The first method generates a sample where the margins are uniformly distributed on the unit interval <span class="math inline">[0,1]</span>, while the second method generates a sample from the chosen margins.</p>
<p>In <a href="#sec-biv_case" class="quarto-xref">Section&nbsp;3.1</a>, we present an algorithm that uses the conditioning method to sample from a copula. This method is very general and can be used for any copula that is sufficiently smooth (see <a href="#eq-cond_sim" class="quarto-xref">Equation&nbsp;5</a> and <a href="#eq-cond_dist_mv" class="quarto-xref">Equation&nbsp;8</a> below). However, the practical infeasibility of the algorithm in dimensions higher than <span class="math inline">2</span> and the computational intensity of numerical inversion call for more efficient ways to sample in higher dimensions. The purpose of <a href="#sec-mv_case" class="quarto-xref">Section&nbsp;3.2</a> is to present such methods and to provide details on the methods used in the <span class="math inline">\textsf{clayton}</span> package. In each section, we provide examples of code to illustrate how to instantiate a copula and how to sample with <span class="math inline">\textsf{clayton}</span>.</p>
<p>In the following sections, we will use <span class="math inline">\textsf{Python}</span> code that assumes that the following packages have been loaded:</p>
<div id="4cdc660c" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> clayton</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> clayton.rng <span class="im">import</span> base, evd, archimedean, monte_carlo</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm, expon</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>plt.style.use(<span class="st">'qb-light.mplstyle'</span>) <span class="co"># for fancy figures</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<section id="sec-biv_case" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="sec-biv_case"><span class="header-section-number">3.1</span> The bivariate case</h2>
<p>In this subsection, we address the problem of generating a bivariate sample from a specified joint distribution with <span class="math inline">d=2</span>. Suppose that we want to sample a bivariate random vector <span class="math inline">\textbf{X}</span> with copula <span class="math inline">C</span>. In the case where the components are independent, the sampling procedure is straightforward: we can independently sample <span class="math inline">X_0</span> and <span class="math inline">X_1</span>. However, in the general case where the copula is not the independent copula, this approach is not applicable.</p>
<p>One solution to this problem is to use the conditioning method to sample from the copula. This method relies on the fact that given <span class="math inline">(U_0, U_1)</span> with copula <span class="math inline">C</span>, the conditonal law of <span class="math inline">U_1</span> given <span class="math inline">U_0</span> is written as:</p>
<p><span id="eq-cond_sim"><span class="math display">
  c_{u_0}(u_1) \triangleq \mathbb{P}\left\{ U_1 \leq u_1 | U_0 = u_0 \right\} = \frac{\partial C(u_0,u_1)}{\partial u_0}.
\tag{5}</span></span></p>
<p>This allows us to first sample <span class="math inline">U_0</span> from a uniform distribution on the unit interval, and then to use the copula to generate <span class="math inline">U_1</span> given <span class="math inline">U_0</span>. Finally, we can transform the resulting sample <span class="math inline">(U_0, U_1)</span> into the original space by applying the inverse marginal distributions <span class="math inline">F_0^{-1}</span> and <span class="math inline">F_1^{-1}</span> to <span class="math inline">U_0</span> and <span class="math inline">U_1</span> respectively. Thus, an algorithm for sampling bivariate copulae is given in <a href="#fig-alg-1" class="quarto-xref">Figure&nbsp;2</a>. Algorithm in <a href="#fig-alg-1" class="quarto-xref">Figure&nbsp;2</a> presents a procedure for generating a bivariate sample from a copula. The algorithm takes as input the length of the sample <span class="math inline">n</span>, as well as the parameters of the copula (<span class="math inline">\theta, \psi_1, \psi_2</span>). The output is a bivariate sample from the desired copula model, denoted <span class="math inline">\{(u_0^{(1)},u_1^{(1)}), \dots, (u_0^{(n)},u_1^{(n)})\}</span>. This algorithm is applicable as long as the copula has a first partial derivative with respect to its first component.</p>
<div id="fig-alg-1" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-alg-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/alg_1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-alg-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Conditional sampling from copula
</figcaption>
</figure>
</div>
<p>For step 6 of the algorithm, we need to find <span class="math inline">u_1 \in [0,1]</span> such that <span class="math inline">c_{u_0}(u_1) - t_1 = 0</span> holds. This <span class="math inline">u_1</span> always exists because for every <span class="math inline">u \in ]0,1[</span>, we have <span class="math inline">0 \leq c_{u_0}(u) \leq 1</span>, and the function <span class="math inline">u \mapsto c_{u_0}(u)</span> is increasing (see Theorem 2.2.7 of <span class="citation" data-cites="nelsen2007introduction">Nelsen (<a href="#ref-nelsen2007introduction" role="doc-biblioref">2007</a>)</span> for a proof). This step can be solved using the function from the package. A sufficient condition for a copula to have a first partial derivative with respect to its first component in the Archimedean and extreme value cases is that the generator <span class="math inline">\varphi</span> and the Pickands dependence function <span class="math inline">A</span> are continuously differentiable on <span class="math inline">]0,1[</span>, respectively. In this case, the first partial derivatives of the copula are given by:</p>
<p><span id="eq-partial_deriv_arch"><span class="math display">
    \frac{\partial C}{\partial u_0}(u_0,u_1) = \frac{\varphi'(u_0)}{\varphi'(C(u_0,u_1))}, \quad (u_0,u_1) \in ]0,1[^2,
\tag{6}</span></span></p>
<p><span id="eq-partial_deriv_pick"><span class="math display">
    \frac{\partial C}{\partial u_0}(u_0,u_1) = \frac{\varphi'(u_0)}{\varphi'(C(u_0,u_1))}, \quad (u_0,u_1) \in ]0,1[^2,
\tag{7}</span></span></p>
<p>where <span class="math inline">t = \ln(u_1) / \ln(u_0u_1) \in (0,1)</span> and <span class="math inline">\mu(t) = A(t) - tA'(t)</span>.</p>
<p>We now have all the necessary theoretical tools to give details on how the <span class="math inline">\textsf{clayton}</span> package is designed. The file <span class="math inline">\texttt{base.py}</span> contains the <span class="math inline">\textbf{Multivariate}</span> class and the <span class="math inline">\texttt{sample}</span> method to generate random numbers from <span class="math inline">\textbf{X}</span> with copula <span class="math inline">C</span>. To do so, we use the inversion method that is to sample from <span class="math inline">\textbf{U}</span> using algorithm in <a href="#fig-alg-1" class="quarto-xref">Figure&nbsp;2</a> and we compose the corresponding uniform margins by <span class="math inline">F_j^\leftarrow</span>. indicates that the sole knowledge of <span class="math inline">A</span> and <span class="math inline">\varphi</span> and their respective derivatives are needed in order to perform the sixth step of algorithm in <a href="#fig-alg-1" class="quarto-xref">Figure&nbsp;2</a>. For that purpose, <span class="math inline">\texttt{cond\_sim}</span> method located inside <span class="math inline">\textbf{Archimedean}</span> and <span class="math inline">\textbf{Extreme}</span> classes performs algorithm in <a href="#fig-alg-1" class="quarto-xref">Figure&nbsp;2</a>. Then each child of the bivariate <span class="math inline">\textbf{Archimedean}</span> (resp. <span class="math inline">\textbf{Extreme}</span>) class is thus defined by its generator <span class="math inline">\varphi</span> (resp. <span class="math inline">A</span>), it’s derivative <span class="math inline">\varphi'</span> (resp. <span class="math inline">A'</span>) and it’s inverse <span class="math inline">\varphi^\leftarrow</span> as emphasized in green in <a href="#fig-diagram" class="quarto-xref">Figure&nbsp;1</a>. Namely, we perform algorithm in <a href="#fig-alg-1" class="quarto-xref">Figure&nbsp;2</a> for the <span class="math inline">\textbf{Archimedean}</span> subclasses <span class="math inline">\texttt{Frank}</span>, <span class="math inline">\texttt{AMH}</span>, <span class="math inline">\texttt{Clayton}</span> (when <span class="math inline">\theta &lt; 0</span> for the previous three), <span class="math inline">\texttt{Nelsen\_9}</span>, <span class="math inline">\texttt{Nelsen\_10}</span>, <span class="math inline">\texttt{Nelsen\_11}</span>, <span class="math inline">\texttt{Nelsen\_12}</span>, <span class="math inline">\texttt{Nelsen\_13}</span>, <span class="math inline">\texttt{Nelsen\_14}</span>, <span class="math inline">\texttt{Nelsen\_15}</span> and <span class="math inline">\texttt{Nelsen\_22}</span>. For the <span class="math inline">\textbf{Extreme}</span> class, such algorithm is performed for the <span class="math inline">\texttt{AsyNegLog}</span> and <span class="math inline">\texttt{AsyMix}</span>. For other models, faster algorithms are known and thus implemented, we refer to <a href="#sec-mv_case" class="quarto-xref">Section&nbsp;3.2</a> for details.</p>
<p>The following code illustrates the random vector generation for a bivariate Archimedean copula. By defining the parameter of the copula and the sample’s length, the constructor for this copula is available and can be called using the <span class="math inline">\texttt{Clayton}</span> method, such as:</p>
<div id="3577c242" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>  n_samples, theta <span class="op">=</span> <span class="dv">1024</span>, <span class="op">-</span><span class="fl">0.5</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  copula <span class="op">=</span> archimedean.Clayton(theta<span class="op">=</span>theta, n_samples<span class="op">=</span>n_samples)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>To obtain a sample with uniform margins and a Clayton copula, we can use the <span class="math inline">\texttt{sample\_unimargin}</span> method, as follows:</p>
<div id="6a7113de" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>  sample <span class="op">=</span> copula.sample_unimargin()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Here, the <span class="math inline">\texttt{sample}</span> object is a <span class="math inline">\textsf{numpy}</span> array with <span class="math inline">2</span> columns and <span class="math inline">1024</span> rows, where each row contains a realization from a Clayton copula (see below)</p>
<div id="12d8dc01" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>  fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>  ax.scatter(sample[:,<span class="dv">0</span>], sample[:,<span class="dv">1</span>],</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>             edgecolors<span class="op">=</span><span class="st">'#6F6F6F'</span>, color<span class="op">=</span><span class="st">'#C5C5C5'</span>, s<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>  ax.set_xlabel(<span class="vs">r'$u_0$'</span>)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>  ax.set_ylabel(<span class="vs">r'$u_1$'</span>)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>  plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="published-202301-boulin-clayton_files/figure-html/cell-5-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="sec-mv_case" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="sec-mv_case"><span class="header-section-number">3.2</span> The multivariate case</h2>
<p>We will now address the generation of multivariate Archimedean and Extreme value copulae proposed in the Clayton package. In the multivariate case, the link between partial derivatives and the conditional law remains. Indeed, let <span class="math inline">(U_0, \dots, U_{d-1})</span> be a <span class="math inline">d</span>-dimensional random vector with uniform margins and copula <span class="math inline">C</span>. The conditional distribution of <span class="math inline">U_k</span> given the values of <span class="math inline">U_0, \dots, U_{k-1}</span> is</p>
<p><span id="eq-cond_dist_mv"><span class="math display">
  \mathbb{P}\left\{ U_k \leq u_k | U_0 = u_0, \dots, U_{k-1} = u_{k-1} \right\} = \frac{\partial^{k-1} C(u_0, \dots, u_k,1,\dots,1)/\partial u_0 \dots \partial u_{k-1}}{\partial^{k-1} C(u_0, \dots, u_{k-1},1,\dots,1) / \partial u_0 \dots \partial u_{k-1}}.
\tag{8}</span></span></p>
<p>for <span class="math inline">k \in {1,\dots, d-1}</span>. The conditional simulation algorithm may be written as follows.</p>
<ol type="1">
<li>Generate <span class="math inline">d</span> independent uniform random on <span class="math inline">[0,1]</span> variates <span class="math inline">v_0, \dots, v_{d-1}</span>.</li>
<li>Set <span class="math inline">u_0 = v_0</span>.</li>
<li>For <span class="math inline">k = 1, \dots, d-1</span>, evaluate the inverse of the conditional distribution given by at <span class="math inline">v_k</span>, to generate <span class="math inline">u_k</span>.</li>
</ol>
<p>Nevertheless, the evaluation of the inverse conditional distribution becomes increasingly complicated as the dimension <span class="math inline">d</span> increases. Furthermore, it can be difficult for some models to derive a closed form of <a href="#eq-cond_dist_mv" class="quarto-xref">Equation&nbsp;8</a> that makes it impossible to implement it in a general algorithm with only the dimension <span class="math inline">d</span> as an input. For multivariate Archimedean copulae, <span class="citation" data-cites="10.1214/07-AOS556">McNeil and Nešlehová (<a href="#ref-10.1214/07-AOS556" role="doc-biblioref">2009</a>)</span> give a method to generate a random vector from the <span class="math inline">d</span>-dimensional copula <span class="math inline">C</span> with generator <span class="math inline">\varphi</span> (see Section 5.2 of <span class="citation" data-cites="10.1214/07-AOS556">McNeil and Nešlehová (<a href="#ref-10.1214/07-AOS556" role="doc-biblioref">2009</a>)</span>). A stochastic representation for Archimedean copulae generated by a <span class="math inline">d</span>-monotone generator is given by</p>
<p><span id="eq-radial"><span class="math display">
\textbf{U} = \left( \varphi^\leftarrow(R S_1), \dots, \varphi^\leftarrow(RS_d) \right) \sim C,
\tag{9}</span></span></p>
<p>where <span class="math inline">R \sim F_R</span>, the radial distribution which is independent of <span class="math inline">S</span> and <span class="math inline">S</span> is distributed uniformly in the unit simplex <span class="math inline">\Delta^{d-1}</span>. One challenging aspect of this algorithm is to have an accurate evaluation of the radial distribution of the Archimedean copula and thus to numerically inverse this distribution. The associated radial distribution for the <span class="math inline">\textsf{Clayton}</span> copula is given in Example 3.3 <span class="citation" data-cites="10.1214/07-AOS556">McNeil and Nešlehová (<a href="#ref-10.1214/07-AOS556" role="doc-biblioref">2009</a>)</span> while those of the <span class="math inline">\textsf{Joe}</span>, <span class="math inline">\textsf{AMH}</span>, <span class="math inline">\textsf{Gumbel}</span> and <span class="math inline">\textsf{Frank}</span> copulae are given in <span class="citation" data-cites="hofert2012likelihood">Hofert, Mächler, and McNeil (<a href="#ref-hofert2012likelihood" role="doc-biblioref">2012</a>)</span>. In general, one can use numerical inversion algorithms for computing the inverse of the radial distribution, however it will lead to spurious numerical errors. Other algorithms exist when the generator is known to be the Laplace-Stieltjes transform, denoted as <span class="math inline">\mathcal{LS}</span>, of some positive random variables (see <span class="citation" data-cites="10.2307/2289314">Marshall and Olkin (<a href="#ref-10.2307/2289314" role="doc-biblioref">1988</a>)</span>, <span class="citation" data-cites="frees1998understanding">Frees and Valdez (<a href="#ref-frees1998understanding" role="doc-biblioref">1998</a>)</span>). This positive random variable is often referenced as the frailty distribution. In this framework, Archimedean copulae allow for the stochastic representation</p>
<p><span class="math display">
  \textbf{U} = \left( \varphi^\leftarrow (E_1/V), \dots, \varphi^\leftarrow(E_d /V)\right) \sim C,
</span></p>
<p>with <span class="math inline">V \sim F = \mathcal{LS}^{-1}[\varphi^\leftarrow]</span> the frailty and <span class="math inline">E_1, \dots, E_d</span> are distributed i.i.d. according to a standard exponential and independent of <span class="math inline">V</span>. Algorithm in <a href="#fig-alg-2" class="quarto-xref">Figure&nbsp;3</a> presents a procedure for generating a multivariate sample from an Archimedean copula where the frailty distribution is known. The algorithm takes as an input the length of the sample <span class="math inline">n</span>, as well as the parameter of the copula <span class="math inline">\theta</span>. The output is a <span class="math inline">d</span>-variate sample from the desired copula model, denoted <span class="math inline">\{(u_0^{(1)}, \dots, u_{d-1}^{(1)}), \dots, (u_0^{(n)},\dots,u_{d-1}^{(n)})\}</span>.</p>
<div id="fig-alg-2" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-alg-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/alg_2.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-alg-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Sampling from Archimedean copula using frailty distribution
</figcaption>
</figure>
</div>
<p>In this framework, we define <span class="math inline">\texttt{\_frailty\_sim}</span> method defined inside the <span class="math inline">\textbf{Archimedean}</span> class which performs algorithm in <a href="#fig-alg-2" class="quarto-xref">Figure&nbsp;3</a>. Then, each Archimedean copula is defined by the generator <span class="math inline">\varphi</span>, it’s inverse <span class="math inline">\varphi^\leftarrow</span> and the frailty distribution denoted as <span class="math inline">\mathcal{LS}^{-1}[\varphi^\leftarrow]</span> as long as we know the frailty. This is the case for <span class="math inline">\texttt{Joe}</span>, <span class="math inline">\texttt{Clayton}</span>, <span class="math inline">\texttt{AMH}</span> or <span class="math inline">\texttt{Frank}</span>.</p>
<p>For the extreme value case, algorithms have been proposed, as in <span class="citation" data-cites="stephenson2003simulating">A. Stephenson (<a href="#ref-stephenson2003simulating" role="doc-biblioref">2003</a>)</span> (see Algorithms 2.1 and 2.2), who proposes sampling methods for the Gumbel and the asymmetric logistic model. These algorithms are implemented in the <span class="math inline">\textsf{clayton}</span> package. Note that these algorithms are model-specific, thus the <span class="math inline">\texttt{sample\_unimargin}</span> method is exceptionally located in the corresponding child of the multivariate <span class="math inline">\textbf{Extreme}</span> class. Another procedure designed by <span class="citation" data-cites="10.1093/biomet/asw008">Dombry, Engelke, and Oesting (<a href="#ref-10.1093/biomet/asw008" role="doc-biblioref">2016</a>)</span> to sample from multivariate extreme value models using extremal functions (see Algorithm 2 in <span class="citation" data-cites="10.1093/biomet/asw008">Dombry, Engelke, and Oesting (<a href="#ref-10.1093/biomet/asw008" role="doc-biblioref">2016</a>)</span>) is also of prime interest. For the implemented models using this algorithm, namely <span class="math inline">\textbf{Hüsler-Reiss}</span>, <span class="math inline">\textbf{tEV}</span>, <span class="math inline">\textbf{Bilogistic}</span> and <span class="math inline">\textbf{Dirichlet}</span> models, a method called <span class="math inline">\texttt{\_rextfunc}</span> is located inside each classes which allows to generate an observation from the according law of the extremal function.</p>
<p>Samples from the Gaussian and Student copula are directly given by Algorithm 5.9 and 5.10 respectively of <span class="citation" data-cites="quantrisk">Alexander J. McNeil (<a href="#ref-quantrisk" role="doc-biblioref">2005</a>)</span>. As each algorithm is model specific, the <span class="math inline">\texttt{sample\_unimargin}</span> method is located inside the <span class="math inline">\textbf{Gaussian}</span> and <span class="math inline">\textbf{Student}</span> classes.</p>
<p>We present how to construct a multivariate Archimedean copula and to generate random vectors from this model. Introducing the parameters of the copula, we appeal the following lines to construct our copula object:</p>
<div id="63432b15" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>d, theta, n_samples <span class="op">=</span> <span class="dv">3</span>, <span class="fl">2.0</span>, <span class="dv">1024</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>copula <span class="op">=</span> archimedean.Clayton(theta<span class="op">=</span>theta, n_samples<span class="op">=</span>n_samples, dim<span class="op">=</span>d)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We now call the <span class="math inline">\texttt{sample\_unimargin}</span> method to obtain randomly generated vectors.</p>
<div id="c472357f" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>sample <span class="op">=</span> copula.sample_unimargin()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We thus represent in three dimensions these realizations below.</p>
<div id="65e3a36a" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>  fig <span class="op">=</span> plt.figure()</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>  ax <span class="op">=</span> fig.add_subplot(<span class="dv">111</span>, projection <span class="op">=</span> <span class="st">'3d'</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>  ax.scatter3D(sample[:,<span class="dv">0</span>], sample[:,<span class="dv">1</span>], sample[:,<span class="dv">2</span>], s<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>               edgecolors<span class="op">=</span><span class="st">'#6F6F6F'</span>, color<span class="op">=</span><span class="st">'#C5C5C5'</span>)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>  ax.set_xlabel(<span class="vs">r'$u_0$'</span>)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>  ax.set_ylabel(<span class="vs">r'$u_1$'</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>  ax.set_zlabel(<span class="vs">r'$u_2$'</span>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>  plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="published-202301-boulin-clayton_files/figure-html/cell-8-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="sec-pairwise" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Case study : Modeling pairwise dependence between spatial maximas with missing data</h1>
<p>We now proceed to a case study where we use our package to assess, under a finite sample framework, the asymptotic properties of an estimator of the <span class="math inline">\lambda</span>-madogram when data are completely missing at random (MCAR). This case study comes from numerical results of <span class="citation" data-cites="boulin2021non">Boulin et al. (<a href="#ref-boulin2021non" role="doc-biblioref">2022</a>)</span>. The <span class="math inline">\lambda</span>-madogram belongs to a family of estimators, namely the madogram, which is of prime interest in environmental sciences, as it is designed to model pairwise dependence between maxima in space, see, e.g., <span class="citation" data-cites="bernard:hal-03207469">Bernard et al. (<a href="#ref-bernard:hal-03207469" role="doc-biblioref">2013</a>)</span>, <span class="citation" data-cites="BADOR201517">Bador et al. (<a href="#ref-BADOR201517" role="doc-biblioref">2015</a>)</span>, <span class="citation" data-cites="saunders">Saunders, Stephenson, and Karoly (<a href="#ref-saunders" role="doc-biblioref">2021</a>)</span> where the madogram was used as a dissimilarity measure to perform clustering. Where in several fields, for example econometrics (<span class="citation" data-cites="woolridge2007">Wooldridge (<a href="#ref-woolridge2007" role="doc-biblioref">2007</a>)</span>) or survey theory (<span class="citation" data-cites="chauvet2015">Boistard, Chauvet, and Haziza (<a href="#ref-chauvet2015" role="doc-biblioref">2016</a>)</span>), the MCAR hypothesis appears to be a strong hypothesis, this hypothesis is more realistic in environmental research as the missingness of one observation is usually due to instruments, communication and processing errors that may be reasonably supposed independent of the quantity of interest. In <a href="#sec-background" class="quarto-xref">Section&nbsp;4.1</a>, we define objects and properties of interest while in <a href="#sec-num" class="quarto-xref">Section&nbsp;4.2</a> we describe a detailed tutorial in <span class="math inline">\textsf{python}</span> and with <span class="math inline">\textsf{clayton}</span> package to compare the asymptotic variance with an empirical counterpart of the <span class="math inline">\lambda</span>-madogram with <span class="math inline">\lambda = 0.5</span>.</p>
<section id="sec-background" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="sec-background"><span class="header-section-number">4.1</span> Background</h2>
<p>It was emphasized that the possible dependence between maxima can be described with the extreme value copula. This function is completely characterized by the Pickands dependence function (see <a href="#eq-tail_dependence_pickands" class="quarto-xref">Equation&nbsp;4</a>) where the latter is equivalent to the <span class="math inline">\lambda</span>-madogram introduced by <span class="citation" data-cites="naveau:hal-00312758">Naveau et al. (<a href="#ref-naveau:hal-00312758" role="doc-biblioref">2009</a>)</span> and defined as</p>
<p><span id="eq-lmbd_mado"><span class="math display">
  \nu(\lambda) = \mathbb{E}\left[ \left|\{F_0(X_0)\}^{1/\lambda} - \{F_1(X_1)\}^{1/(1-\lambda)} \right|\right],
\tag{10}</span></span></p>
<p>with <span class="math inline">\lambda \in (0,1)</span>, and if <span class="math inline">\lambda = 0</span> and <span class="math inline">0&lt;u&lt;1</span>, then <span class="math inline">u^{1/\lambda} = 0</span> by convention. The <span class="math inline">\lambda</span>-madogram took its inspiration from the extensively used geostatistics tool, the variogram (see Chapter 1.3 of <span class="citation" data-cites="alma991005826659705596">Gaetan and Guyon (<a href="#ref-alma991005826659705596" role="doc-biblioref">2008</a>)</span> for a definition and some classical properties). The <span class="math inline">\lambda</span>-madogram can be interpreted as the <span class="math inline">L_1</span>-distance between the uniform margins elevated to the inverse of the corresponding weights <span class="math inline">\lambda</span> and <span class="math inline">1-\lambda</span>. This quantity describes the dependence structure between extremes by its relation with the Pickands dependence function. If we suppose that <span class="math inline">C</span> is an extreme value copula as in , we have</p>
<p><span id="eq-pickands_mado"><span class="math display">
  A(\lambda) = \frac{\nu(\lambda) + c(\lambda)}{1-\nu(\lambda) - c(\lambda)},
\tag{11}</span></span></p>
<p>with <span class="math inline">c(\lambda) = 2^{-1} (\lambda / (1-\lambda) + (1-\lambda)/\lambda)</span> (see Proposition 3 of <span class="citation" data-cites="MARCON20171">Marcon et al. (<a href="#ref-MARCON20171" role="doc-biblioref">2017</a>)</span> for details).</p>
<p>We consider independent and identically distributed i.i.d. copies <span class="math inline">\textbf{X}_1, \dots, \textbf{X}_n</span> of <span class="math inline">\textbf{X}</span>. In presence of missing data, we do not observe a complete vector <span class="math inline">\textbf{X}_i</span> for <span class="math inline">i \in \{1,\dots,n\}</span>. We introduce <span class="math inline">\textbf{I}_i \in \{0,1\}^2</span> which satisfies, <span class="math inline">\forall j \in \{0,1\}</span>, if <span class="math inline">X_{i,j}</span> is not observed then <span class="math inline">I_{i,j} = 0</span>. To formalize incomplete observations, we introduce the incomplete vector <span class="math inline">\tilde{\textbf{X}}_i</span> with values in the product space <span class="math inline">\bigotimes_{j=1}^2 (\mathbb{R} \cup \{\textsf{NA}\})</span> such as</p>
<p><span class="math display">
  \tilde{X}_{i,j} = X_{i,j} I_{i,j} + \textsf{NA} (1-I_{i,j}), \quad i \in \{1,\dots,n\}, \, j \in \{0,\dots, d-1\}.
</span></p>
<p>We thus suppose that we observe a <span class="math inline">4</span>-tuple such as</p>
<p><span id="eq-missing_2"><span class="math display">
  (\textbf{I}_i, \tilde{\textbf{X}}_i), \quad i \in \{1,\dots,n\},
\tag{12}</span></span></p>
<p>i.e.&nbsp;at each <span class="math inline">i \in \{1,\dots,n\}</span>, several entries may be missing. We also suppose that for all <span class="math inline">i \in \{1, \dots,n \}</span>, <span class="math inline">\textbf{I}_{i}</span> are i.i.d copies from <span class="math inline">\textbf{I} = (I_0, I_1)</span> where <span class="math inline">I_j</span> is distributed according to a Bernoulli random variable <span class="math inline">\mathcal{B}(p_j)</span> with <span class="math inline">p_j = \mathbb{P}(I_j = 1)</span> for <span class="math inline">j \in \{0,1\}</span>. We denote by <span class="math inline">p</span> the probability of observing completely a realization from <span class="math inline">\textbf{X}</span>, that is <span class="math inline">p = \mathbb{P}(I_0=1, I_1 = 1)</span>. In <span class="citation" data-cites="boulin2021non">Boulin et al. (<a href="#ref-boulin2021non" role="doc-biblioref">2022</a>)</span>, hybrid and corrected estimators, respectively denoted as <span class="math inline">\hat{\nu}_n^{\mathcal{H}}</span> and <span class="math inline">\hat{\nu}_n^{\mathcal{H*}}</span>, are proposed to estimate nonparametrically the <span class="math inline">\lambda</span>-madogram in presence of missing data completely at random. Furthermore, a closed expression of their asymptotic variances for <span class="math inline">\lambda \in ]0,1[</span> is also given. This result is summarized in the following proposition.</p>
<div id="thm-line" class="theorem">
<p><span class="theorem-title"><strong>Theorem 1 (<span class="citation" data-cites="boulin2021non">Boulin et al. (<a href="#ref-boulin2021non" role="doc-biblioref">2022</a>)</span>)</strong></span> Let <span class="math inline">(\textbf{I}_i, \tilde{\textbf{X}_i})_{i=1}^n</span> be a samble given by <a href="#eq-missing_2" class="quarto-xref">Equation&nbsp;12</a>. For <span class="math inline">\lambda \in ]0,1[</span>, if <span class="math inline">C</span> is an extreme value copula with Pickands dependence function <span class="math inline">A</span>, we have as <span class="math inline">n \rightarrow \infty</span> <span class="math display">\begin{align*}
    &amp;\sqrt{n} \left(\hat{\nu}_n^{\mathcal{H}}(\lambda) - \nu( \lambda)\right) \overset{d}{\rightarrow} \mathcal{N}\left(0, \mathcal{S}^{\mathcal{H}}(p_1,p_2,p, \lambda)\right), \\
    &amp;\sqrt{n} \left(\hat{\nu}_n^{\mathcal{H}*}(\lambda) - \nu( \lambda)\right) \overset{d}{\rightarrow} \mathcal{N}\left(0, \mathcal{S}^{\mathcal{H}*}(p_1,p_2,p, \lambda)\right),
\end{align*}</span></p>
<p>where <span class="math inline">\mathcal{S}^{\mathcal{H}}(p_1,p_2,p, \lambda)</span> and <span class="math inline">\mathcal{S}^{\mathcal{H}*}(p_1,p_2,p, \lambda)</span> are the asymptoptic variances of the random variables.</p>
</div>
</section>
<section id="sec-num" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="sec-num"><span class="header-section-number">4.2</span> Numerical results</h2>
<p>Benefiting from generating data with <span class="math inline">\textsf{clayton}</span> we are thus able, with Monte Carlo simulation, to assess theoretical results given by <a href="#thm-line" class="quarto-xref">Theorem&nbsp;1</a> in a finite sample setting. For that purpose, we implement a <span class="math inline">\textsf{MonteCarlo}</span> class (in <span class="math inline">\texttt{monte\_carlo.py}</span> file) which contains some methods to perform some Monte Carlo iterations for a given extreme value copula. Now, we set up parameters to sample our bivariate dataset. For this subsection, we choose the asymmetric negative logistic model (see <a href="#sec-bv_ext" class="quarto-xref">Section&nbsp;6.2</a> for a definition) with parameters <span class="math inline">\theta = 10, \psi_1 = 0.1, \psi_2 = 1.0</span> and we define the following function:</p>
<div id="1add1b61" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> gauss_function(x, x0, sigma):</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>      <span class="cf">return</span> (np.sqrt(<span class="fl">1.</span> <span class="op">/</span> (<span class="dv">2</span><span class="op">*</span>np.pi <span class="op">*</span> sigma<span class="op">**</span><span class="dv">2</span>)) <span class="op">*</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>              np.exp(<span class="op">-</span>(x <span class="op">-</span> x0) <span class="op">**</span> <span class="dv">2</span> <span class="op">/</span> (<span class="dv">2</span> <span class="op">*</span> sigma<span class="op">**</span><span class="dv">2</span>)))</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>  n_samples <span class="op">=</span> <span class="dv">512</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>  theta, psi1, psi2 <span class="op">=</span> <span class="dv">10</span>, <span class="fl">0.1</span>, <span class="fl">1.0</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We choose the standard normal and exponential as margins. To simulate this sample, the following lines should be typed:</p>
<div id="af22e5f5" class="cell" data-execution_count="9">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>  copula <span class="op">=</span> evd.AsyNegLog(theta<span class="op">=</span>theta, psi1<span class="op">=</span>psi1,</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>                         psi2<span class="op">=</span>psi2, n_samples<span class="op">=</span>n_samples)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>  sample <span class="op">=</span> copula.sample(inv_cdf<span class="op">=</span>[norm.ppf, expon.ppf])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The <span class="math inline">1024 \times 2</span> array <span class="math inline">\texttt{sample}</span> contains <span class="math inline">1024</span> realization of the <span class="math inline">\textbf{asymmetric negative logistic}</span> model where the first column is distributed according to a standard normal random variable and the second column as a standard exponential. This distribution is depicted below. To obtain it, one needs the following lines of command:</p>
<div id="7275456a" class="cell" data-execution_count="10">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>  fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>  ax.scatter(sample[:,<span class="dv">0</span>], sample[:,<span class="dv">1</span>],</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>             edgecolors<span class="op">=</span><span class="st">"#6F6F6F"</span>, color<span class="op">=</span><span class="st">"#C5C5C5"</span>, s<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>  ax.set_xlabel(<span class="vs">r'$x_0$'</span>)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>  ax.set_ylabel(<span class="vs">r'$x_1$'</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>  plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="published-202301-boulin-clayton_files/figure-html/cell-11-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Before going into further details, we will present the missing mechanism. Let <span class="math inline">V_0</span> and <span class="math inline">V_1</span> be random variables uniformly distributed under the <span class="math inline">]0,1[</span> segment with copula <span class="math inline">C_{(V_0,V_1)}</span>. We set <span class="math inline">I_0 = 1\{{V_0 \leq p_0}\}</span> and <span class="math inline">I_1 = 1\{{V_1 \leq p_1}\}</span>. It is thus immediate that <span class="math inline">I_0 \sim \mathcal{B}(p_0)</span> and <span class="math inline">I_1 \sim \mathcal{B}(p_1)</span> and <span class="math inline">p \triangleq \mathbb{P}\{I_0 = 1, I_1 =1 \} = C_{(V_0,V_1)}(p_0, p_1)</span>. For our illustration, we will take <span class="math inline">C_{(V_0,V_1)}</span> as a copula with parameter <span class="math inline">\theta = 2.0</span> (we refer to <a href="#sec-bv_arch" class="quarto-xref">Section&nbsp;6.1</a> for a definition of this copula). For this copula, it is more likely to observe a realization <span class="math inline">v_0 \geq 0.8</span> from <span class="math inline">V_0</span> if <span class="math inline">v_1 \geq 0.8</span> from <span class="math inline">V_1</span>. If we observe <span class="math inline">v_1 &lt; 0.8</span>, the realization <span class="math inline">v_0</span> is close to being independent of <span class="math inline">v_1</span>. In climate studies, extreme events could damage the recording instrument in the surrounding regions where they occur, thus the missingness of one variable may depend on others. We initialize the copula <span class="math inline">C_{(V_0,V_1)}</span> with the following line:</p>
<div id="8cdc543a" class="cell" data-execution_count="11">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>  copula_miss <span class="op">=</span> archimedean.Joe(theta<span class="op">=</span><span class="fl">2.0</span>, n_samples<span class="op">=</span>n_samples)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>For a given <span class="math inline">\lambda \in ]0,1[</span>, we now want to estimate a <span class="math inline">\lambda</span>-madogram with a sample from the asymmetric negative logistic model, where some observations are missing due to the missing mechanism described above. We will repeat this step several times to compute an empirical counterpart of the asymptotic variance. The object has been designed for this purpose: we specify the number of iterations <span class="math inline">n_{iter}</span> (take <span class="math inline">n_{iter} = 1024</span>), the chosen extreme value copula (asymmetric negative logistic model), the missing mechanism (described by <span class="math inline">C_{(V_0,V_1)}</span> and <span class="math inline">p_0 = p_1 = 0.9</span>), and <span class="math inline">\lambda</span> (noted <span class="math inline">\texttt{w}</span>). We can write the following lines of code:</p>
<div id="8a7cd95b" class="cell" data-execution_count="12">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>  u <span class="op">=</span> np.array([<span class="fl">0.9</span>, <span class="fl">0.9</span>])</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>  n_iter, P, w <span class="op">=</span> <span class="dv">256</span>, [[u[<span class="dv">0</span>], copula_miss._c(</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>      u)], [copula_miss._c(u), u[<span class="dv">1</span>]]], np.array([<span class="fl">0.5</span>,<span class="fl">0.5</span>])</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>  monte <span class="op">=</span> monte_carlo.MonteCarlo(n_iter<span class="op">=</span>n_iter, n_samples<span class="op">=</span>n_samples,</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>                                 copula<span class="op">=</span>copula, copula_miss<span class="op">=</span>copula_miss,</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>                                 weight<span class="op">=</span>w, matp<span class="op">=</span>P)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The <span class="math inline">\texttt{MonteCarlo}</span> object is thus initialized with all parameters needed. We may use the <span class="math inline">\texttt{simu}</span> method to generate a <span class="math inline">\texttt{DataFrame}</span> (a <span class="math inline">\texttt{pandas}</span> object) composed out <span class="math inline">1024</span> rows and <span class="math inline">3</span> columns. Each row contains an estimate of the <span class="math inline">\lambda</span>-madogram, <span class="math inline">\hat{\nu}_n^{\mathcal{H}*}</span> in <a href="#thm-line" class="quarto-xref">Theorem&nbsp;1</a> (<span class="math inline">\texttt{var\_mado}</span>), the sample length <span class="math inline">n</span> (<span class="math inline">\texttt{n}</span>) and the normalized estimation error (<span class="math inline">\texttt{scaled}</span>). We thus call the <span class="math inline">\texttt{simu}</span> method.</p>
<div id="950418dc" class="cell" data-execution_count="13">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>  df_wmado <span class="op">=</span> monte.finite_sample(inv_cdf<span class="op">=</span>[norm.ppf, expon.ppf], corr<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(df_wmado.head())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>      wmado      n    scaled
0  0.148163  512.0 -0.128602
1  0.149337  512.0 -0.102024
2  0.153788  512.0 -0.001322
3  0.153169  512.0 -0.015324
4  0.155756  512.0  0.043209</code></pre>
</div>
</div>
<p>The argument <span class="math inline">\texttt{corr=True}</span> specifies that we compute the corrected estimator, <span class="math inline">\hat{\nu}_n^{\mathcal{H}*}</span> in <a href="#thm-line" class="quarto-xref">Theorem&nbsp;1</a>. Now, using the <span class="math inline">\texttt{var\_mado}</span> method defined inside in the <strong>Extreme</strong> class, we obtain the asymptotic variance for the given model and parameters from the missing mechanism. We obtain this quantity as follows</p>
<div id="64a758b2" class="cell" data-execution_count="14">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>  var_mado <span class="op">=</span> copula.var_mado(w, jointp<span class="op">=</span>copula_miss._c(u), matp<span class="op">=</span>P, corr<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(var_mado)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(df_wmado[<span class="st">'scaled'</span>].var())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>0.015417245591834503
0.01370549107120327</code></pre>
</div>
</div>
<p>We propose here to check numerically the asymptotic normality with variance <span class="math inline">\mathcal{S}^{\mathcal{H}*}</span> of the normalized estimation error of the corrected estimator. We have all data in hand and the asymptotic variance was computed by lines above. We thus write:</p>
<div id="afd43d2d" class="cell" data-execution_count="15">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>    sigma <span class="op">=</span> np.sqrt(var_mado)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> np.linspace(<span class="bu">min</span>(df_wmado[<span class="st">'scaled'</span>]), <span class="bu">max</span>(df_wmado[<span class="st">'scaled'</span>]), <span class="dv">1000</span>)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    gauss <span class="op">=</span> gauss_function(x, <span class="dv">0</span>, sigma)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    sns.displot(data<span class="op">=</span>df_wmado, x<span class="op">=</span><span class="st">"scaled"</span>, color<span class="op">=</span><span class="st">'#C5C5C5'</span>,</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>                kind<span class="op">=</span><span class="st">'hist'</span>, stat<span class="op">=</span><span class="st">'density'</span>, common_norm<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>                alpha<span class="op">=</span><span class="fl">0.5</span>, fill<span class="op">=</span><span class="va">True</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>, bins<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>    plt.plot(x,gauss, color<span class="op">=</span><span class="st">'#6F6F6F'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="published-202301-boulin-clayton_files/figure-html/cell-16-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="sec-discussion" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Discussion</h1>
<section id="comparison-of-textsfclayton-with-textsfr-packages" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="comparison-of-textsfclayton-with-textsfr-packages"><span class="header-section-number">5.1</span> Comparison of <span class="math inline">\textsf{clayton}</span> with <span class="math inline">\textsf{R}</span> packages</h2>
<p>To compare to existing packages in <span class="math inline">\textsf{R}</span>, we consider the <span class="math inline">\textsf{copula}</span> package (<span class="citation" data-cites="kojadinovic2010modeling">Kojadinovic and Yan (<a href="#ref-kojadinovic2010modeling" role="doc-biblioref">2010</a>)</span>) and <span class="math inline">\textsf{mev}</span> (<span class="citation" data-cites="mevR">Belzile et al. (<a href="#ref-mevR" role="doc-biblioref">2022</a>)</span>) for sampling from Archimedean and multivariate extreme value distributions, respectively. To run the experiment, we use two computer clusters. The first cluster consists of five nodes, each with two 18-core Xeon Gold 3.1 GHz processors and 192 GB of memory, with 2933 MHz per socket. The second cluster has two CPU sockets, each containing a Xeon Platinum 8268 2.90 GHz processor with 24 cores. These configurations provide a significant amount of computational power and are well-suited for handling complex, data-intensive tasks. We use the first cluster to install the <span class="math inline">\textsf{copula}</span> package and sample from the <span class="math inline">\textbf{Clayton}</span>, <span class="math inline">\textbf{Frank}</span>, and <span class="math inline">\textbf{Joe}</span> models. We consider an increasing dimension <span class="math inline">d \in \{50, 100, \dots, 1600\}</span> for a fixed sample size of <span class="math inline">n=1000</span>. For the copula package, we compute the average time spent across 100 runs in order to cancel out variability. We use the second cluster to install the <span class="math inline">\textsf{mev}</span> package and call some of its methods to sample from the <span class="math inline">\textbf{Husler Reiss}</span>, <span class="math inline">\textbf{Logistic}</span>, and <span class="math inline">\textbf{TEV}</span> distributions. Sampling from the latter is fast, but sampling from the two others is time consuming. Therefore, we only consider dimensions <span class="math inline">d \in \{25, 50, \dots, 250\}</span> for a fixed sample size of <span class="math inline">n=1000</span>.</p>
<div id="fig-num_res" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-num_res-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/discussion/num_time_arch.png" class="img-fluid figure-img"></p>
<figcaption>Archimedean</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/discussion/num_time_evd.png" class="img-fluid figure-img"></p>
<figcaption>Multivariate extreme value</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-num_res-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Comparison results. Time spent (in seconds) to sample from the corresponding models with respect to the dimension <span class="math inline">d</span>. The left panel shows the results for sampling from <span class="math inline">\textbf{Clayton}</span>, <span class="math inline">\textbf{Frank}</span> and <span class="math inline">\textbf{Joe}</span> using <span class="math inline">\textsf{clayton}</span> in <span class="math inline">\textsf{Python}</span> and <span class="math inline">\textsf{copula}</span> in <span class="math inline">\textsf{R}</span>. The right panel shows the results for sampling from <span class="math inline">\textbf{HuslerReiss}</span>, <span class="math inline">\textbf{Logistic}</span> and <span class="math inline">\textbf{TEV}</span> by <span class="math inline">\textsf{clayton}</span> in <span class="math inline">\textsf{Python}</span> and <span class="math inline">\textsf{mev}</span> in <span class="math inline">\textsf{R}</span>. In both cases, <span class="math inline">1000</span> vectors are generated for each model.
</figcaption>
</figure>
</div>
<p>The figure shows the results of a comparison between the <span class="math inline">\textsf{clayton}</span> and <span class="math inline">\textsf{copula}</span> packages in <span class="math inline">\textsf{R}</span>, and the <span class="math inline">\textsf{mev}</span> package in <span class="math inline">\textsf{Python}</span>. The comparison shows that the <span class="math inline">\textsf{clayton}</span> package is more efficient at sampling from <span class="math inline">\textbf{Clayton}</span>, <span class="math inline">\textbf{Frank}</span> and <span class="math inline">\textbf{Joe}</span> copulae than the <span class="math inline">\textsf{copula}</span> package. The gap in efficiency may be due to the choice of algorithms used in the <span class="math inline">\textsf{clayton}</span> package, which uses frailty distributions. The time required for sampling increases linearly with the dimension for the <span class="math inline">\textsf{clayton}</span> package, but shows a more erratic behavior for the <span class="math inline">\textsf{copula}</span> package.</p>
</section>
<section id="conclusion" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="conclusion"><span class="header-section-number">5.2</span> Conclusion</h2>
<p>This paper presents the construction and some implementations of the <span class="math inline">\textsf{Python}</span> package <span class="math inline">\textsf{clayton}</span> for random copula sampling. This is a seminal work in the field of software implementation of copula modeling in <span class="math inline">\textsf{Python}</span> and there is much more potential for growth. It is hoped that the potential diffusion of the software through those who need it may bring further implementations for multivariate modeling with copulae under <span class="math inline">\textsf{Python}</span>. For example, choosing a copula to fit the data is an important but difficult problem. A robust approach to estimating copulae has been investigated recently by <span class="citation" data-cites="alquier2020estimation">Alquier et al. (<a href="#ref-alquier2020estimation" role="doc-biblioref">2022</a>)</span> using Maximum Mean Discrepancy. In relation to our example, semiparametric estimation of copulae with missing data could be of great interest, as proposed by <span class="citation" data-cites="HAMORI201985">Hamori, Motegi, and Zhang (<a href="#ref-HAMORI201985" role="doc-biblioref">2019</a>)</span>.</p>
<p>Additionally, implementation of the algorithm proposed by <span class="citation" data-cites="10.1214/07-AOS556">McNeil and Nešlehová (<a href="#ref-10.1214/07-AOS556" role="doc-biblioref">2009</a>)</span> for generating random vectors for Archimedean copulae has been tackled, but as expected, numerical inversion gives spurious results, especially when the parameter <span class="math inline">\theta</span> and the dimension <span class="math inline">d</span> are high. Furthermore, as the support of the radial distribution is contained in the real line, numerical inversion leads to increased computational time. Further investigation is needed in order to generate random vectors from classical Archimedan models using the radial distribution.</p>
<p>A direction of improvement for the <span class="math inline">\textsf{clayton}</span> package is dependence modeling with Vine copulae, which have recently been a tool of high interest in the machine learning community (see, e.g., <span class="citation" data-cites="lopez2013gaussian">Lopez-Paz, Hernández-Lobato, and Zoubin (<a href="#ref-lopez2013gaussian" role="doc-biblioref">2013</a>)</span>, <span class="citation" data-cites="Veeramachaneni2015CopulaGM">Veeramachaneni, Cuesta-Infante, and O’Reilly (<a href="#ref-Veeramachaneni2015CopulaGM" role="doc-biblioref">2015</a>)</span>, <span class="citation" data-cites="Carrera2016VineCC">Carrera, Santana, and Lozano (<a href="#ref-Carrera2016VineCC" role="doc-biblioref">2016</a>)</span>, <span class="citation" data-cites="10.5555/2946645.2946678">Gonçalves, Von Zuben, and Banerjee (<a href="#ref-10.5555/2946645.2946678" role="doc-biblioref">2016</a>)</span> or <span class="citation" data-cites="SunCuesta-InfanteVeeramachaneni2019">Sun, Cuesta-Infante, and Veeramachaneni (<a href="#ref-SunCuesta-InfanteVeeramachaneni2019" role="doc-biblioref">2019</a>)</span>). This highlights the need for dependence modeling with copulae in <span class="math inline">\textsf{Python}</span>, as a significant part of the machine learning community uses this language. In relation to this paper, Vine copulae may be useful for modeling dependencies between extreme events, as suggested by <span class="citation" data-cites="SIMPSON2021104736">Simpson, Wadsworth, and Tawn (<a href="#ref-SIMPSON2021104736" role="doc-biblioref">2021</a>)</span>, <span class="citation" data-cites="nolde2021linking">Nolde and Wadsworth (<a href="#ref-nolde2021linking" role="doc-biblioref">2021</a>)</span>. Furthermore, other copula models could be implemented to model further dependencies. These implementations will expand the scope of dependence modeling with <span class="math inline">\textsf{Python}</span> and provide high-quality, usable tools for anyone who needs them.</p>
</section>
</section>
<section id="references" class="level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-quantrisk" class="csl-entry" role="listitem">
Alexander J. McNeil, Paul Embrechts, Rudiger Frey. 2005. <em>Quantitative Risk Management - Concepts, Techniques and Tools</em>. Princeton Series in Finance. Princeton University Press. <a href="https://libgen.li/file.php?md5=478a0059673fecd0c76229cd3d8884e7">libgen.li/file.php?md5=478a0059673fecd0c76229cd3d8884e7</a>.
</div>
<div id="ref-ALI1978405" class="csl-entry" role="listitem">
Ali, Mir M, N. N Mikhail, and M.Safiul Haq. 1978. <span>“A Class of Bivariate Distributions Including the Bivariate Logistic.”</span> <em>Journal of Multivariate Analysis</em> 8 (3): 405–12. https://doi.org/<a href="https://doi.org/10.1016/0047-259X(78)90063-5">https://doi.org/10.1016/0047-259X(78)90063-5</a>.
</div>
<div id="ref-alquier2020estimation" class="csl-entry" role="listitem">
Alquier, Pierre, Badr-Eddine Chérief-Abdellatif, Alexis Derumigny, and Jean-David Fermanian. 2022. <span>“Estimation of Copulas via Maximum Mean Discrepancy.”</span> <em>Journal of the American Statistical Association</em>, 1–16.
</div>
<div id="ref-copulasPy" class="csl-entry" role="listitem">
Alvarez, M., C. Sala, Y. Sun, J. D. Pérez, K. A. Zhang, A. Montanez, G. Bonomi, K. Veeramachaneni, I. Ramírez, and F. A. Hofman. 2021. <span>“Copulas.”</span> <em>GitHub Repository</em>. <a href="https://github.com/sdv-dev/Copulas" class="uri">https://github.com/sdv-dev/Copulas</a>; GitHub.
</div>
<div id="ref-BADOR201517" class="csl-entry" role="listitem">
Bador, Margot, Philippe Naveau, Eric Gilleland, Mercè Castellà, and Tatiana Arivelo. 2015. <span>“Spatial Clustering of Summer Temperature Maxima from the <span>CNRM-CM5</span> Climate Model Ensembles &amp; <span>E-OBS</span> over <span>Europe</span>.”</span> <em>Weather and Climate Extremes</em> 9: 17–24. https://doi.org/<a href="https://doi.org/10.1016/j.wace.2015.05.003">https://doi.org/10.1016/j.wace.2015.05.003</a>.
</div>
<div id="ref-baudin2017openturns" class="csl-entry" role="listitem">
Baudin, Michaël, Anne Dutfoy, Bertrand Iooss, and Anne-Laure Popelin. 2017. <span>“Openturns: An Industrial Software for Uncertainty Quantification in Simulation.”</span> In <em>Handbook of Uncertainty Quantification</em>, 2001–38. Springer.
</div>
<div id="ref-mevR" class="csl-entry" role="listitem">
Belzile, Leo et al. 2022. <em><span class="nocase">mev</span>: Modelling Extreme Values</em>. <a href="https://CRAN.R-project.org/package=mev">https://CRAN.R-project.org/package=mev</a>.
</div>
<div id="ref-bernard:hal-03207469" class="csl-entry" role="listitem">
Bernard, Elsa, Philippe Naveau, Mathieu Vrac, and Olivier Mestre. 2013. <span>“<span class="nocase">Clustering of Maxima: Spatial Dependencies among Heavy Rainfall in France</span>.”</span> <em><span>Journal of Climate</span></em> 26 (20): 7929–37. <a href="https://doi.org/10.1175/JCLI-D-12-00836.1">https://doi.org/10.1175/JCLI-D-12-00836.1</a>.
</div>
<div id="ref-copulaePy" class="csl-entry" role="listitem">
Bock, Daniel, and Jacob Chapman. 2021. <span>“Copulae.”</span> <em>GitHub Repository</em>. <a href="https://github.com/DanielBok/copulae" class="uri">https://github.com/DanielBok/copulae</a>; GitHub.
</div>
<div id="ref-chauvet2015" class="csl-entry" role="listitem">
Boistard, Helene, Guillaume Chauvet, and David Haziza. 2016. <span>“Doubly Robust Inference for the Distribution Function in the Presence of Missing Survey Data.”</span> <em>Scandinavian Journal of Statistics</em> 43 (3): 683–99. https://doi.org/<a href="https://doi.org/10.1111/sjos.12198">https://doi.org/10.1111/sjos.12198</a>.
</div>
<div id="ref-boulin2021non" class="csl-entry" role="listitem">
Boulin, Alexis, Elena Di Bernardino, Thomas Laloë, and Gwladys Toulemonde. 2022. <span>“Non-Parametric Estimator of a Multivariate Madogram for Missing-Data and Extreme Value Framework.”</span> <em>Journal of Multivariate Analysis</em> 192: 105059.
</div>
<div id="ref-bucher2011new" class="csl-entry" role="listitem">
Bücher, Axel, Holger Dette, and Stanislav Volgushev. 2011. <span>“New Estimators of the Pickands Dependence Function and a Test for Extreme-Value Dependence.”</span> <em>The Annals of Statistics</em> 39 (4): 1963–2006.
</div>
<div id="ref-Carrera2016VineCC" class="csl-entry" role="listitem">
Carrera, Diana, Roberto Santana, and José Antonio Lozano. 2016. <span>“Vine Copula Classifiers for the Mind Reading Problem.”</span> <em>Progress in Artificial Intelligence</em> 5: 289–305.
</div>
<div id="ref-10.2307/2335289" class="csl-entry" role="listitem">
Clayton, D. G. 1978. <span>“A Model for Association in Bivariate Life Tables and Its Application in Epidemiological Studies of Familial Tendency in Chronic Disease Incidence.”</span> <em>Biometrika</em> 65 (1): 141–51. <a href="http://www.jstor.org/stable/2335289">http://www.jstor.org/stable/2335289</a>.
</div>
<div id="ref-Demarta_Mcneil" class="csl-entry" role="listitem">
Demarta, Stefano, and Alexander J. McNeil. 2005. <span>“The t <span>Copula</span> and <span>Related</span> <span>Copulas</span>.”</span> <em>International Statistical Review</em> 73 (1): 111–29. https://doi.org/<a href="https://doi.org/10.1111/j.1751-5823.2005.tb00254.x">https://doi.org/10.1111/j.1751-5823.2005.tb00254.x</a>.
</div>
<div id="ref-10.1093/biomet/asw008" class="csl-entry" role="listitem">
Dombry, Clément, Sebastian Engelke, and Marco Oesting. 2016. <span>“<span class="nocase">Exact simulation of max-stable processes</span>.”</span> <em>Biometrika</em> 103 (2): 303–17. <a href="https://doi.org/10.1093/biomet/asw008">https://doi.org/10.1093/biomet/asw008</a>.
</div>
<div id="ref-10.2307/25463423" class="csl-entry" role="listitem">
Einmahl, John H. J., and Tao Lin. 2006. <span>“Asymptotic Normality of Extreme Value Estimators on <span class="math inline">\mathcal{C}([0, 1])</span>.”</span> <em>The Annals of Statistics</em> 34 (1): 469–92. <a href="http://www.jstor.org/stable/25463423">http://www.jstor.org/stable/25463423</a>.
</div>
<div id="ref-10.1214/21-AOS2050" class="csl-entry" role="listitem">
Einmahl, John H. J., and Johan Segers. 2021. <span>“<span class="nocase">Empirical tail copulas for functional data</span>.”</span> <em>The Annals of Statistics</em> 49 (5): 2672–96. <a href="https://doi.org/10.1214/21-AOS2050">https://doi.org/10.1214/21-AOS2050</a>.
</div>
<div id="ref-10.2307/3318798" class="csl-entry" role="listitem">
Fermanian, Jean-David, Dragan Radulović, and Marten Wegkamp. 2004. <span>“Weak Convergence of Empirical Copula Processes.”</span> <em>Bernoulli</em> 10 (5): 847–60. <a href="https://doi.org/10.3150/bj/1099579158">https://doi.org/10.3150/bj/1099579158</a>.
</div>
<div id="ref-Frank1979" class="csl-entry" role="listitem">
Frank, M. J. 1979. <span>“On the Simultaneous Associativity of f(x, y) and x + y - f(x, y).”</span> <em>Aequationes Mathematicae</em> 19: 194–226. <a href="http://eudml.org/doc/136825">http://eudml.org/doc/136825</a>.
</div>
<div id="ref-frees1998understanding" class="csl-entry" role="listitem">
Frees, Edward W, and Emiliano A Valdez. 1998. <span>“Understanding Relationships Using Copulas.”</span> <em>North American Actuarial Journal</em> 2 (1): 1–25.
</div>
<div id="ref-alma991005826659705596" class="csl-entry" role="listitem">
Gaetan, Carlo, and Xavier Guyon. 2008. <em>Modélisation Et Statistique Spatiales</em>. Mathématiques &amp; Applications. Berlin Heidelberg New York: Springer.
</div>
<div id="ref-10.2307/2337532" class="csl-entry" role="listitem">
Genest, C., K. Ghoudi, and L.-P. Rivest. 1995. <span>“A Semiparametric Estimation Procedure of Dependence Parameters in Multivariate Families of Distributions.”</span> <em>Biometrika</em> 82 (3): 543–52. <a href="http://www.jstor.org/stable/2337532">http://www.jstor.org/stable/2337532</a>.
</div>
<div id="ref-10.2307/24586878" class="csl-entry" role="listitem">
Gijbels, Irène, Marek Omelka, and Noël Veraverbeke. 2015. <span>“Estimation of a Copula When a Covariate Affects Only Marginal Distributions.”</span> <em>Scandinavian Journal of Statistics</em> 42 (4): 1109–26. <a href="http://www.jstor.org/stable/24586878">http://www.jstor.org/stable/24586878</a>.
</div>
<div id="ref-10.5555/2946645.2946678" class="csl-entry" role="listitem">
Gonçalves, André R., Fernando J. Von Zuben, and Arindam Banerjee. 2016. <span>“Multi-Task Sparse Structure Learning with Gaussian Copula Models.”</span> <em>J. Mach. Learn. Res.</em> 17 (1): 1205–34.
</div>
<div id="ref-gudendorf2009extremevalue" class="csl-entry" role="listitem">
Gudendorf, Gordon, and Johan Segers. 2010. <span>“Extreme-Value Copulas.”</span> In <em>Copula Theory and Its Applications</em>, 198:127–45. Lect. Notes Stat. Proc. Springer, Heidelberg. <a href="https://doi.org/10.1007/978-3-642-12465-5\_6">https://doi.org/10.1007/978-3-642-12465-5\_6</a>.
</div>
<div id="ref-GUDENDORF20123073" class="csl-entry" role="listitem">
———. 2012. <span>“Nonparametric Estimation of Multivariate Extreme-Value Copulas.”</span> <em>Journal of Statistical Planning and Inference</em> 142 (12): 3073–85. https://doi.org/<a href="https://doi.org/10.1016/j.jspi.2012.05.007">https://doi.org/10.1016/j.jspi.2012.05.007</a>.
</div>
<div id="ref-1960" class="csl-entry" role="listitem">
Gumbel, E. J. 1960. <span>“Distributions de Valeurs Extrêmes En Plusieurs Dimensions.”</span> <em>Publications de l’institut de Statistique de l’Université de Paris</em> 9: 171–73.
</div>
<div id="ref-HAMORI201985" class="csl-entry" role="listitem">
Hamori, Shigeyuki, Kaiji Motegi, and Zheng Zhang. 2019. <span>“Calibration Estimation of Semiparametric Copula Models with Data Missing at Random.”</span> <em>Journal of Multivariate Analysis</em> 173: 85–109. https://doi.org/<a href="https://doi.org/10.1016/j.jmva.2019.02.003">https://doi.org/10.1016/j.jmva.2019.02.003</a>.
</div>
<div id="ref-harris2020array" class="csl-entry" role="listitem">
Harris, Charles R, K Jarrod Millman, Stéfan J Van Der Walt, Ralf Gommers, Pauli Virtanen, David Cournapeau, Eric Wieser, et al. 2020. <span>“Array Programming with NumPy.”</span> <em>Nature</em> 585 (7825): 357–62.
</div>
<div id="ref-hofert2012likelihood" class="csl-entry" role="listitem">
Hofert, Marius, Martin Mächler, and Alexander J McNeil. 2012. <span>“Likelihood Inference for Archimedean Copulas in High Dimensions Under Known Margins.”</span> <em>Journal of Multivariate Analysis</em> 110: 133–50.
</div>
<div id="ref-HUSLER1989283" class="csl-entry" role="listitem">
Hüsler, Jürg, and Rolf-Dieter Reiss. 1989. <span>“Maxima of Normal Random Vectors: Between Independence and Complete Dependence.”</span> <em>Statistics &amp; Probability Letters</em> 7 (4): 283–86. https://doi.org/<a href="https://doi.org/10.1016/0167-7152(89)90106-5">https://doi.org/10.1016/0167-7152(89)90106-5</a>.
</div>
<div id="ref-Joe1990FamiliesOM" class="csl-entry" role="listitem">
Joe, H. 1990. <span>“Families of Min-Stable Multivariate Exponential and Multivariate Extreme Value Distributions.”</span> <em>Statistics &amp; Probability Letters</em> 9: 75–81.
</div>
<div id="ref-joe1997multivariate" class="csl-entry" role="listitem">
———. 1997. <em>Multivariate Models and Multivariate Dependence Concepts</em>. Chapman &amp; Hall/CRC Monographs on Statistics &amp; Applied Probability. Taylor &amp; Francis. <a href="https://books.google.fr/books?id=iJbRZL2QzMAC">https://books.google.fr/books?id=iJbRZL2QzMAC</a>.
</div>
<div id="ref-copulaR" class="csl-entry" role="listitem">
Jun Yan. 2007. <span>“Enjoy the Joy of Copulas: With a Package <span class="nocase">copula</span>.”</span> <em>Journal of Statistical Software</em> 21 (4): 1–21. <a href="https://www.jstatsoft.org/v21/i04/">https://www.jstatsoft.org/v21/i04/</a>.
</div>
<div id="ref-kojadinovic2010modeling" class="csl-entry" role="listitem">
Kojadinovic, Ivan, and Jun Yan. 2010. <span>“Modeling Multivariate Distributions with Continuous Margins Using the Copula r Package.”</span> <em>Journal of Statistical Software</em> 34: 1–20.
</div>
<div id="ref-lopez2013gaussian" class="csl-entry" role="listitem">
Lopez-Paz, David, Jose Miguel Hernández-Lobato, and Ghahramani Zoubin. 2013. <span>“Gaussian Process Vine Copulas for Multivariate Dependence.”</span> In <em>International Conference on Machine Learning</em>, 10–18. PMLR.
</div>
<div id="ref-MARCON20171" class="csl-entry" role="listitem">
Marcon, G., S. A. Padoan, P. Naveau, P. Muliere, and J. Segers. 2017. <span>“Multivariate Nonparametric Estimation of the Pickands Dependence Function Using Bernstein Polynomials.”</span> <em>Journal of Statistical Planning and Inference</em> 183: 1–17. https://doi.org/<a href="https://doi.org/10.1016/j.jspi.2016.10.004">https://doi.org/10.1016/j.jspi.2016.10.004</a>.
</div>
<div id="ref-10.2307/2289314" class="csl-entry" role="listitem">
Marshall, Albert W., and Ingram Olkin. 1988. <span>“Families of Multivariate Distributions.”</span> <em>Journal of the American Statistical Association</em> 83 (403): 834–41. <a href="http://www.jstor.org/stable/2289314">http://www.jstor.org/stable/2289314</a>.
</div>
<div id="ref-10.1214/07-AOS556" class="csl-entry" role="listitem">
McNeil, Alexander J., and Johanna Nešlehová. 2009. <span>“<span class="nocase">Multivariate Archimedean copulas, d-monotone functions and l1-norm symmetric distributions</span>.”</span> <em>The Annals of Statistics</em> 37 (5B): 3059–97. <a href="https://doi.org/10.1214/07-AOS556">https://doi.org/10.1214/07-AOS556</a>.
</div>
<div id="ref-MISHRA2011157" class="csl-entry" role="listitem">
Mishra, Ashok K., and Vijay P. Singh. 2011. <span>“Drought Modeling – a Review.”</span> <em>Journal of Hydrology</em> 403 (1): 157–75. https://doi.org/<a href="https://doi.org/10.1016/j.jhydrol.2011.03.049">https://doi.org/10.1016/j.jhydrol.2011.03.049</a>.
</div>
<div id="ref-naveau:hal-00312758" class="csl-entry" role="listitem">
Naveau, Philippe, Armelle Guillou, Daniel Cooley, and Jean Diebolt. 2009. <span>“Modelling Pairwise Dependence of Maxima in Space.”</span> <em>Biometrika</em> 96 (1): 1–17. <a href="https://doi.org/10.1093/biomet/asp001">https://doi.org/10.1093/biomet/asp001</a>.
</div>
<div id="ref-nelsen2007introduction" class="csl-entry" role="listitem">
Nelsen, Roger B. 2007. <em>An Introduction to Copulas</em>. Springer Science &amp; Business Media.
</div>
<div id="ref-nicolas2022pycop" class="csl-entry" role="listitem">
Nicolas, Maxime LD. 2022. <span>“Pycop: A Python Package for Dependence Modeling with Copulas.”</span> <em>Zenodo Software Package</em> 70: 7030034.
</div>
<div id="ref-nolde2021linking" class="csl-entry" role="listitem">
Nolde, Natalia, and Jennifer L. Wadsworth. 2021. <span>“Linking Representations for Multivariate Extremes via a Limit Set.”</span> <a href="https://arxiv.org/abs/2012.00990">https://arxiv.org/abs/2012.00990</a>.
</div>
<div id="ref-patton2012review" class="csl-entry" role="listitem">
Patton, Andrew J. 2012. <span>“A Review of Copula Models for Economic Time Series.”</span> <em>Journal of Multivariate Analysis</em> 110: 4–18.
</div>
<div id="ref-PORTIER2018160" class="csl-entry" role="listitem">
Portier, François, and Johan Segers. 2018. <span>“On the Weak Convergence of the Empirical Conditional Copula Under a Simplifying Assumption.”</span> <em>Journal of Multivariate Analysis</em> 166: 160–81. https://doi.org/<a href="https://doi.org/10.1016/j.jmva.2018.03.002">https://doi.org/10.1016/j.jmva.2018.03.002</a>.
</div>
<div id="ref-saunders" class="csl-entry" role="listitem">
Saunders, K., A. Stephenson, and David Karoly. 2021. <span>“A Regionalisation Approach for Rainfall Based on Extremal Dependence.”</span> <em>Extremes</em> 24 (June). <a href="https://doi.org/10.1007/s10687-020-00395-y">https://doi.org/10.1007/s10687-020-00395-y</a>.
</div>
<div id="ref-VineCopulaR" class="csl-entry" role="listitem">
Schepsmeier, U., J. Stoeber, E. C. Brechmann, B. Graeler, T. Nagler, T. Erhardt, C. Almeida, et al. 2019. <span>“VineCopula : Statistical Inference of Vine Copulas.”</span> <em>Package "VineCopula". R Package, Version 2.3.0</em>. <a href="https://cran.r-project.org/web/packages/VineCopula/index.html">https://cran.r-project.org/web/packages/VineCopula/index.html</a>.
</div>
<div id="ref-SIMPSON2021104736" class="csl-entry" role="listitem">
Simpson, Emma S., Jennifer L. Wadsworth, and Jonathan A. Tawn. 2021. <span>“A Geometric Investigation into the Tail Dependence of Vine Copulas.”</span> <em>Journal of Multivariate Analysis</em> 184: 104736. https://doi.org/<a href="https://doi.org/10.1016/j.jmva.2021.104736">https://doi.org/10.1016/j.jmva.2021.104736</a>.
</div>
<div id="ref-Skla59" class="csl-entry" role="listitem">
Sklar, Abe. 1959. <span>“Fonctions de Répartition à n Dimensions Et Leurs Marges.”</span> <em>Publications de l’Institut de Statistique de l’Université de Paris</em> 8: 229–31.
</div>
<div id="ref-Smith1990" class="csl-entry" role="listitem">
Smith, R. L. 1990. <em>Extreme Value Theory</em>. Handbook of Applicable Mathematics (ed. W. Ledermann), vol. 7. Chichester: John Wiley, pp. 437–471.
</div>
<div id="ref-evdR" class="csl-entry" role="listitem">
Stephenson, A. G. 2002. <span>“<span class="nocase">evd</span>: <span>Extreme</span> <span>Value</span> <span>Distributions</span>.”</span> <em>R News</em> 2 (2). <a href="https://CRAN.R-project.org/doc/Rnews/">https://CRAN.R-project.org/doc/Rnews/</a>.
</div>
<div id="ref-stephenson2003simulating" class="csl-entry" role="listitem">
Stephenson, Alec. 2003. <span>“Simulating Multivariate Extreme Value Distributions of Logistic Type.”</span> <em>Extremes</em> 6 (1): 49–59.
</div>
<div id="ref-SunCuesta-InfanteVeeramachaneni2019" class="csl-entry" role="listitem">
Sun, Yi, Alfredo Cuesta-Infante, and Kalyan Veeramachaneni. 2019. <span>“Learning Vine Copula Models for Synthetic Data Generation.”</span> <em>Proceedings of the AAAI Conference on Artificial Intelligence</em> 33 (01): 5049–57. <a href="https://doi.org/10.1609/aaai.v33i01.33015049">https://doi.org/10.1609/aaai.v33i01.33015049</a>.
</div>
<div id="ref-10.1093/biomet/75.3.397" class="csl-entry" role="listitem">
Tawn, Jonathan A. 1988. <span>“<span class="nocase">Bivariate extreme value theory: Models and estimation</span>.”</span> <em>Biometrika</em> 75 (3): 397–415. <a href="https://doi.org/10.1093/biomet/75.3.397">https://doi.org/10.1093/biomet/75.3.397</a>.
</div>
<div id="ref-tawn1990" class="csl-entry" role="listitem">
———. 1990. <span>“Modelling Multivariate Extreme Value Distributions.”</span> <em>Biometrika</em> 77 (2): 245–53. <a href="http://www.jstor.org/stable/2336802">http://www.jstor.org/stable/2336802</a>.
</div>
<div id="ref-Veeramachaneni2015CopulaGM" class="csl-entry" role="listitem">
Veeramachaneni, Kalyan, Alfredo Cuesta-Infante, and Una-May O’Reilly. 2015. <span>“Copula Graphical Models for Wind Resource Estimation.”</span> In <em>IJCAI</em>.
</div>
<div id="ref-virtanen2020scipy" class="csl-entry" role="listitem">
Virtanen, Pauli, Ralf Gommers, Travis E Oliphant, Matt Haberland, Tyler Reddy, David Cournapeau, Evgeni Burovski, et al. 2020. <span>“SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python.”</span> <em>Nature Methods</em> 17 (3): 261–72.
</div>
<div id="ref-woolridge2007" class="csl-entry" role="listitem">
Wooldridge, Jeffrey M. 2007. <span>“Inverse Probability Weighted Estimation for General Missing Data Problems.”</span> <em>Journal of Econometrics</em> 141 (2): 1281–301. https://doi.org/<a href="https://doi.org/10.1016/j.jeconom.2007.02.002">https://doi.org/10.1016/j.jeconom.2007.02.002</a>.
</div>
</div>
</section>
<section id="appendices" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> Appendix</h1>
<section id="sec-bv_arch" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="sec-bv_arch"><span class="header-section-number">6.1</span> Bivariate Archimedean models</h2>
<div class="&nbsp;{#fig-bv_arch-1}">
<p><img src="figures/app/arch_table_1.png" class="img-fluid" style="width:100.0%"></p>
</div>
<div class="&nbsp;{#fig-bv_arch-2}">
<p><img src="figures/app/arch_table_2.png" class="img-fluid" style="width:100.0%"></p>
</div>
</section>
<section id="sec-bv_ext" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="sec-bv_ext"><span class="header-section-number">6.2</span> Implemented bivariate extreme models</h2>
<div class="&nbsp;{#fig-bv-ext}">
<p><img src="figures/app/ext_table.png" class="img-fluid" style="width:100.0%"></p>
</div>
</section>
<section id="sec-mv_arch" class="level2" data-number="6.3">
<h2 data-number="6.3" class="anchored" data-anchor-id="sec-mv_arch"><span class="header-section-number">6.3</span> Multivariate Archimedean copulae</h2>
<div class="&nbsp;{#fig-mv-arch}">
<p><img src="figures/app/arch_mv_table.png" class="img-fluid" style="width:100.0%"></p>
</div>
</section>
<section id="sec-mv_ext" class="level2" data-number="6.4">
<h2 data-number="6.4" class="anchored" data-anchor-id="sec-mv_ext"><span class="header-section-number">6.4</span> Multivariate extreme models</h2>
<p>Before giving the main details, we introduce some notations. Let <span class="math inline">B</span> be the set of all nonempty subsets of <span class="math inline">\{1,\dots,d\}</span> and <span class="math inline">B_1 = \{b \in B, |b| = 1\}</span>, where <span class="math inline">|b|</span> denotes the number of elements in thet set <span class="math inline">b</span>. We note by <span class="math inline">B_{(j)} = \{b \in B, j \in b\}</span>. For <span class="math inline">d=3</span>, the Pickands is expressed as</p>
<div id="eq-mv_ext">
<p><span class="math display">\begin{align*}
A(\textbf{w}) =&amp; \alpha_1 w_1 + \psi_1 w_2 + \phi_1 w_3 + \left( (\alpha_2 w_1)^{\theta_1} + (\psi_2w_2)^{\theta_1} \right)^{1/\theta_1} + \left( (\alpha_3 w_2)^{\theta_2} + (\phi_2w_3)^{\theta_2} \right)^{1/\theta_2} \\ &amp;+ \left( (\psi_3 w_2)^{\theta_3} + (\phi_3w_3)^{\theta_3} \right)^{1/\theta_3}
  + \left( (\alpha_4 w_1)^{\theta_4} + (\psi_4 w_2)^{\theta_4} + (\phi_4 w_3)^{\theta_4} \right)^{1/\theta_4},
\end{align*}</span></p>
</div>
<p>where <span class="math inline">\boldsymbol{\alpha} = (\alpha_1, \dots, \alpha_4), \boldsymbol{\psi} = (\psi_1, \dots, \psi_4), \boldsymbol{\phi} = (\phi_1, \dots, \phi_4)</span> are all elements of <span class="math inline">\Delta^3</span>. We take <span class="math inline">\boldsymbol{\alpha} = (0.4,0.3,0.1,0.2)</span>, <span class="math inline">\boldsymbol{\psi} = (0.1, 0.2, 0.4, 0.3)</span>, <span class="math inline">\boldsymbol{\phi} = (0.6,0.1,0.1,0.2)</span> and <span class="math inline">\boldsymbol{\theta} = (\theta_1, \dots, \theta_4) = (0.6,0.5,0.8,0.3)</span> as the dependence parameter.</p>
<p>The Dirichlet model is a mixture of <span class="math inline">m</span> Dirichlet densities, that is <span class="math display">
    h(\textbf{w}) = \sum_{k=1}^m \theta_k \frac{\Gamma(\sum_{j=1}^d \sigma_{kj})}{\Pi_{j=1}^d \Gamma(\sigma_{kj})} \Pi_{j=1}^d w_j^{\sigma_{kj}-1},
</span> with <span class="math inline">\sum_{k=1}^m \theta_k = 1</span>, <span class="math inline">\sigma_{kj} &gt; 0</span> for <span class="math inline">k \in \{1,\dots,m\}</span> and <span class="math inline">j \in \{1, \dots, d\}</span>. Let <span class="math inline">\mathcal{D} \in [0, \infty)^{(d-1)\times (d-1)}</span> denotes the space of symmetric strictly conditionnaly negative definite matrices that is</p>
<div id="striclty_cond_neg">
<p><span class="math display">\begin{align*}
            \mathcal{D}_{k} = \Big\{ \Gamma \in [0,\infty)^{k \times k} : a^\top \Gamma a &lt; 0 \; \textrm{for all } a \in \mathbb{R}^{k} \setminus \{\textbf{0}\}  \, \textrm{with } \sum_{j=1}^{d-1} a_j = 0, \\ \Gamma_{ii} = 0, \Gamma_{ij} = \Gamma_{ji}, \quad 1 \leq i,j\leq k \Big\}.
        \end{align*}</span></p>
</div>
<p>For any <span class="math inline">2 \leq k \leq d</span>, consider <span class="math inline">m' = (m_1, \dots, m_k)</span> with <span class="math inline">1 \leq m_1 &lt;  \dots &lt; m_k \leq d</span> define <span class="math display">
    \Sigma^{(k)}_m = 2 \left( \Gamma_{m_i m_k} + \Gamma_{m_j m_k} - \Gamma_{m_i m_j} \right)_{m_i m_j \neq m_k} \in [0,\infty)^{(d-1)\times(d-1)}.
</span> Furthermore, note <span class="math inline">S(\cdot | \Sigma^{(k)}_m)</span> denote the survival function of a normal random vector with mean vector <span class="math inline">\textbf{0}</span> and covariance matrix <span class="math inline">\Sigma^{(k)}</span>. We now define : <span class="math display">
    h_{km}(\textbf{y}) = \int_{y_k}^\infty S\left( (y_i - z + 2\Gamma_{m_i m_k})_{i=1}^{k-1} | \Gamma_{km}\right) e^{-z}dz
</span> for <span class="math inline">2 \leq k \leq d</span>. We denote by <span class="math inline">\Sigma^{(k)}</span> the summation over all <span class="math inline">k</span>-vectors <span class="math inline">m=(m_1,\dots,m_k)</span> with <span class="math inline">1\leq m_1 &lt; \dots &lt; m_k \leq d</span>.</p>
<div class="&nbsp;{#fig-mv_ext}">
<p><img src="figures/app/ext_mv_table.png" class="img-fluid" style="width:100.0%"></p>
</div>
</section>
<section id="sec-mv_ellip" class="level2" data-number="6.5">
<h2 data-number="6.5" class="anchored" data-anchor-id="sec-mv_ellip"><span class="header-section-number">6.5</span> Multivariate elliptical dependencies</h2>
<p>Let <span class="math inline">\textbf{X} \sim \textbf{E}_d(\boldsymbol{\mu}, \Sigma, \psi)</span> be an elliptical distributed random vector with cumulative distribution <span class="math inline">F</span> and marginal <span class="math inline">F_0, \dots, F_{d-1}</span>. Then, the copula <span class="math inline">C</span> of <span class="math inline">F</span> is called an elliptical copula. We denote by <span class="math inline">\phi</span> the standard normal distribution function and <span class="math inline">\boldsymbol{\phi}_\Sigma</span> the joint distribution function of <span class="math inline">\textbf{X} \sim \mathcal{N}_d(\textbf{0}, \Sigma)</span>, where <span class="math inline">\textbf{0}</span> is the <span class="math inline">d</span>-dimensional vector composed out of <span class="math inline">0</span>. In the same way, we note <span class="math inline">t_{\theta}</span> the distribution function of a standard univariate distribution <span class="math inline">t</span> distribution and by <span class="math inline">\boldsymbol{t}_{\theta, \Sigma}</span> the joint distribution function of the vector <span class="math inline">\textbf{X} \sim \boldsymbol{t}_{d}(\theta, \textbf{0}, \Sigma)</span>. A <span class="math inline">d</span> squared matrix <span class="math inline">\Sigma</span> is said to be positively semi definite if for all <span class="math inline">u \in \mathbb{R}^d</span> we have :</p>
<p><span class="math display">
  u^\top \Sigma u \geq 0
</span></p>
<div class="&nbsp;{#fig-mv_elli}">
<p><img src="figures/app/elli_table.png" class="img-fluid" style="width:100.0%"></p>
</div>
<!-- -->

</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a></div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@article{boulin2023,
  author = {Boulin, Alexis},
  publisher = {French Statistical Society},
  title = {A {Python} {Package} for {Sampling} from {Copulae:} Clayton},
  journal = {Computo},
  date = {2023-01-12},
  url = {https://computo.sfds.asso.fr/published-202301-boulin-clayton/},
  doi = {10.57750/4szh-t752},
  issn = {2824-7795},
  langid = {en},
  abstract = {The package \$\textbackslash textsf\{clayton\}\$ is
    designed to be intuitive, user-friendly, and efficient. It offers a
    wide range of copula models, including Archimedean, Elliptical, and
    Extreme. The package is implemented in pure \$\textbackslash
    textsf\{Python\}\$, making it easy to install and use. In addition,
    we provide detailed documentation and examples to help users get
    started quickly. We also conduct a performance comparison with
    existing \$\textbackslash textsf\{R\}\$ packages, demonstrating the
    efficiency of our implementation. The \$\textbackslash
    textsf\{clayton\}\$ package is a valuable tool for researchers and
    practitioners working with copulae in \$\textbackslash
    textsf\{Python\}\$.}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-boulin2023" class="csl-entry quarto-appendix-citeas" role="listitem">
Boulin, Alexis. 2023. <span>“A Python Package for Sampling from Copulae:
Clayton.”</span> <em>Computo</em>, January. <a href="https://doi.org/10.57750/4szh-t752">https://doi.org/10.57750/4szh-t752</a>.
</div></div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb18" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "A Python Package for Sampling from Copulae: clayton"</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle:</span><span class="co"> "A Python Package for Sampling from Copulae: clayton"</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="co">  - name: Alexis Boulin</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="co">    url: https://aleboul.github.io/</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="co">    corresponding: true</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co">    email: aboulin@unice.fr</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="co">    affiliations:</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="co">      - name: Université Côte d'Azur, CNRS, LJAD, France</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="co">        url: https://univ-cotedazur.fr/</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="co">      - name: Inria, Lemon</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="co">        url: https://www.inria.fr/fr/lemon</span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> 2023-01-12</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a><span class="an">date-modified:</span><span class="co"> last-modified</span></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> |</span></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a><span class="co">  The package $\textsf{clayton}$ is designed to be intuitive, user-friendly, and efficient. It offers a wide range of copula models, including Archimedean, Elliptical, and Extreme. The package is implemented in pure $\textsf{Python}$, making it easy to install and use.</span></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a><span class="an">abstract:</span><span class="co"> &gt;+</span></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a><span class="co">  The package $\textsf{clayton}$ is designed to be intuitive, user-friendly, and efficient. It offers a wide range of copula models, including Archimedean, Elliptical, and Extreme. The package is implemented in pure $\textsf{Python}$, making it easy to install and use. In addition, we provide detailed documentation and examples to help users get started quickly. We also conduct a performance comparison with existing $\textsf{R}$ packages, demonstrating the efficiency of our implementation. The $\textsf{clayton}$ package is a valuable tool for researchers and practitioners working with copulae in $\textsf{Python}$.</span></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a><span class="an">keywords:</span><span class="co"> [Copulae, Random number generation]</span></span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a><span class="an">citation:</span></span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a><span class="co">  type: article-journal</span></span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a><span class="co">  container-title: "Computo"</span></span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a><span class="co">  doi: "10.57750/4szh-t752"</span></span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a><span class="co">  publisher: "French Statistical Society"</span></span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a><span class="co">  issn: "2824-7795"</span></span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a><span class="co">  pdf-url: "https://computo.sfds.asso.fr/published-202301-boulin-clayton/published-202301-boulin-clayton.pdf"</span></span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a><span class="co">  url:  "https://computo.sfds.asso.fr/published-202301-boulin-clayton/"</span></span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a><span class="an">google-scholar:</span><span class="co"> true</span></span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a><span class="an">bibliography:</span><span class="co"> references.bib</span></span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a><span class="an">github-user:</span><span class="co"> computorg</span></span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a><span class="an">repo:</span><span class="co"> "published-202301-boulin-clayton"</span></span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a><span class="an">draft:</span><span class="co"> false </span></span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a><span class="an">published:</span><span class="co"> true</span></span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a><span class="co">  computo-html: default</span></span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a><span class="co">  computo-pdf: default</span></span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a><span class="fu"># Introduction</span></span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a>Modeling dependence relations between random variables is a topic of interest in probability theory and statistics. The most popular approach is based on the second moment of the underlying random variables, namely, the covariance. It is well known that only linear dependence can be captured by the covariance and it is only characteristic for a few models, e.g., the multivariate normal distribution or binary random variables. As a beneficial alternative to dependence, the concept of copulae, going back to @Skla59, has drawn a lot of attention. The copula $C: <span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>^d \rightarrow <span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>$ of a random vector $\mathbf{X} = (X_0, \dots, X_{d-1})$ with $d \geq 2$ allows us to separate the effect of dependence from the effect of the marginal distribution, such that:</span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-45"><a href="#cb18-45" aria-hidden="true" tabindex="-1"></a>    \mathbb{P}\left<span class="sc">\{</span> X_0 \leq x_0, \dots, X_{d-1} \leq x_{d-1} \right<span class="sc">\}</span> = C\left(\mathbb{P} <span class="sc">\{</span>X_0 \leq x_0<span class="sc">\}</span>, \dots, \mathbb{P}<span class="sc">\{</span>X_{d-1} \leq x_{d-1} <span class="sc">\}</span>\right),</span>
<span id="cb18-46"><a href="#cb18-46" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-47"><a href="#cb18-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-48"><a href="#cb18-48" aria-hidden="true" tabindex="-1"></a>where $(x_0, \dots, x_{d-1}) \in \mathbb{R}^d$. The main consequence of this identity is that the copula completely characterizes the stochastic dependence between the margins of $\mathbf{X}$.</span>
<span id="cb18-49"><a href="#cb18-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-50"><a href="#cb18-50" aria-hidden="true" tabindex="-1"></a>In other words, copulae allow us to model marginal distributions and dependence structure separately. Furthermore, motivated by Sklar's theorem, the problem of investigating stochastic dependence is reduced to the study of multivariate distribution functions under the unit hypercube $<span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>^d$ with uniform margins. The theory of copulae has been of prime interest for many applied fields of science, such as quantitative finance (@patton2012review) or environmental sciences (@MISHRA2011157). This increasing number of applications has led to a demand for statistical methods. For example, semiparametric estimation (@10.2307/2337532), nonparametric estimation (@10.2307/3318798) of copulae or nonparametric estimation of conditional copulae (@10.2307/24586878, @PORTIER2018160) have been investigated. These results are established for a fixed arbitrary dimension $d \geq 2$, but several investigations (e.g. @10.2307/25463423, @10.1214/21-AOS2050) are done for functional data for the tail copula, which captures dependence in the upper tail.</span>
<span id="cb18-51"><a href="#cb18-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-52"><a href="#cb18-52" aria-hidden="true" tabindex="-1"></a>Software implementation of copulae has been extensively studied in $\textsf{R}$, for example in the packages @evdR, @copulaR, @VineCopulaR. However, methods for working with copulae in $\textsf{Python}$ are still limited. As far as we know, copula-dedicated packages in $\textsf{Python}$ are mainly designed for modeling, such as @copulasPy and @copulaePy. These packages use maximum likelihood methods to estimate the copula parameters from observed data and generate synthetic data using the estimated copula model. Other packages provide sampling methods for copulae, but they are typically restricted to the bivariate case and the conditional simulation method (see, for example, @baudin2017openturns). Additionally, if the multivariate case is considered only Archimedean and elliptical copulae are under interest and those packages (see @nicolas2022pycop) do not include the extreme value class in arbitrary dimensions $d \geq 2$. In this paper, we propose to implement a wide range of copulae, including the extreme value class, in arbitrary fixed dimension $d \geq 2$.</span>
<span id="cb18-53"><a href="#cb18-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-54"><a href="#cb18-54" aria-hidden="true" tabindex="-1"></a>Through this paper we adopt the following notational conventions: all the indices will start at $0$ as in $\textsf{Python}$. Consider $(\Omega, \mathcal{A}, \mathbb{P})$ a probability space and let $\textbf{X} = (X_0, \dots, X_{d-1})$ be a $d$-dimensional random vector with values in $(\mathbb{R}^d, \mathcal{B}(\mathbb{R}^d))$, with $d \geq 2$ and $\mathcal{B}(\mathbb{R}^d)$ the Borel $\sigma$-algebra of $\mathbb{R}^d$. This random vector has a joint distribution $F$ with copula $C$ and its margins are denoted by $F_j(x) = \mathbb{P}<span class="sc">\{</span>X_j \leq x<span class="sc">\}</span>$ for all $x \in \mathbb{R}$ and $j \in <span class="sc">\{</span>0, \dots, d-1<span class="sc">\}</span>$. Denote by $\textbf{U} = (U_0, \dots, U_{d-1})$ a $d$ random vector with copula $C$ and uniform margins. All bold letters $\textbf{x}$ will denote a vector of $\mathbb{R}^d$.</span>
<span id="cb18-55"><a href="#cb18-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-56"><a href="#cb18-56" aria-hidden="true" tabindex="-1"></a>The $\textsf{clayton}$ package, whose Python code can be found in <span class="co">[</span><span class="ot">https://github.com/Aleboul/clayton</span><span class="co">](https://github.com/Aleboul/clayton)</span>, uses object-oriented features of the Python language. The package contains classes for Archimedean, elliptical, and extreme value copulae. In @sec-classes, we briefly describe the classes defined in the package. @sec-rng presents methods for generating random vectors. In @sec-pairwise, we apply the $\textsf{clayton}$ package to model pairwise dependence between maxima. @sec-discussion discusses potential improvements to the package and provides concluding remarks. Sections from @sec-bv_arch to @sec-mv_ellip define and illustrate all the parametric copula models implemented in the package.</span>
<span id="cb18-57"><a href="#cb18-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-58"><a href="#cb18-58" aria-hidden="true" tabindex="-1"></a><span class="fu"># Classes {#sec-classes}</span></span>
<span id="cb18-59"><a href="#cb18-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-60"><a href="#cb18-60" aria-hidden="true" tabindex="-1"></a>:::{#fig-diagram}</span>
<span id="cb18-61"><a href="#cb18-61" aria-hidden="true" tabindex="-1"></a><span class="al">![](figures/diagram.png)</span></span>
<span id="cb18-62"><a href="#cb18-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-63"><a href="#cb18-63" aria-hidden="true" tabindex="-1"></a>The figure shows a object diagram that structures the code. The $\textbf{Multivariate}$ class serves as the root and is used to instantiate all its child classes $\textbf{Archimedean}$, $\textbf{Extreme}$, $\textbf{Gaussian}$, and $\textbf{Student}$ in red. The blue-colored classes correspond to various parametric copula models, and the green-colored classes represent examples of methods. Symbols $\varphi, \varphi^\leftarrow, \dot{\varphi}$ correspond to the generator function, its inverse, and its derivative, respectively, while $A, \dot{A}$ refer to the Pickands dependence function and its derivative.</span>
<span id="cb18-64"><a href="#cb18-64" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-65"><a href="#cb18-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-66"><a href="#cb18-66" aria-hidden="true" tabindex="-1"></a>The architecture of the code is shown in @fig-diagram. At the third level of the architecture, we find important parametric models of Archimedean and extreme value copulae (depicted as blue in the figure). These parametric models contain methods such as the generator function $\varphi$ (see @sec-arch) for Archimedean copulae and the Pickands dependence function $A$ (see @sec-extreme) for extreme value copulae (depicted as green in the figure). We provide a brief overview of Archimedean copulae and some of their properties in high-dimensional spaces in @sec-arch. A characterization of extreme value copulae is given in @sec-extreme. The from @sec-bv_arch to @sec-mv_ellip define and illustrate all the copula models implemented in the package.</span>
<span id="cb18-67"><a href="#cb18-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-68"><a href="#cb18-68" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Archimedean class {#sec-arch}</span></span>
<span id="cb18-69"><a href="#cb18-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-70"><a href="#cb18-70" aria-hidden="true" tabindex="-1"></a>Let $\varphi$ be a generator that is a strictly decreasing, convex function from $<span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>$ to $<span class="co">[</span><span class="ot">0, \infty</span><span class="co">]</span>$ such that $\varphi(1) = 0$ and $\varphi(0) = \infty$. We denote the generalized inverse of $\varphi$ by $\varphi^\leftarrow$. Consider the following equation:</span>
<span id="cb18-71"><a href="#cb18-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-72"><a href="#cb18-72" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-73"><a href="#cb18-73" aria-hidden="true" tabindex="-1"></a>    C(\textbf{u}) = \varphi^\leftarrow (\varphi(u_0)+ \dots + \varphi(u_{d-1})).</span>
<span id="cb18-74"><a href="#cb18-74" aria-hidden="true" tabindex="-1"></a>$$ {#eq-arch_cop}</span>
<span id="cb18-75"><a href="#cb18-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-76"><a href="#cb18-76" aria-hidden="true" tabindex="-1"></a>If this relation holds and $C$ is a copula function, then $C$ is called an Archimedean copula. A necessary condition for @eq-arch_cop to be a copula is that the generator $\varphi$ is a $d$-monotonic function, i.e., it is differentiable up to the order $d$ and its derivatives satisfy</span>
<span id="cb18-77"><a href="#cb18-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-78"><a href="#cb18-78" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-79"><a href="#cb18-79" aria-hidden="true" tabindex="-1"></a>  (-1)^k \left(\varphi\right)^{(k)}(x) \geq 0, \quad k \in <span class="sc">\{</span>1, \dots, d<span class="sc">\}</span></span>
<span id="cb18-80"><a href="#cb18-80" aria-hidden="true" tabindex="-1"></a>$$ {#eq-dmono}</span>
<span id="cb18-81"><a href="#cb18-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-82"><a href="#cb18-82" aria-hidden="true" tabindex="-1"></a>for $x \in (0, \infty)$ (see Corollary 2.1 of @10.1214/07-AOS556). Note that $d$-monotonic Archimedean inverse generators do not necessarily generate Archimedean copulae in dimensions higher than $d$ (see @10.1214/07-AOS556). As a result, some Archimedean subclasses are only implemented for the bivariate case as they do not generate an Archimedean copula in higher dimensions. In the bivariate case, @eq-dmono can be interpreted as $\varphi$ being a convex function.</span>
<span id="cb18-83"><a href="#cb18-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-84"><a href="#cb18-84" aria-hidden="true" tabindex="-1"></a>The $\textsf{clayton}$ package implements common one-parameter families of Archimedean copulae, such as the Clayton (@10.2307/2335289), Gumbel (@1960), Joe (@joe1997multivariate), Frank (@Frank1979), and AMH (@ALI1978405) copulae for the multivariate case. It is worth noting that all Archimedean copulae are symmetric, and in dimensions 3 or higher, only positive associations are allowed. For the specific bivariate case, the package also implements other families, such as those numbered from 4.2.9 to 4.2.15 and 4.2.22 in Section 4.2 of @nelsen2007introduction. Definitions and illustrations of these parametric copula models can be found in @sec-bv_arch and @sec-mv_arch.</span>
<span id="cb18-85"><a href="#cb18-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-86"><a href="#cb18-86" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Extreme class {#sec-extreme}</span></span>
<span id="cb18-87"><a href="#cb18-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-88"><a href="#cb18-88" aria-hidden="true" tabindex="-1"></a>Investigating the notion of copulae within the framework of multivariate extreme value theory leads to the extreme value copulae (see @gudendorf2009extremevalue for an overview) defined as </span>
<span id="cb18-89"><a href="#cb18-89" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-90"><a href="#cb18-90" aria-hidden="true" tabindex="-1"></a>C(\textbf{u}) = \exp \left( - \ell(-\ln(u_0), \dots, -\ln(u_{d-1})) \right), \quad \textbf{u} \in (0,1]^d,</span>
<span id="cb18-91"><a href="#cb18-91" aria-hidden="true" tabindex="-1"></a>$$ {#eq-evc}</span>
<span id="cb18-92"><a href="#cb18-92" aria-hidden="true" tabindex="-1"></a>where $\ell: <span class="co">[</span><span class="ot">0,\infty)^d \rightarrow [0,\infty)$ the stable tail dependence function which is convex, homogeneous of order one, namely $\ell(c\textbf{x}) = c \ell(\textbf{x})$ for $c &gt; 0$ and satisfies $\max(x_0,\dots,x_{d-1})  \leq \ell(x_0,\dots,x_{d-1}) \leq x_0+\dots+x_{d-1}, \forall \textbf{x} \in [0,\infty)^d$. Let $\Delta^{d-1} = \{\textbf{w} \in [0,1</span><span class="co">]</span>^d: w_0 + \dots + w_{d-1} = 1<span class="sc">\}</span>$ be the unit simplex. The Pickands dependence function $A: \Delta^{d-1} \rightarrow <span class="co">[</span><span class="ot">1/d,1</span><span class="co">]</span>$ characterizes $\ell$ by its homogeneity, which is the restriction of $\ell$ to the unit simplex $\Delta^{d-1}$:</span>
<span id="cb18-93"><a href="#cb18-93" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-94"><a href="#cb18-94" aria-hidden="true" tabindex="-1"></a>  \ell(x_0, \dots,x_{d-1}) = (x_0 + \dots + x_{d-1}) A(w_0, \dots, w_{d-1}), \quad w_j = \frac{x_j}{x_0 + \dots + x_{d-1}},</span>
<span id="cb18-95"><a href="#cb18-95" aria-hidden="true" tabindex="-1"></a>$${#eq-tail_dependence_pickands}</span>
<span id="cb18-96"><a href="#cb18-96" aria-hidden="true" tabindex="-1"></a>for $j \in <span class="sc">\{</span>1,\dots,d-1<span class="sc">\}</span>$ and $w_0 = 1 - w_1 - \dots - w_{d-1}$ with $\textbf{x} \in [0, \infty)^d \setminus <span class="sc">\{</span>\textbf{0}<span class="sc">\}</span>$. The Pickands dependence function characterizes the extremal dependence structure of an extreme value random vector and verifies $\max<span class="sc">\{</span>w_0,\dots,w_{d-1}<span class="sc">\}</span> \leq A(w_0,\dots,w_{d-1}) \leq 1$ where the lower bound corresponds to comonotonicity and the upper bound corresponds to independence. Estimating this function is an active area of research, with many compelling studies having been conducted on the topic (see, for example, @bucher2011new, @GUDENDORF20123073).</span>
<span id="cb18-97"><a href="#cb18-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-98"><a href="#cb18-98" aria-hidden="true" tabindex="-1"></a>From a practical point of view, the family of extreme value copulae is very rich and arises naturally as the limiting distribution of properly normalised componentwise maxima. Furthermore, it contains a rich variety of parametric models and allows asymmetric dependence, that is, for the bivariate case:</span>
<span id="cb18-99"><a href="#cb18-99" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-100"><a href="#cb18-100" aria-hidden="true" tabindex="-1"></a>  \exists (u_0,u_1) \in <span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>^2, \quad C(u_0,u_1) \neq C(u_1,u_0).</span>
<span id="cb18-101"><a href="#cb18-101" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-102"><a href="#cb18-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-103"><a href="#cb18-103" aria-hidden="true" tabindex="-1"></a>In the multivariate framework, the logistic copula (or Gumbel, see @1960), the asymmetric logistic copula (@tawn1990), the Hüsler and Reiss distribution (@HUSLER1989283), the t-EV copula (@Demarta_Mcneil), Bilogistic model (@Smith1990) are implemented. It's worth noting that the logistic copula is the sole model that is both Archimedean and extreme value. The library includes bivariate extreme value copulae such as asymmetric negative logistic (@Joe1990FamiliesOM), asymmetric mixed (@10.1093/biomet/75.3.397). The reader is again invited to read from @sec-bv_ext to @sec-mv_ext for precise definitions of these models.</span>
<span id="cb18-104"><a href="#cb18-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-105"><a href="#cb18-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-106"><a href="#cb18-106" aria-hidden="true" tabindex="-1"></a><span class="fu"># Random number generator {#sec-rng}</span></span>
<span id="cb18-107"><a href="#cb18-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-108"><a href="#cb18-108" aria-hidden="true" tabindex="-1"></a>We propose a $\textsf{Python}$-based implementation for generating random numbers from a wide variety of copulae. The $\textsf{clayton}$ package requires a few external libraries that are commonly used in scientific computing in $\textsf{Python}$.</span>
<span id="cb18-109"><a href="#cb18-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-110"><a href="#cb18-110" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`numpy`</span> version 1.6.1 or newer. This is the fundamental package for scientific computing, it contains linear algebra functions and matrix / vector objects (@harris2020array).</span>
<span id="cb18-111"><a href="#cb18-111" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`scipy`</span> version 1.7.1 or newer. A library of open-source software for mathematics, science and engineering (@virtanen2020scipy).</span>
<span id="cb18-112"><a href="#cb18-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-113"><a href="#cb18-113" aria-hidden="true" tabindex="-1"></a>The $\textsf{clayton}$ package provides two methods for generating random vectors: $\texttt{sample<span class="sc">\_</span>unimargin}$ and $\texttt{sample}$. The first method generates a sample where the margins are uniformly distributed on the unit interval $<span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>$, while the second method generates a sample from the chosen margins.</span>
<span id="cb18-114"><a href="#cb18-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-115"><a href="#cb18-115" aria-hidden="true" tabindex="-1"></a>In @sec-biv_case, we present an algorithm that uses the conditioning method to sample from a copula. This method is very general and can be used for any copula that is sufficiently smooth (see @eq-cond_sim and @eq-cond_dist_mv below). However, the practical infeasibility of the algorithm in dimensions higher than $2$ and the computational intensity of numerical inversion call for more efficient ways to sample in higher dimensions. The purpose of @sec-mv_case is to present such methods and to provide details on the methods used in the $\textsf{clayton}$ package. In each section, we provide examples of code to illustrate how to instantiate a copula and how to sample with $\textsf{clayton}$.</span>
<span id="cb18-116"><a href="#cb18-116" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-117"><a href="#cb18-117" aria-hidden="true" tabindex="-1"></a>In the following sections, we will use $\textsf{Python}$ code that assumes that the following packages have been loaded:</span>
<span id="cb18-118"><a href="#cb18-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-121"><a href="#cb18-121" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-122"><a href="#cb18-122" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> clayton</span>
<span id="cb18-123"><a href="#cb18-123" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> clayton.rng <span class="im">import</span> base, evd, archimedean, monte_carlo</span>
<span id="cb18-124"><a href="#cb18-124" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb18-125"><a href="#cb18-125" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb18-126"><a href="#cb18-126" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb18-127"><a href="#cb18-127" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm, expon</span>
<span id="cb18-128"><a href="#cb18-128" aria-hidden="true" tabindex="-1"></a>plt.style.use(<span class="st">'qb-light.mplstyle'</span>) <span class="co"># for fancy figures</span></span>
<span id="cb18-129"><a href="#cb18-129" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">10</span>)</span>
<span id="cb18-130"><a href="#cb18-130" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-131"><a href="#cb18-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-132"><a href="#cb18-132" aria-hidden="true" tabindex="-1"></a><span class="fu">## The bivariate case {#sec-biv_case}</span></span>
<span id="cb18-133"><a href="#cb18-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-134"><a href="#cb18-134" aria-hidden="true" tabindex="-1"></a>In this subsection, we address the problem of generating a bivariate sample from a specified joint distribution with $d=2$. Suppose that we want to sample a bivariate random vector $\textbf{X}$ with copula $C$. In the case where the components are independent, the sampling procedure is straightforward: we can independently sample $X_0$ and $X_1$. However, in the general case where the copula is not the independent copula, this approach is not applicable.</span>
<span id="cb18-135"><a href="#cb18-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-136"><a href="#cb18-136" aria-hidden="true" tabindex="-1"></a>One solution to this problem is to use the conditioning method to sample from the copula. This method relies on the fact that given $(U_0, U_1)$ with copula $C$, the conditonal law of $U_1$ given $U_0$ is written as: </span>
<span id="cb18-137"><a href="#cb18-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-138"><a href="#cb18-138" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-139"><a href="#cb18-139" aria-hidden="true" tabindex="-1"></a>  c_{u_0}(u_1) \triangleq \mathbb{P}\left<span class="sc">\{</span> U_1 \leq u_1 | U_0 = u_0 \right<span class="sc">\}</span> = \frac{\partial C(u_0,u_1)}{\partial u_0}.</span>
<span id="cb18-140"><a href="#cb18-140" aria-hidden="true" tabindex="-1"></a>$$ {#eq-cond_sim}</span>
<span id="cb18-141"><a href="#cb18-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-142"><a href="#cb18-142" aria-hidden="true" tabindex="-1"></a>This allows us to first sample $U_0$ from a uniform distribution on the unit interval, and then to use the copula to generate $U_1$ given $U_0$. Finally, we can transform the resulting sample $(U_0, U_1)$ into the original space by applying the inverse marginal distributions $F_0^{-1}$ and $F_1^{-1}$ to $U_0$ and $U_1$ respectively. Thus, an algorithm for sampling bivariate copulae is given in @fig-alg-1. Algorithm in @fig-alg-1 presents a procedure for generating a bivariate sample from a copula. The algorithm takes as input the length of the sample $n$, as well as the parameters of the copula ($\theta, \psi_1, \psi_2$). The output is a bivariate sample from the desired copula model, denoted $<span class="sc">\{</span>(u_0^{(1)},u_1^{(1)}), \dots, (u_0^{(n)},u_1^{(n)})<span class="sc">\}</span>$. This algorithm is applicable as long as the copula has a first partial derivative with respect to its first component.</span>
<span id="cb18-143"><a href="#cb18-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-144"><a href="#cb18-144" aria-hidden="true" tabindex="-1"></a>::: {#fig-alg-1}</span>
<span id="cb18-145"><a href="#cb18-145" aria-hidden="true" tabindex="-1"></a><span class="al">![](figures/alg_1.png)</span></span>
<span id="cb18-146"><a href="#cb18-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-147"><a href="#cb18-147" aria-hidden="true" tabindex="-1"></a>Conditional sampling from copula</span>
<span id="cb18-148"><a href="#cb18-148" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-149"><a href="#cb18-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-150"><a href="#cb18-150" aria-hidden="true" tabindex="-1"></a>For step 6 of the algorithm, we need to find $u_1 \in <span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>$ such that $c_{u_0}(u_1) - t_1 = 0$ holds. This $u_1$ always exists because for every $u \in ]0,1<span class="co">[</span><span class="ot">$, we have $0 \leq c_{u_0}(u) \leq 1$, and the function $u \mapsto c_{u_0}(u)$ is increasing (see Theorem 2.2.7 of @nelsen2007introduction for a proof). This step can be solved using the \textsf{brentq} function from the \textsf{scipy} package. A sufficient condition for a copula to have a first partial derivative with respect to its first component in the Archimedean and extreme value cases is that the generator $\varphi$ and the Pickands dependence function $A$ are continuously differentiable on $</span><span class="co">]</span>0,1[$, respectively. In this case, the first partial derivatives of the copula are given by:</span>
<span id="cb18-151"><a href="#cb18-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-152"><a href="#cb18-152" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-153"><a href="#cb18-153" aria-hidden="true" tabindex="-1"></a>    \frac{\partial C}{\partial u_0}(u_0,u_1) = \frac{\varphi'(u_0)}{\varphi'(C(u_0,u_1))}, \quad (u_0,u_1) \in ]0,1[^2,</span>
<span id="cb18-154"><a href="#cb18-154" aria-hidden="true" tabindex="-1"></a>$$ {#eq-partial_deriv_arch}</span>
<span id="cb18-155"><a href="#cb18-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-156"><a href="#cb18-156" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-157"><a href="#cb18-157" aria-hidden="true" tabindex="-1"></a>    \frac{\partial C}{\partial u_0}(u_0,u_1) = \frac{\varphi'(u_0)}{\varphi'(C(u_0,u_1))}, \quad (u_0,u_1) \in ]0,1[^2,</span>
<span id="cb18-158"><a href="#cb18-158" aria-hidden="true" tabindex="-1"></a>$$ {#eq-partial_deriv_pick}</span>
<span id="cb18-159"><a href="#cb18-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-160"><a href="#cb18-160" aria-hidden="true" tabindex="-1"></a>where $t = \ln(u_1) / \ln(u_0u_1) \in (0,1)$ and $\mu(t) = A(t) - tA'(t)$.</span>
<span id="cb18-161"><a href="#cb18-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-162"><a href="#cb18-162" aria-hidden="true" tabindex="-1"></a>We now have all the necessary theoretical tools to give details on how the $\textsf{clayton}$ package is designed. The file $\texttt{base.py}$ contains the $\textbf{Multivariate}$ class and the $\texttt{sample}$ method to generate random numbers from $\textbf{X}$ with copula $C$. To do so, we use the inversion method that is to sample from $\textbf{U}$ using algorithm in @fig-alg-1 and we compose the corresponding uniform margins by $F_j^\leftarrow$. \eqref{eq:cond_sim} indicates that the sole knowledge of $A$ and $\varphi$ and their respective derivatives are needed in order to perform the sixth step of algorithm in @fig-alg-1. For that purpose, $\texttt{cond<span class="sc">\_</span>sim}$ method located inside $\textbf{Archimedean}$ and $\textbf{Extreme}$ classes performs algorithm in @fig-alg-1. Then each child of the bivariate $\textbf{Archimedean}$ (resp. $\textbf{Extreme}$) class is thus defined by its generator $\varphi$ (resp. $A$), it's derivative $\varphi'$ (resp. $A'$) and it's inverse $\varphi^\leftarrow$ as emphasized in green in @fig-diagram. Namely, we perform algorithm in @fig-alg-1 for the $\textbf{Archimedean}$ subclasses $\texttt{Frank}$, $\texttt{AMH}$, $\texttt{Clayton}$ (when $\theta &lt; 0$ for the previous three), $\texttt{Nelsen<span class="sc">\_</span>9}$, $\texttt{Nelsen<span class="sc">\_</span>10}$, $\texttt{Nelsen<span class="sc">\_</span>11}$, $\texttt{Nelsen<span class="sc">\_</span>12}$, $\texttt{Nelsen<span class="sc">\_</span>13}$, $\texttt{Nelsen<span class="sc">\_</span>14}$, $\texttt{Nelsen<span class="sc">\_</span>15}$ and $\texttt{Nelsen<span class="sc">\_</span>22}$. For the $\textbf{Extreme}$ class, such algorithm is performed for the $\texttt{AsyNegLog}$ and $\texttt{AsyMix}$. For other models, faster algorithms are known and thus implemented, we refer to @sec-mv_case for details.</span>
<span id="cb18-163"><a href="#cb18-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-164"><a href="#cb18-164" aria-hidden="true" tabindex="-1"></a>The following code illustrates the random vector generation for a bivariate Archimedean copula. By defining the parameter of the copula and the sample's length, the constructor for this copula is available and can be called using the $\texttt{Clayton}$ method, such as:</span>
<span id="cb18-165"><a href="#cb18-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-168"><a href="#cb18-168" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-169"><a href="#cb18-169" aria-hidden="true" tabindex="-1"></a>  n_samples, theta <span class="op">=</span> <span class="dv">1024</span>, <span class="op">-</span><span class="fl">0.5</span></span>
<span id="cb18-170"><a href="#cb18-170" aria-hidden="true" tabindex="-1"></a>  copula <span class="op">=</span> archimedean.Clayton(theta<span class="op">=</span>theta, n_samples<span class="op">=</span>n_samples)</span>
<span id="cb18-171"><a href="#cb18-171" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-172"><a href="#cb18-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-173"><a href="#cb18-173" aria-hidden="true" tabindex="-1"></a>To obtain a sample with uniform margins and a Clayton copula, we can use the $\texttt{sample<span class="sc">\_</span>unimargin}$ method, as follows:</span>
<span id="cb18-174"><a href="#cb18-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-177"><a href="#cb18-177" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-178"><a href="#cb18-178" aria-hidden="true" tabindex="-1"></a>  sample <span class="op">=</span> copula.sample_unimargin()</span>
<span id="cb18-179"><a href="#cb18-179" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-180"><a href="#cb18-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-181"><a href="#cb18-181" aria-hidden="true" tabindex="-1"></a>Here, the $\texttt{sample}$ object is a $\textsf{numpy}$ array with $2$ columns and $1024$ rows, where each row contains a realization from a Clayton copula (see below)</span>
<span id="cb18-182"><a href="#cb18-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-185"><a href="#cb18-185" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-186"><a href="#cb18-186" aria-hidden="true" tabindex="-1"></a>  fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb18-187"><a href="#cb18-187" aria-hidden="true" tabindex="-1"></a>  ax.scatter(sample[:,<span class="dv">0</span>], sample[:,<span class="dv">1</span>],</span>
<span id="cb18-188"><a href="#cb18-188" aria-hidden="true" tabindex="-1"></a>             edgecolors<span class="op">=</span><span class="st">'#6F6F6F'</span>, color<span class="op">=</span><span class="st">'#C5C5C5'</span>, s<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb18-189"><a href="#cb18-189" aria-hidden="true" tabindex="-1"></a>  ax.set_xlabel(<span class="vs">r'$u_0$'</span>)</span>
<span id="cb18-190"><a href="#cb18-190" aria-hidden="true" tabindex="-1"></a>  ax.set_ylabel(<span class="vs">r'$u_1$'</span>)</span>
<span id="cb18-191"><a href="#cb18-191" aria-hidden="true" tabindex="-1"></a>  plt.show()</span>
<span id="cb18-192"><a href="#cb18-192" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-193"><a href="#cb18-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-194"><a href="#cb18-194" aria-hidden="true" tabindex="-1"></a><span class="fu">## The multivariate case {#sec-mv_case}</span></span>
<span id="cb18-195"><a href="#cb18-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-196"><a href="#cb18-196" aria-hidden="true" tabindex="-1"></a>We will now address the generation of multivariate Archimedean and Extreme value copulae proposed in the Clayton package. In the multivariate case, the link between partial derivatives and the conditional law remains. Indeed, let $(U_0, \dots, U_{d-1})$ be a $d$-dimensional random vector with uniform margins and copula $C$. The conditional distribution of $U_k$ given the values of $U_0, \dots, U_{k-1}$ is</span>
<span id="cb18-197"><a href="#cb18-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-198"><a href="#cb18-198" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-199"><a href="#cb18-199" aria-hidden="true" tabindex="-1"></a>  \mathbb{P}\left<span class="sc">\{</span> U_k \leq u_k | U_0 = u_0, \dots, U_{k-1} = u_{k-1} \right<span class="sc">\}</span> = \frac{\partial^{k-1} C(u_0, \dots, u_k,1,\dots,1)/\partial u_0 \dots \partial u_{k-1}}{\partial^{k-1} C(u_0, \dots, u_{k-1},1,\dots,1) / \partial u_0 \dots \partial u_{k-1}}.</span>
<span id="cb18-200"><a href="#cb18-200" aria-hidden="true" tabindex="-1"></a>$$ {#eq-cond_dist_mv}</span>
<span id="cb18-201"><a href="#cb18-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-202"><a href="#cb18-202" aria-hidden="true" tabindex="-1"></a>for $k \in {1,\dots, d-1}$. The conditional simulation algorithm may be written as follows.</span>
<span id="cb18-203"><a href="#cb18-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-204"><a href="#cb18-204" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Generate $d$ independent uniform random on $<span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>$ variates $v_0, \dots, v_{d-1}$.</span>
<span id="cb18-205"><a href="#cb18-205" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Set $u_0 = v_0$.</span>
<span id="cb18-206"><a href="#cb18-206" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>For $k = 1, \dots, d-1$, evaluate the inverse of the conditional distribution given by \eqref{eq:cond_dist_mv} at $v_k$, to generate $u_k$.</span>
<span id="cb18-207"><a href="#cb18-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-208"><a href="#cb18-208" aria-hidden="true" tabindex="-1"></a>Nevertheless, the evaluation of the inverse conditional distribution becomes increasingly complicated as the dimension $d$ increases. Furthermore, it can be difficult for some models to derive a closed form of @eq-cond_dist_mv that makes it impossible to implement it in a general algorithm with only the dimension $d$ as an input. For multivariate Archimedean copulae, @10.1214/07-AOS556 give a method to generate a random vector from the $d$-dimensional copula $C$ with generator $\varphi$ (see Section 5.2 of @10.1214/07-AOS556). A stochastic representation for Archimedean copulae generated by a $d$-monotone generator is given by</span>
<span id="cb18-209"><a href="#cb18-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-210"><a href="#cb18-210" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-211"><a href="#cb18-211" aria-hidden="true" tabindex="-1"></a>\textbf{U} = \left( \varphi^\leftarrow(R S_1), \dots, \varphi^\leftarrow(RS_d) \right) \sim C,</span>
<span id="cb18-212"><a href="#cb18-212" aria-hidden="true" tabindex="-1"></a>$$ {#eq-radial}</span>
<span id="cb18-213"><a href="#cb18-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-214"><a href="#cb18-214" aria-hidden="true" tabindex="-1"></a>where $R \sim F_R$, the radial distribution which is independent of $S$ and $S$ is distributed uniformly in the unit simplex $\Delta^{d-1}$. One challenging aspect of this algorithm is to have an accurate evaluation of the radial distribution of the Archimedean copula and thus to numerically inverse this distribution. The associated radial distribution for the $\textsf{Clayton}$ copula is given in Example 3.3 @10.1214/07-AOS556 while those of the $\textsf{Joe}$, $\textsf{AMH}$, $\textsf{Gumbel}$ and $\textsf{Frank}$ copulae are given in @hofert2012likelihood. In general, one can use numerical inversion algorithms for computing the inverse of the radial distribution, however it will lead to spurious numerical errors. Other algorithms exist when the generator is known to be the Laplace-Stieltjes transform, denoted as $\mathcal{LS}$, of some positive random variables (see @10.2307/2289314, @frees1998understanding). This positive random variable is often referenced as the frailty distribution. In this framework, Archimedean copulae allow for the stochastic representation</span>
<span id="cb18-215"><a href="#cb18-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-216"><a href="#cb18-216" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-217"><a href="#cb18-217" aria-hidden="true" tabindex="-1"></a>  \textbf{U} = \left( \varphi^\leftarrow (E_1/V), \dots, \varphi^\leftarrow(E_d /V)\right) \sim C,</span>
<span id="cb18-218"><a href="#cb18-218" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb18-219"><a href="#cb18-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-220"><a href="#cb18-220" aria-hidden="true" tabindex="-1"></a>with $V \sim F = \mathcal{LS}^{-1}<span class="co">[</span><span class="ot">\varphi^\leftarrow</span><span class="co">]</span>$ the frailty and $E_1, \dots, E_d$ are distributed i.i.d. according to a standard exponential and independent of $V$. Algorithm in @fig-alg-2 presents a procedure for generating a multivariate sample from an Archimedean copula where the frailty distribution is known. The algorithm takes as an input the length of the sample $n$, as well as the parameter of the copula $\theta$. The output is a $d$-variate sample from the desired copula model, denoted $<span class="sc">\{</span>(u_0^{(1)}, \dots, u_{d-1}^{(1)}), \dots, (u_0^{(n)},\dots,u_{d-1}^{(n)})<span class="sc">\}</span>$.</span>
<span id="cb18-221"><a href="#cb18-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-222"><a href="#cb18-222" aria-hidden="true" tabindex="-1"></a>::: {#fig-alg-2}</span>
<span id="cb18-223"><a href="#cb18-223" aria-hidden="true" tabindex="-1"></a><span class="al">![](figures/alg_2.png)</span></span>
<span id="cb18-224"><a href="#cb18-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-225"><a href="#cb18-225" aria-hidden="true" tabindex="-1"></a>Sampling from Archimedean copula using frailty distribution</span>
<span id="cb18-226"><a href="#cb18-226" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-227"><a href="#cb18-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-228"><a href="#cb18-228" aria-hidden="true" tabindex="-1"></a>In this framework, we define $\texttt{<span class="sc">\_</span>frailty<span class="sc">\_</span>sim}$ method defined inside the $\textbf{Archimedean}$ class which performs algorithm in @fig-alg-2. Then, each Archimedean copula is defined by the generator $\varphi$, it's inverse $\varphi^\leftarrow$ and the frailty distribution denoted as $\mathcal{LS}^{-1}<span class="co">[</span><span class="ot">\varphi^\leftarrow</span><span class="co">]</span>$ as long as we know the frailty. This is the case for $\texttt{Joe}$, $\texttt{Clayton}$, $\texttt{AMH}$ or $\texttt{Frank}$.</span>
<span id="cb18-229"><a href="#cb18-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-230"><a href="#cb18-230" aria-hidden="true" tabindex="-1"></a>For the extreme value case, algorithms have been proposed, as in @stephenson2003simulating (see Algorithms 2.1 and 2.2), who proposes sampling methods for the Gumbel and the asymmetric logistic model. These algorithms are implemented in the $\textsf{clayton}$ package. Note that these algorithms are model-specific, thus the $\texttt{sample<span class="sc">\_</span>unimargin}$ method is exceptionally located in the corresponding child of the multivariate $\textbf{Extreme}$ class. Another procedure designed by @10.1093/biomet/asw008 to sample from multivariate extreme value models using extremal functions (see Algorithm 2 in @10.1093/biomet/asw008) is also of prime interest. For the implemented models using this algorithm, namely $\textbf{Hüsler-Reiss}$, $\textbf{tEV}$, $\textbf{Bilogistic}$ and $\textbf{Dirichlet}$ models, a method called $\texttt{<span class="sc">\_</span>rextfunc}$ is located inside each classes which allows to generate an observation from the according law of the extremal function.</span>
<span id="cb18-231"><a href="#cb18-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-232"><a href="#cb18-232" aria-hidden="true" tabindex="-1"></a>Samples from the Gaussian and Student copula are directly given by Algorithm 5.9 and 5.10 respectively of @quantrisk. As each algorithm is model specific, the $\texttt{sample<span class="sc">\_</span>unimargin}$ method is located inside the $\textbf{Gaussian}$ and $\textbf{Student}$ classes.</span>
<span id="cb18-233"><a href="#cb18-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-234"><a href="#cb18-234" aria-hidden="true" tabindex="-1"></a>We present how to construct a multivariate Archimedean copula and to generate random vectors from this model. Introducing the parameters of the copula, we appeal the following lines to construct our copula object:</span>
<span id="cb18-235"><a href="#cb18-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-238"><a href="#cb18-238" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-239"><a href="#cb18-239" aria-hidden="true" tabindex="-1"></a>d, theta, n_samples <span class="op">=</span> <span class="dv">3</span>, <span class="fl">2.0</span>, <span class="dv">1024</span></span>
<span id="cb18-240"><a href="#cb18-240" aria-hidden="true" tabindex="-1"></a>copula <span class="op">=</span> archimedean.Clayton(theta<span class="op">=</span>theta, n_samples<span class="op">=</span>n_samples, dim<span class="op">=</span>d)</span>
<span id="cb18-241"><a href="#cb18-241" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-242"><a href="#cb18-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-243"><a href="#cb18-243" aria-hidden="true" tabindex="-1"></a>We now call the $\texttt{sample<span class="sc">\_</span>unimargin}$ method to obtain randomly generated vectors.</span>
<span id="cb18-244"><a href="#cb18-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-247"><a href="#cb18-247" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-248"><a href="#cb18-248" aria-hidden="true" tabindex="-1"></a>sample <span class="op">=</span> copula.sample_unimargin()</span>
<span id="cb18-249"><a href="#cb18-249" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-250"><a href="#cb18-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-251"><a href="#cb18-251" aria-hidden="true" tabindex="-1"></a>We thus represent in three dimensions these realizations below.</span>
<span id="cb18-252"><a href="#cb18-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-255"><a href="#cb18-255" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-256"><a href="#cb18-256" aria-hidden="true" tabindex="-1"></a>  fig <span class="op">=</span> plt.figure()</span>
<span id="cb18-257"><a href="#cb18-257" aria-hidden="true" tabindex="-1"></a>  ax <span class="op">=</span> fig.add_subplot(<span class="dv">111</span>, projection <span class="op">=</span> <span class="st">'3d'</span>)</span>
<span id="cb18-258"><a href="#cb18-258" aria-hidden="true" tabindex="-1"></a>  ax.scatter3D(sample[:,<span class="dv">0</span>], sample[:,<span class="dv">1</span>], sample[:,<span class="dv">2</span>], s<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb18-259"><a href="#cb18-259" aria-hidden="true" tabindex="-1"></a>               edgecolors<span class="op">=</span><span class="st">'#6F6F6F'</span>, color<span class="op">=</span><span class="st">'#C5C5C5'</span>)</span>
<span id="cb18-260"><a href="#cb18-260" aria-hidden="true" tabindex="-1"></a>  ax.set_xlabel(<span class="vs">r'$u_0$'</span>)</span>
<span id="cb18-261"><a href="#cb18-261" aria-hidden="true" tabindex="-1"></a>  ax.set_ylabel(<span class="vs">r'$u_1$'</span>)</span>
<span id="cb18-262"><a href="#cb18-262" aria-hidden="true" tabindex="-1"></a>  ax.set_zlabel(<span class="vs">r'$u_2$'</span>)</span>
<span id="cb18-263"><a href="#cb18-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-264"><a href="#cb18-264" aria-hidden="true" tabindex="-1"></a>  plt.show()</span>
<span id="cb18-265"><a href="#cb18-265" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-266"><a href="#cb18-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-267"><a href="#cb18-267" aria-hidden="true" tabindex="-1"></a><span class="fu"># Case study : Modeling pairwise dependence between spatial maximas with missing data {#sec-pairwise}</span></span>
<span id="cb18-268"><a href="#cb18-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-269"><a href="#cb18-269" aria-hidden="true" tabindex="-1"></a>We now proceed to a case study where we use our \textsf{python} package to assess, under a finite sample framework, the asymptotic properties of an estimator of the $\lambda$-madogram when data are completely missing at random (MCAR). This case study comes from numerical results of @boulin2021non. The $\lambda$-madogram belongs to a family of estimators, namely the madogram, which is of prime interest in environmental sciences, as it is designed to model pairwise dependence between maxima in space, see, e.g., @bernard:hal-03207469, @BADOR201517, @saunders where the madogram was used as a dissimilarity measure to perform clustering. Where in several fields, for example econometrics (@woolridge2007) or survey theory (@chauvet2015), the MCAR hypothesis appears to be a strong hypothesis, this hypothesis is more realistic in environmental research as the missingness of one observation is usually due to instruments, communication and processing errors that may be reasonably supposed independent of the quantity of interest. In @sec-background, we define objects and properties of interest while in @sec-num we describe a detailed tutorial in $\textsf{python}$ and with $\textsf{clayton}$ package to compare the asymptotic variance with an empirical counterpart of the $\lambda$-madogram with $\lambda = 0.5$.</span>
<span id="cb18-270"><a href="#cb18-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-271"><a href="#cb18-271" aria-hidden="true" tabindex="-1"></a><span class="fu">## Background {#sec-background}</span></span>
<span id="cb18-272"><a href="#cb18-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-273"><a href="#cb18-273" aria-hidden="true" tabindex="-1"></a>It was emphasized that the possible dependence between maxima can be described with the extreme value copula. This function is completely characterized by the Pickands dependence function (see @eq-tail_dependence_pickands) where the latter is equivalent to the $\lambda$-madogram introduced by @naveau:hal-00312758 and defined as  </span>
<span id="cb18-274"><a href="#cb18-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-275"><a href="#cb18-275" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb18-276"><a href="#cb18-276" aria-hidden="true" tabindex="-1"></a>  \nu(\lambda) = \mathbb{E}\left<span class="co">[</span><span class="ot"> \left|\{F_0(X_0)\}^{1/\lambda} - \{F_1(X_1)\}^{1/(1-\lambda)} \right|\right</span><span class="co">]</span>,</span>
<span id="cb18-277"><a href="#cb18-277" aria-hidden="true" tabindex="-1"></a>$$ {#eq-lmbd_mado}</span>
<span id="cb18-278"><a href="#cb18-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-279"><a href="#cb18-279" aria-hidden="true" tabindex="-1"></a>with $\lambda \in (0,1)$, and if $\lambda = 0$ and $0&lt;u&lt;1$, then $u^{1/\lambda} = 0$ by convention. The $\lambda$-madogram took its inspiration from the extensively used geostatistics tool, the variogram (see Chapter 1.3 of @alma991005826659705596 for a definition and some classical properties). The $\lambda$-madogram can be interpreted as the $L_1$-distance between the uniform margins elevated to the inverse of the corresponding weights $\lambda$ and $1-\lambda$. This quantity describes the dependence structure between extremes by its relation with the Pickands dependence function. If we suppose that $C$ is an extreme value copula as in \eqref{eq:evc}, we have</span>
<span id="cb18-280"><a href="#cb18-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-281"><a href="#cb18-281" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb18-282"><a href="#cb18-282" aria-hidden="true" tabindex="-1"></a>  A(\lambda) = \frac{\nu(\lambda) + c(\lambda)}{1-\nu(\lambda) - c(\lambda)},</span>
<span id="cb18-283"><a href="#cb18-283" aria-hidden="true" tabindex="-1"></a>$$ {#eq-pickands_mado}</span>
<span id="cb18-284"><a href="#cb18-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-285"><a href="#cb18-285" aria-hidden="true" tabindex="-1"></a>with $c(\lambda) = 2^{-1} (\lambda / (1-\lambda) + (1-\lambda)/\lambda)$ (see Proposition 3 of @MARCON20171 for details).</span>
<span id="cb18-286"><a href="#cb18-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-287"><a href="#cb18-287" aria-hidden="true" tabindex="-1"></a>We consider independent and identically distributed i.i.d. copies $\textbf{X}_1, \dots, \textbf{X}_n$ of $\textbf{X}$. In presence of missing data, we do not observe a complete vector $\textbf{X}_i$ for $i \in \{1,\dots,n\}$. We introduce $\textbf{I}_i \in \{0,1\}^2$ which satisfies, $\forall j \in \{0,1\}$, if $X_{i,j}$ is not observed then $I_{i,j} = 0$. To formalize incomplete observations, we introduce the incomplete vector $\tilde{\textbf{X}}_i$ with values in the product space $\bigotimes_{j=1}^2 (\mathbb{R} \cup <span class="sc">\{</span>\textsf{NA}<span class="sc">\}</span>)$ such as</span>
<span id="cb18-288"><a href="#cb18-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-289"><a href="#cb18-289" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-290"><a href="#cb18-290" aria-hidden="true" tabindex="-1"></a>  \tilde{X}_{i,j} = X_{i,j} I_{i,j} + \textsf{NA} (1-I_{i,j}), \quad i \in <span class="sc">\{</span>1,\dots,n<span class="sc">\}</span>, \, j \in <span class="sc">\{</span>0,\dots, d-1<span class="sc">\}</span>.</span>
<span id="cb18-291"><a href="#cb18-291" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-292"><a href="#cb18-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-293"><a href="#cb18-293" aria-hidden="true" tabindex="-1"></a>We thus suppose that we observe a $4$-tuple such as</span>
<span id="cb18-294"><a href="#cb18-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-295"><a href="#cb18-295" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb18-296"><a href="#cb18-296" aria-hidden="true" tabindex="-1"></a>  (\textbf{I}_i, \tilde{\textbf{X}}_i), \quad i \in <span class="sc">\{</span>1,\dots,n<span class="sc">\}</span>,</span>
<span id="cb18-297"><a href="#cb18-297" aria-hidden="true" tabindex="-1"></a>$$ {#eq-missing_2}</span>
<span id="cb18-298"><a href="#cb18-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-299"><a href="#cb18-299" aria-hidden="true" tabindex="-1"></a>i.e. at each $i \in <span class="sc">\{</span>1,\dots,n<span class="sc">\}</span>$, several entries may be missing. We also suppose that for all $i \in <span class="sc">\{</span>1, \dots,n <span class="sc">\}</span>$, $\textbf{I}_{i}$ are i.i.d copies from $\textbf{I} = (I_0, I_1)$ where $I_j$ is distributed according to a Bernoulli random variable $\mathcal{B}(p_j)$ with $p_j = \mathbb{P}(I_j = 1)$ for $j \in <span class="sc">\{</span>0,1<span class="sc">\}</span>$. We denote by $p$ the probability of observing completely a realization from $\textbf{X}$, that is $p = \mathbb{P}(I_0=1, I_1 = 1)$. In @boulin2021non, hybrid and corrected estimators, respectively denoted as $\hat{\nu}_n^{\mathcal{H}}$ and $\hat{\nu}_n^{\mathcal{H*}}$, are proposed to estimate nonparametrically the $\lambda$-madogram in presence of missing data completely at random. Furthermore, a closed expression of their asymptotic variances for $\lambda \in ]0,1[$ is also given. This result is summarized in the following proposition.</span>
<span id="cb18-300"><a href="#cb18-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-301"><a href="#cb18-301" aria-hidden="true" tabindex="-1"></a>::: {#thm-line}</span>
<span id="cb18-302"><a href="#cb18-302" aria-hidden="true" tabindex="-1"></a><span class="fu">## @boulin2021non</span></span>
<span id="cb18-303"><a href="#cb18-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-304"><a href="#cb18-304" aria-hidden="true" tabindex="-1"></a>Let $(\textbf{I}_i, \tilde{\textbf{X}_i})_{i=1}^n$ be a samble given by @eq-missing_2. For $\lambda \in ]0,1[$, if $C$ is </span>
<span id="cb18-305"><a href="#cb18-305" aria-hidden="true" tabindex="-1"></a>an extreme value copula with Pickands dependence function $A$, we have as $n \rightarrow \infty$</span>
<span id="cb18-306"><a href="#cb18-306" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb18-307"><a href="#cb18-307" aria-hidden="true" tabindex="-1"></a>    &amp;\sqrt{n} \left(\hat{\nu}_n^{\mathcal{H}}(\lambda) - \nu( \lambda)\right) \overset{d}{\rightarrow} \mathcal{N}\left(0, \mathcal{S}^{\mathcal{H}}(p_1,p_2,p, \lambda)\right), <span class="sc">\\</span> </span>
<span id="cb18-308"><a href="#cb18-308" aria-hidden="true" tabindex="-1"></a>    &amp;\sqrt{n} \left(\hat{\nu}_n^{\mathcal{H}*}(\lambda) - \nu( \lambda)\right) \overset{d}{\rightarrow} \mathcal{N}\left(0, \mathcal{S}^{\mathcal{H}*}(p_1,p_2,p, \lambda)\right),</span>
<span id="cb18-309"><a href="#cb18-309" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb18-310"><a href="#cb18-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-311"><a href="#cb18-311" aria-hidden="true" tabindex="-1"></a>where $\mathcal{S}^{\mathcal{H}}(p_1,p_2,p, \lambda)$ and $\mathcal{S}^{\mathcal{H}*}(p_1,p_2,p, \lambda)$ are the </span>
<span id="cb18-312"><a href="#cb18-312" aria-hidden="true" tabindex="-1"></a>asymptoptic variances of the random variables.</span>
<span id="cb18-313"><a href="#cb18-313" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-314"><a href="#cb18-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-315"><a href="#cb18-315" aria-hidden="true" tabindex="-1"></a><span class="fu">## Numerical results {#sec-num}</span></span>
<span id="cb18-316"><a href="#cb18-316" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-317"><a href="#cb18-317" aria-hidden="true" tabindex="-1"></a>Benefiting from generating data with $\textsf{clayton}$ we are thus able, with Monte Carlo simulation, to assess theoretical results given by @thm-line in a finite sample setting. For that purpose, we implement a $\textsf{MonteCarlo}$ class (in $\texttt{monte<span class="sc">\_</span>carlo.py}$ file) which contains some methods to perform some Monte Carlo iterations for a given extreme value copula. Now, we set up parameters to sample our bivariate dataset. For this subsection, we choose the asymmetric negative logistic model (see @sec-bv_ext for a definition) with parameters $\theta = 10, \psi_1 = 0.1, \psi_2 = 1.0$ and we define the following function:</span>
<span id="cb18-318"><a href="#cb18-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-321"><a href="#cb18-321" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-322"><a href="#cb18-322" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> gauss_function(x, x0, sigma):</span>
<span id="cb18-323"><a href="#cb18-323" aria-hidden="true" tabindex="-1"></a>      <span class="cf">return</span> (np.sqrt(<span class="fl">1.</span> <span class="op">/</span> (<span class="dv">2</span><span class="op">*</span>np.pi <span class="op">*</span> sigma<span class="op">**</span><span class="dv">2</span>)) <span class="op">*</span></span>
<span id="cb18-324"><a href="#cb18-324" aria-hidden="true" tabindex="-1"></a>              np.exp(<span class="op">-</span>(x <span class="op">-</span> x0) <span class="op">**</span> <span class="dv">2</span> <span class="op">/</span> (<span class="dv">2</span> <span class="op">*</span> sigma<span class="op">**</span><span class="dv">2</span>)))</span>
<span id="cb18-325"><a href="#cb18-325" aria-hidden="true" tabindex="-1"></a>  n_samples <span class="op">=</span> <span class="dv">512</span></span>
<span id="cb18-326"><a href="#cb18-326" aria-hidden="true" tabindex="-1"></a>  theta, psi1, psi2 <span class="op">=</span> <span class="dv">10</span>, <span class="fl">0.1</span>, <span class="fl">1.0</span></span>
<span id="cb18-327"><a href="#cb18-327" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-328"><a href="#cb18-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-329"><a href="#cb18-329" aria-hidden="true" tabindex="-1"></a>We choose the standard normal and exponential as margins. To simulate this sample, the following lines should be typed:</span>
<span id="cb18-330"><a href="#cb18-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-333"><a href="#cb18-333" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-334"><a href="#cb18-334" aria-hidden="true" tabindex="-1"></a>  copula <span class="op">=</span> evd.AsyNegLog(theta<span class="op">=</span>theta, psi1<span class="op">=</span>psi1,</span>
<span id="cb18-335"><a href="#cb18-335" aria-hidden="true" tabindex="-1"></a>                         psi2<span class="op">=</span>psi2, n_samples<span class="op">=</span>n_samples)</span>
<span id="cb18-336"><a href="#cb18-336" aria-hidden="true" tabindex="-1"></a>  sample <span class="op">=</span> copula.sample(inv_cdf<span class="op">=</span>[norm.ppf, expon.ppf])</span>
<span id="cb18-337"><a href="#cb18-337" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-338"><a href="#cb18-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-339"><a href="#cb18-339" aria-hidden="true" tabindex="-1"></a>The $1024 \times 2$ array $\texttt{sample}$ contains $1024$ realization of the $\textbf{asymmetric negative logistic}$ model where the first column is distributed according to a standard normal random variable and the second column as a standard exponential. This distribution is depicted below. To obtain it, one needs the following lines of command:</span>
<span id="cb18-340"><a href="#cb18-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-343"><a href="#cb18-343" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-344"><a href="#cb18-344" aria-hidden="true" tabindex="-1"></a>  fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb18-345"><a href="#cb18-345" aria-hidden="true" tabindex="-1"></a>  ax.scatter(sample[:,<span class="dv">0</span>], sample[:,<span class="dv">1</span>],</span>
<span id="cb18-346"><a href="#cb18-346" aria-hidden="true" tabindex="-1"></a>             edgecolors<span class="op">=</span><span class="st">"#6F6F6F"</span>, color<span class="op">=</span><span class="st">"#C5C5C5"</span>, s<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb18-347"><a href="#cb18-347" aria-hidden="true" tabindex="-1"></a>  ax.set_xlabel(<span class="vs">r'$x_0$'</span>)</span>
<span id="cb18-348"><a href="#cb18-348" aria-hidden="true" tabindex="-1"></a>  ax.set_ylabel(<span class="vs">r'$x_1$'</span>)</span>
<span id="cb18-349"><a href="#cb18-349" aria-hidden="true" tabindex="-1"></a>  plt.show()</span>
<span id="cb18-350"><a href="#cb18-350" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-351"><a href="#cb18-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-352"><a href="#cb18-352" aria-hidden="true" tabindex="-1"></a>Before going into further details, we will present the missing mechanism. Let $V_0$ and $V_1$ be random variables uniformly distributed under the $]0,1[$ segment with copula $C_{(V_0,V_1)}$. We set $I_0 = 1<span class="sc">\{</span>{V_0 \leq p_0}<span class="sc">\}</span>$ and $I_1 = 1<span class="sc">\{</span>{V_1 \leq p_1}<span class="sc">\}</span>$. It is thus immediate that $I_0 \sim \mathcal{B}(p_0)$ and $I_1 \sim \mathcal{B}(p_1)$ and $p \triangleq \mathbb{P}<span class="sc">\{</span>I_0 = 1, I_1 =1 <span class="sc">\}</span> = C_{(V_0,V_1)}(p_0, p_1)$. For our illustration, we will take $C_{(V_0,V_1)}$ as a \texttt{Joe} copula with parameter $\theta = 2.0$ (we refer to @sec-bv_arch for a definition of this copula). For this copula, it is more likely to observe a realization $v_0 \geq 0.8$ from $V_0$ if $v_1 \geq 0.8$ from $V_1$. If we observe $v_1 &lt; 0.8$, the realization $v_0$ is close to being independent of $v_1$. In climate studies, extreme events could damage the recording instrument in the surrounding regions where they occur, thus the missingness of one variable may depend on others. We initialize the copula $C_{(V_0,V_1)}$ with the following line:</span>
<span id="cb18-353"><a href="#cb18-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-356"><a href="#cb18-356" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-357"><a href="#cb18-357" aria-hidden="true" tabindex="-1"></a>  copula_miss <span class="op">=</span> archimedean.Joe(theta<span class="op">=</span><span class="fl">2.0</span>, n_samples<span class="op">=</span>n_samples)</span>
<span id="cb18-358"><a href="#cb18-358" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-359"><a href="#cb18-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-360"><a href="#cb18-360" aria-hidden="true" tabindex="-1"></a>For a given $\lambda \in ]0,1[$, we now want to estimate a $\lambda$-madogram with a sample from the asymmetric negative logistic model, where some observations are missing due to the missing mechanism described above. We will repeat this step several times to compute an empirical counterpart of the asymptotic variance. The \texttt{MonteCarlo} object has been designed for this purpose: we specify the number of iterations $n_{iter}$ (take $n_{iter} = 1024$), the chosen extreme value copula (asymmetric negative logistic model), the missing mechanism (described by $C_{(V_0,V_1)}$ and $p_0 = p_1 = 0.9$), and $\lambda$ (noted $\texttt{w}$). We can write the following lines of code:</span>
<span id="cb18-361"><a href="#cb18-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-364"><a href="#cb18-364" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-365"><a href="#cb18-365" aria-hidden="true" tabindex="-1"></a>  u <span class="op">=</span> np.array([<span class="fl">0.9</span>, <span class="fl">0.9</span>])</span>
<span id="cb18-366"><a href="#cb18-366" aria-hidden="true" tabindex="-1"></a>  n_iter, P, w <span class="op">=</span> <span class="dv">256</span>, [[u[<span class="dv">0</span>], copula_miss._c(</span>
<span id="cb18-367"><a href="#cb18-367" aria-hidden="true" tabindex="-1"></a>      u)], [copula_miss._c(u), u[<span class="dv">1</span>]]], np.array([<span class="fl">0.5</span>,<span class="fl">0.5</span>])</span>
<span id="cb18-368"><a href="#cb18-368" aria-hidden="true" tabindex="-1"></a>  monte <span class="op">=</span> monte_carlo.MonteCarlo(n_iter<span class="op">=</span>n_iter, n_samples<span class="op">=</span>n_samples,</span>
<span id="cb18-369"><a href="#cb18-369" aria-hidden="true" tabindex="-1"></a>                                 copula<span class="op">=</span>copula, copula_miss<span class="op">=</span>copula_miss,</span>
<span id="cb18-370"><a href="#cb18-370" aria-hidden="true" tabindex="-1"></a>                                 weight<span class="op">=</span>w, matp<span class="op">=</span>P)</span>
<span id="cb18-371"><a href="#cb18-371" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-372"><a href="#cb18-372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-373"><a href="#cb18-373" aria-hidden="true" tabindex="-1"></a>The $\texttt{MonteCarlo}$ object is thus initialized with all parameters needed. We may use the $\texttt{simu}$ method to generate a $\texttt{DataFrame}$ (a $\texttt{pandas}$ object) composed out $1024$ rows and $3$ columns. Each row contains an estimate of the $\lambda$-madogram, $\hat{\nu}_n^{\mathcal{H}*}$ in @thm-line ($\texttt{var<span class="sc">\_</span>mado}$), the sample length $n$ ($\texttt{n}$) and the normalized estimation error ($\texttt{scaled}$). We thus call the $\texttt{simu}$ method.</span>
<span id="cb18-374"><a href="#cb18-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-377"><a href="#cb18-377" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-378"><a href="#cb18-378" aria-hidden="true" tabindex="-1"></a>  df_wmado <span class="op">=</span> monte.finite_sample(inv_cdf<span class="op">=</span>[norm.ppf, expon.ppf], corr<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb18-379"><a href="#cb18-379" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(df_wmado.head())</span>
<span id="cb18-380"><a href="#cb18-380" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-381"><a href="#cb18-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-382"><a href="#cb18-382" aria-hidden="true" tabindex="-1"></a>The argument $\texttt{corr=True}$ specifies that we compute the corrected estimator, $\hat{\nu}_n^{\mathcal{H}*}$ in @thm-line. Now, using the $\texttt{var\_mado}$ method defined inside in the **Extreme** class, we obtain the asymptotic variance for the given model and parameters from the missing mechanism. We obtain this quantity as follows</span>
<span id="cb18-383"><a href="#cb18-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-386"><a href="#cb18-386" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-387"><a href="#cb18-387" aria-hidden="true" tabindex="-1"></a>  var_mado <span class="op">=</span> copula.var_mado(w, jointp<span class="op">=</span>copula_miss._c(u), matp<span class="op">=</span>P, corr<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb18-388"><a href="#cb18-388" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(var_mado)</span>
<span id="cb18-389"><a href="#cb18-389" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(df_wmado[<span class="st">'scaled'</span>].var())</span>
<span id="cb18-390"><a href="#cb18-390" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-391"><a href="#cb18-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-392"><a href="#cb18-392" aria-hidden="true" tabindex="-1"></a>We propose here to check numerically the asymptotic normality with variance $\mathcal{S}^{\mathcal{H}*}$ of the normalized estimation error of the corrected estimator. We have all data in hand and the asymptotic variance was computed by lines above. We thus write:</span>
<span id="cb18-393"><a href="#cb18-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-396"><a href="#cb18-396" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-397"><a href="#cb18-397" aria-hidden="true" tabindex="-1"></a>    sigma <span class="op">=</span> np.sqrt(var_mado)</span>
<span id="cb18-398"><a href="#cb18-398" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> np.linspace(<span class="bu">min</span>(df_wmado[<span class="st">'scaled'</span>]), <span class="bu">max</span>(df_wmado[<span class="st">'scaled'</span>]), <span class="dv">1000</span>)</span>
<span id="cb18-399"><a href="#cb18-399" aria-hidden="true" tabindex="-1"></a>    gauss <span class="op">=</span> gauss_function(x, <span class="dv">0</span>, sigma)</span>
<span id="cb18-400"><a href="#cb18-400" aria-hidden="true" tabindex="-1"></a>    sns.displot(data<span class="op">=</span>df_wmado, x<span class="op">=</span><span class="st">"scaled"</span>, color<span class="op">=</span><span class="st">'#C5C5C5'</span>,</span>
<span id="cb18-401"><a href="#cb18-401" aria-hidden="true" tabindex="-1"></a>                kind<span class="op">=</span><span class="st">'hist'</span>, stat<span class="op">=</span><span class="st">'density'</span>, common_norm<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb18-402"><a href="#cb18-402" aria-hidden="true" tabindex="-1"></a>                alpha<span class="op">=</span><span class="fl">0.5</span>, fill<span class="op">=</span><span class="va">True</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>, bins<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb18-403"><a href="#cb18-403" aria-hidden="true" tabindex="-1"></a>    plt.plot(x,gauss, color<span class="op">=</span><span class="st">'#6F6F6F'</span>)</span>
<span id="cb18-404"><a href="#cb18-404" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-405"><a href="#cb18-405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-406"><a href="#cb18-406" aria-hidden="true" tabindex="-1"></a><span class="fu"># Discussion {#sec-discussion}</span></span>
<span id="cb18-407"><a href="#cb18-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-408"><a href="#cb18-408" aria-hidden="true" tabindex="-1"></a><span class="fu">## Comparison of $\textsf{clayton}$ with $\textsf{R}$ packages</span></span>
<span id="cb18-409"><a href="#cb18-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-410"><a href="#cb18-410" aria-hidden="true" tabindex="-1"></a>To compare \textsf{clayton} to existing packages in $\textsf{R}$, we consider the $\textsf{copula}$ package (@kojadinovic2010modeling) and $\textsf{mev}$ (@mevR) for sampling from Archimedean and multivariate extreme value distributions, respectively. To run the experiment, we use two computer clusters. The first cluster consists of five nodes, each with two 18-core Xeon Gold 3.1 GHz processors and 192 GB of memory, with 2933 MHz per socket. The second cluster has two CPU sockets, each containing a Xeon Platinum 8268 2.90 GHz processor with 24 cores. These configurations provide a significant amount of computational power and are well-suited for handling complex, data-intensive tasks. We use the first cluster to install the $\textsf{copula}$ package and sample from the $\textbf{Clayton}$, $\textbf{Frank}$, and $\textbf{Joe}$ models. We consider an increasing dimension $d \in <span class="sc">\{</span>50, 100, \dots, 1600<span class="sc">\}</span>$ for a fixed sample size of $n=1000$. For the copula package, we compute the average time spent across 100 runs in order to cancel out variability. We use the second cluster to install the $\textsf{mev}$ package and call some of its methods to sample from the $\textbf{Husler Reiss}$, $\textbf{Logistic}$, and $\textbf{TEV}$ distributions. Sampling from the latter is fast, but sampling from the two others is time consuming. Therefore, we only consider dimensions $d \in <span class="sc">\{</span>25, 50, \dots, 250<span class="sc">\}</span>$ for a fixed sample size of $n=1000$.</span>
<span id="cb18-411"><a href="#cb18-411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-412"><a href="#cb18-412" aria-hidden="true" tabindex="-1"></a>::: {#fig-num_res layout-ncol=2}</span>
<span id="cb18-413"><a href="#cb18-413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-414"><a href="#cb18-414" aria-hidden="true" tabindex="-1"></a><span class="al">![Archimedean](figures/discussion/num_time_arch.png)</span></span>
<span id="cb18-415"><a href="#cb18-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-416"><a href="#cb18-416" aria-hidden="true" tabindex="-1"></a><span class="al">![Multivariate extreme value](figures/discussion/num_time_evd.png)</span></span>
<span id="cb18-417"><a href="#cb18-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-418"><a href="#cb18-418" aria-hidden="true" tabindex="-1"></a>Comparison results. Time spent (in seconds) to sample from the corresponding models with respect to the dimension $d$. The left panel shows the results for sampling from $\textbf{Clayton}$, $\textbf{Frank}$ and $\textbf{Joe}$ using $\textsf{clayton}$ in $\textsf{Python}$ and $\textsf{copula}$ in $\textsf{R}$. The right panel shows the results for sampling from $\textbf{HuslerReiss}$, $\textbf{Logistic}$ and $\textbf{TEV}$ by $\textsf{clayton}$ in $\textsf{Python}$ and $\textsf{mev}$ in $\textsf{R}$. In both cases, $1000$ vectors are generated for each model.</span>
<span id="cb18-419"><a href="#cb18-419" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-420"><a href="#cb18-420" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-421"><a href="#cb18-421" aria-hidden="true" tabindex="-1"></a>The figure shows the results of a comparison between the $\textsf{clayton}$ and $\textsf{copula}$ packages in $\textsf{R}$, and the $\textsf{mev}$ package in $\textsf{Python}$. The comparison shows that the $\textsf{clayton}$ package is more efficient at sampling from $\textbf{Clayton}$, $\textbf{Frank}$ and $\textbf{Joe}$ copulae than the $\textsf{copula}$ package. The gap in efficiency may be due to the choice of algorithms used in the $\textsf{clayton}$ package, which uses frailty distributions. The time required for sampling increases linearly with the dimension for the $\textsf{clayton}$ package, but shows a more erratic behavior for the $\textsf{copula}$ package.</span>
<span id="cb18-422"><a href="#cb18-422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-423"><a href="#cb18-423" aria-hidden="true" tabindex="-1"></a><span class="fu">## Conclusion</span></span>
<span id="cb18-424"><a href="#cb18-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-425"><a href="#cb18-425" aria-hidden="true" tabindex="-1"></a>This paper presents the construction and some implementations of the $\textsf{Python}$ package $\textsf{clayton}$ for random copula sampling. This is a seminal work in the field of software implementation of copula modeling in $\textsf{Python}$ and there is much more potential for growth. It is hoped that the potential diffusion of the software through those who need it may bring further implementations for multivariate modeling with copulae under $\textsf{Python}$. For example, choosing a copula to fit the data is an important but difficult problem. A robust approach to estimating copulae has been investigated recently by @alquier2020estimation using Maximum Mean Discrepancy. In relation to our example, semiparametric estimation of copulae with missing data could be of great interest, as proposed by @HAMORI201985.</span>
<span id="cb18-426"><a href="#cb18-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-427"><a href="#cb18-427" aria-hidden="true" tabindex="-1"></a>Additionally, implementation of the algorithm proposed by @10.1214/07-AOS556 for generating random vectors for Archimedean copulae has been tackled, but as expected, numerical inversion gives spurious results, especially when the parameter $\theta$ and the dimension $d$ are high. Furthermore, as the support of the radial distribution is contained in the real line, numerical inversion leads to increased computational time. Further investigation is needed in order to generate random vectors from classical Archimedan models using the radial distribution.</span>
<span id="cb18-428"><a href="#cb18-428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-429"><a href="#cb18-429" aria-hidden="true" tabindex="-1"></a>A direction of improvement for the $\textsf{clayton}$ package is dependence modeling with Vine copulae, which have recently been a tool of high interest in the machine learning community (see, e.g., @lopez2013gaussian, @Veeramachaneni2015CopulaGM, @Carrera2016VineCC, @10.5555/2946645.2946678 or @SunCuesta-InfanteVeeramachaneni2019). This highlights the need for dependence modeling with copulae in $\textsf{Python}$, as a significant part of the machine learning community uses this language. In relation to this paper, Vine copulae may be useful for modeling dependencies between extreme events, as suggested by @SIMPSON2021104736, @nolde2021linking. Furthermore, other copula models could be implemented to model further dependencies. These implementations will expand the scope of dependence modeling with $\textsf{Python}$ and provide high-quality, usable tools for anyone who needs them.</span>
<span id="cb18-430"><a href="#cb18-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-431"><a href="#cb18-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-432"><a href="#cb18-432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-433"><a href="#cb18-433" aria-hidden="true" tabindex="-1"></a><span class="fu"># References {.unnumbered}</span></span>
<span id="cb18-434"><a href="#cb18-434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-435"><a href="#cb18-435" aria-hidden="true" tabindex="-1"></a>::: {#refs}</span>
<span id="cb18-436"><a href="#cb18-436" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-437"><a href="#cb18-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-438"><a href="#cb18-438" aria-hidden="true" tabindex="-1"></a><span class="fu"># Appendix {#appendices}</span></span>
<span id="cb18-439"><a href="#cb18-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-440"><a href="#cb18-440" aria-hidden="true" tabindex="-1"></a><span class="fu">## Bivariate Archimedean models {#sec-bv_arch}</span></span>
<span id="cb18-441"><a href="#cb18-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-442"><a href="#cb18-442" aria-hidden="true" tabindex="-1"></a>:::&nbsp;{#fig-bv_arch-1}</span>
<span id="cb18-443"><a href="#cb18-443" aria-hidden="true" tabindex="-1"></a><span class="al">![](figures/app/arch_table_1.png)</span>{width=100%}</span>
<span id="cb18-444"><a href="#cb18-444" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-445"><a href="#cb18-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-446"><a href="#cb18-446" aria-hidden="true" tabindex="-1"></a>:::&nbsp;{#fig-bv_arch-2}</span>
<span id="cb18-447"><a href="#cb18-447" aria-hidden="true" tabindex="-1"></a><span class="al">![](figures/app/arch_table_2.png)</span>{width=100%}</span>
<span id="cb18-448"><a href="#cb18-448" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-449"><a href="#cb18-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-450"><a href="#cb18-450" aria-hidden="true" tabindex="-1"></a><span class="fu">## Implemented bivariate extreme models {#sec-bv_ext}</span></span>
<span id="cb18-451"><a href="#cb18-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-452"><a href="#cb18-452" aria-hidden="true" tabindex="-1"></a>:::&nbsp;{#fig-bv-ext}</span>
<span id="cb18-453"><a href="#cb18-453" aria-hidden="true" tabindex="-1"></a><span class="al">![](figures/app/ext_table.png)</span>{width=100%}</span>
<span id="cb18-454"><a href="#cb18-454" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-455"><a href="#cb18-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-456"><a href="#cb18-456" aria-hidden="true" tabindex="-1"></a><span class="fu">## Multivariate Archimedean copulae {#sec-mv_arch}</span></span>
<span id="cb18-457"><a href="#cb18-457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-458"><a href="#cb18-458" aria-hidden="true" tabindex="-1"></a>:::&nbsp;{#fig-mv-arch}</span>
<span id="cb18-459"><a href="#cb18-459" aria-hidden="true" tabindex="-1"></a><span class="al">![](figures/app/arch_mv_table.png)</span>{width=100%}</span>
<span id="cb18-460"><a href="#cb18-460" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-461"><a href="#cb18-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-462"><a href="#cb18-462" aria-hidden="true" tabindex="-1"></a><span class="fu">## Multivariate extreme models {#sec-mv_ext}</span></span>
<span id="cb18-463"><a href="#cb18-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-464"><a href="#cb18-464" aria-hidden="true" tabindex="-1"></a>Before giving the main details, we introduce some notations. Let $B$ be the set of all nonempty subsets of $<span class="sc">\{</span>1,\dots,d<span class="sc">\}</span>$ </span>
<span id="cb18-465"><a href="#cb18-465" aria-hidden="true" tabindex="-1"></a>and $B_1 = <span class="sc">\{</span>b \in B, |b| = 1<span class="sc">\}</span>$, where $|b|$ denotes the number of elements in thet set $b$. We note by $B_{(j)} = <span class="sc">\{</span>b \in B, j \in b<span class="sc">\}</span>$. </span>
<span id="cb18-466"><a href="#cb18-466" aria-hidden="true" tabindex="-1"></a>For $d=3$, the Pickands is expressed as</span>
<span id="cb18-467"><a href="#cb18-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-468"><a href="#cb18-468" aria-hidden="true" tabindex="-1"></a>::: {#eq-mv_ext}</span>
<span id="cb18-469"><a href="#cb18-469" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb18-470"><a href="#cb18-470" aria-hidden="true" tabindex="-1"></a> A(\textbf{w}) =&amp; \alpha_1 w_1 + \psi_1 w_2 + \phi_1 w_3 + \left( (\alpha_2 w_1)^{\theta_1} + (\psi_2w_2)^{\theta_1} \right)^{1/\theta_1} + \left( (\alpha_3 w_2)^{\theta_2} + (\phi_2w_3)^{\theta_2} \right)^{1/\theta_2} <span class="sc">\\</span> &amp;+ \left( (\psi_3 w_2)^{\theta_3} + (\phi_3w_3)^{\theta_3} \right)^{1/\theta_3} </span>
<span id="cb18-471"><a href="#cb18-471" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>\left( (\alpha_4 w_1)^{\theta_4} + (\psi_4 w_2)^{\theta_4} + (\phi_4 w_3)^{\theta_4} \right)^{1/\theta_4},</span>
<span id="cb18-472"><a href="#cb18-472" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb18-473"><a href="#cb18-473" aria-hidden="true" tabindex="-1"></a>::: </span>
<span id="cb18-474"><a href="#cb18-474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-475"><a href="#cb18-475" aria-hidden="true" tabindex="-1"></a>where $\boldsymbol{\alpha} = (\alpha_1, \dots, \alpha_4), \boldsymbol{\psi} = (\psi_1, \dots, \psi_4), \boldsymbol{\phi} = (\phi_1, \dots, \phi_4)$ are all elements of $\Delta^3$. </span>
<span id="cb18-476"><a href="#cb18-476" aria-hidden="true" tabindex="-1"></a>We take $\boldsymbol{\alpha} = (0.4,0.3,0.1,0.2)$, $\boldsymbol{\psi} = (0.1, 0.2, 0.4, 0.3)$, $\boldsymbol{\phi} = (0.6,0.1,0.1,0.2)$ and </span>
<span id="cb18-477"><a href="#cb18-477" aria-hidden="true" tabindex="-1"></a>$\boldsymbol{\theta} = (\theta_1, \dots, \theta_4) = (0.6,0.5,0.8,0.3)$ as the dependence parameter.</span>
<span id="cb18-478"><a href="#cb18-478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-479"><a href="#cb18-479" aria-hidden="true" tabindex="-1"></a>The Dirichlet model is a mixture of $m$ Dirichlet densities, that is</span>
<span id="cb18-480"><a href="#cb18-480" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-481"><a href="#cb18-481" aria-hidden="true" tabindex="-1"></a>    h(\textbf{w}) = \sum_{k=1}^m \theta_k \frac{\Gamma(\sum_{j=1}^d \sigma_{kj})}{\Pi_{j=1}^d \Gamma(\sigma_{kj})} \Pi_{j=1}^d w_j^{\sigma_{kj}-1},</span>
<span id="cb18-482"><a href="#cb18-482" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-483"><a href="#cb18-483" aria-hidden="true" tabindex="-1"></a>with $\sum_{k=1}^m \theta_k = 1$, $\sigma_{kj} &gt; 0$ for $k \in <span class="sc">\{</span>1,\dots,m<span class="sc">\}</span>$ and $j \in <span class="sc">\{</span>1, \dots, d<span class="sc">\}</span>$. Let $\mathcal{D} \in [0, \infty)^{(d-1)\times (d-1)}$ denotes the space of symmetric strictly conditionnaly negative definite matrices that is</span>
<span id="cb18-484"><a href="#cb18-484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-485"><a href="#cb18-485" aria-hidden="true" tabindex="-1"></a>::: {#striclty_cond_neg}</span>
<span id="cb18-486"><a href="#cb18-486" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb18-487"><a href="#cb18-487" aria-hidden="true" tabindex="-1"></a>            \mathcal{D}_{k} = \Big\{ \Gamma \in [0,\infty)^{k \times k} : a^\top \Gamma a &lt; 0 \; \textrm{for all } a \in \mathbb{R}^{k} \setminus \{\textbf{0}\}  \, \textrm{with } \sum_{j=1}^{d-1} a_j = 0, \\ \Gamma_{ii} = 0, \Gamma_{ij} = \Gamma_{ji}, \quad 1 \leq i,j\leq k \Big<span class="sc">\}</span>.</span>
<span id="cb18-488"><a href="#cb18-488" aria-hidden="true" tabindex="-1"></a>        \end{align*}</span>
<span id="cb18-489"><a href="#cb18-489" aria-hidden="true" tabindex="-1"></a>::: </span>
<span id="cb18-490"><a href="#cb18-490" aria-hidden="true" tabindex="-1"></a>For any $2 \leq k \leq d$, consider $m' = (m_1, \dots, m_k)$ with $1 \leq m_1 &lt;  \dots &lt; m_k \leq d$ define</span>
<span id="cb18-491"><a href="#cb18-491" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-492"><a href="#cb18-492" aria-hidden="true" tabindex="-1"></a>    \Sigma^{(k)}_m = 2 \left( \Gamma_{m_i m_k} + \Gamma_{m_j m_k} - \Gamma_{m_i m_j} \right)_{m_i m_j \neq m_k} \in [0,\infty)^{(d-1)\times(d-1)}.</span>
<span id="cb18-493"><a href="#cb18-493" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-494"><a href="#cb18-494" aria-hidden="true" tabindex="-1"></a>Furthermore, note $S(\cdot | \Sigma^{(k)}_m)$ denote the survival function of a normal random vector with mean vector $\textbf{0}$ and covariance matrix $\Sigma^{(k)}$. We now define :</span>
<span id="cb18-495"><a href="#cb18-495" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-496"><a href="#cb18-496" aria-hidden="true" tabindex="-1"></a>    h_{km}(\textbf{y}) = \int_{y_k}^\infty S\left( (y_i - z + 2\Gamma_{m_i m_k})_{i=1}^{k-1} | \Gamma_{km}\right) e^{-z}dz </span>
<span id="cb18-497"><a href="#cb18-497" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-498"><a href="#cb18-498" aria-hidden="true" tabindex="-1"></a>for $2 \leq k \leq d$. We denote by $\Sigma^{(k)}$ the summation over all $k$-vectors $m=(m_1,\dots,m_k)$ with $1\leq m_1 &lt; \dots &lt; m_k \leq d$.</span>
<span id="cb18-499"><a href="#cb18-499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-500"><a href="#cb18-500" aria-hidden="true" tabindex="-1"></a>:::&nbsp;{#fig-mv_ext}</span>
<span id="cb18-501"><a href="#cb18-501" aria-hidden="true" tabindex="-1"></a><span class="al">![](figures/app/ext_mv_table.png)</span>{width=100%}</span>
<span id="cb18-502"><a href="#cb18-502" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-503"><a href="#cb18-503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-504"><a href="#cb18-504" aria-hidden="true" tabindex="-1"></a><span class="fu">## Multivariate elliptical dependencies {#sec-mv_ellip}</span></span>
<span id="cb18-505"><a href="#cb18-505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-506"><a href="#cb18-506" aria-hidden="true" tabindex="-1"></a>Let $\textbf{X} \sim \textbf{E}_d(\boldsymbol{\mu}, \Sigma, \psi)$ be an elliptical distributed random vector with cumulative distribution $F$ </span>
<span id="cb18-507"><a href="#cb18-507" aria-hidden="true" tabindex="-1"></a>and marginal $F_0, \dots, F_{d-1}$. Then, the copula $C$ of $F$ is called an elliptical copula. We denote by  $\phi$ the standard normal distribution </span>
<span id="cb18-508"><a href="#cb18-508" aria-hidden="true" tabindex="-1"></a>function and $\boldsymbol{\phi}_\Sigma$ the joint distribution function of $\textbf{X} \sim \mathcal{N}_d(\textbf{0}, \Sigma)$, where $\textbf{0}$ is </span>
<span id="cb18-509"><a href="#cb18-509" aria-hidden="true" tabindex="-1"></a>the $d$-dimensional vector composed out of $0$. In the same way, we note $t_{\theta}$ the distribution function of a standard univariate distribution </span>
<span id="cb18-510"><a href="#cb18-510" aria-hidden="true" tabindex="-1"></a>$t$ distribution and by $\boldsymbol{t}_{\theta, \Sigma}$ the joint distribution function of the vector $\textbf{X} \sim \boldsymbol{t}_{d}(\theta, \textbf{0}, \Sigma)$. </span>
<span id="cb18-511"><a href="#cb18-511" aria-hidden="true" tabindex="-1"></a>A $d$ squared matrix $\Sigma$ is said to be positively semi definite if for all $u \in \mathbb{R}^d$ we have :</span>
<span id="cb18-512"><a href="#cb18-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-513"><a href="#cb18-513" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-514"><a href="#cb18-514" aria-hidden="true" tabindex="-1"></a>  u^\top \Sigma u \geq 0</span>
<span id="cb18-515"><a href="#cb18-515" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-516"><a href="#cb18-516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-517"><a href="#cb18-517" aria-hidden="true" tabindex="-1"></a>:::&nbsp;{#fig-mv_elli}</span>
<span id="cb18-518"><a href="#cb18-518" aria-hidden="true" tabindex="-1"></a><span class="al">![](figures/app/elli_table.png)</span>{width=100%}</span>
<span id="cb18-519"><a href="#cb18-519" aria-hidden="true" tabindex="-1"></a>:::</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>